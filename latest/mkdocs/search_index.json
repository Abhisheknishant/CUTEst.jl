{
    "docs": [
        {
            "location": "/", 
            "text": "CUTEst.jl documentation\n\n\nThis package provides an interface to \nCUTEst\n, the \nConstrained and Unconstrained Test Environment with safe threads\n for nonlinear optimization.\n\n\nThis package uses \nNLPModels.jl\n, but it also gives direct access to the CUTEst functions.\n\n\n\n\nCUTEst brief history\n\n\nCUTEst has been around for a while. It started as CUTE, then CUTEr, then CUTEr2, and finally CUTEst. The \noriginal project\n can be used independently of Julia.\n\n\nCUTEst works by decoding a \n.SIF\n file into other files and objects so that a user compiles links that to his code. It also gives the option of doing that for you, in which case you have to send some code to it's folder, and ask for the compilation.\n\n\nCUTEst gives you about 100 methods to access the objective and constraints functions, as well as their derivatives in many different formats. It also gives access to the problem's information, like number of variables, constraints, the initial point, the bounds, an so on.\n\n\n\n\nInstalling\n\n\nCurrently, this package builds its own version of CUTEst, if you have your own version of CUTEst, this will conflict with it. Check the issues for a fix, or open one for help.\n\n\nThe following commands should automatically download NLPModels.jl and CUTEst, and install them.\n\n\nPkg\n.\nclone\n(\nhttps://github.com/JuliaSmoothOptimizers/NLPModels.jl.git\n)\n\n\nPkg\n.\nclone\n(\nhttps://github.com/JuliaSmoothOptimizers/CUTEst.jl.git\n)\n\n\nPkg\n.\ncheckout\n(\nCUTEst\n,\n \ndevelop\n)\n\n\nPkg\n.\nbuild\n(\nCUTEst\n)\n\n\n\n\n\n\n\n\nUsage\n\n\nCheck the \ntutorial\n for complete usage.\n\n\nThe simplest use of CUTEst is through the interface of NLPModels.jl. Here's the quick \nreference guide\n.\n\n\nusing\n \nCUTEst\n\n\n\nnlp\n \n=\n \nCUTEstModel\n(\nROSENBR\n)\n\n\nprintln\n(\nx0 = \n$(nlp.meta.x0)\n)\n\n\nprintln\n(\nfx = \n$( obj(nlp, nlp.meta.x0) )\n)\n\n\nprintln\n(\ngx = \n$( grad(nlp, nlp.meta.x0) )\n)\n\n\nprintln\n(\nHx = \n$( hess(nlp, nlp.meta.x0) )\n)\n\n\ncutest_finalize\n(\nnlp\n)\n\n\n\n\n\n\nx0 = [-1.2,1.0]\nfx = 24.199999999999996\ngx = [-215.59999999999997,-87.99999999999999]\nHx =\n    [1, 1]  =  1330.0\n    [2, 1]  =  480.0\n    [2, 2]  =  200.0\n\n\n\n\n\nCheck the \nNLPModels API\n for details.\n\n\n\n\nWorking with CUTEst directly\n\n\nWe also have implemented function to allow access to the CUTEst functions directly. There is a specialized API which provides a Julian way to access them, and a core API which is only a wrapper for CUTEst. For more information see the section \ncore\n, or the documentation \nhere\n.\n\n\n\n\nContents\n\n\n\n\nAPI\n\n\nNLPModels API\n\n\nExtra Julian API\n\n\nCore and specialized API\n\n\nInternal\n\n\n\n\n\n\nWorking with CUTEst directly\n\n\nSpecialized Interface\n\n\n\n\n\n\nReference\n\n\nCUTEst.jl documentation\n\n\nCUTEst brief history\n\n\nInstalling\n\n\nUsage\n\n\nWorking with CUTEst directly\n\n\nContents\n\n\n\n\n\n\nTutorial\n\n\nNLPModels interface", 
            "title": "Home"
        }, 
        {
            "location": "/#cutestjl-documentation", 
            "text": "This package provides an interface to  CUTEst , the  Constrained and Unconstrained Test Environment with safe threads  for nonlinear optimization.  This package uses  NLPModels.jl , but it also gives direct access to the CUTEst functions.", 
            "title": "CUTEst.jl documentation"
        }, 
        {
            "location": "/#cutest-brief-history", 
            "text": "CUTEst has been around for a while. It started as CUTE, then CUTEr, then CUTEr2, and finally CUTEst. The  original project  can be used independently of Julia.  CUTEst works by decoding a  .SIF  file into other files and objects so that a user compiles links that to his code. It also gives the option of doing that for you, in which case you have to send some code to it's folder, and ask for the compilation.  CUTEst gives you about 100 methods to access the objective and constraints functions, as well as their derivatives in many different formats. It also gives access to the problem's information, like number of variables, constraints, the initial point, the bounds, an so on.", 
            "title": "CUTEst brief history"
        }, 
        {
            "location": "/#installing", 
            "text": "Currently, this package builds its own version of CUTEst, if you have your own version of CUTEst, this will conflict with it. Check the issues for a fix, or open one for help.  The following commands should automatically download NLPModels.jl and CUTEst, and install them.  Pkg . clone ( https://github.com/JuliaSmoothOptimizers/NLPModels.jl.git )  Pkg . clone ( https://github.com/JuliaSmoothOptimizers/CUTEst.jl.git )  Pkg . checkout ( CUTEst ,   develop )  Pkg . build ( CUTEst )", 
            "title": "Installing"
        }, 
        {
            "location": "/#usage", 
            "text": "Check the  tutorial  for complete usage.  The simplest use of CUTEst is through the interface of NLPModels.jl. Here's the quick  reference guide .  using   CUTEst  nlp   =   CUTEstModel ( ROSENBR )  println ( x0 =  $(nlp.meta.x0) )  println ( fx =  $( obj(nlp, nlp.meta.x0) ) )  println ( gx =  $( grad(nlp, nlp.meta.x0) ) )  println ( Hx =  $( hess(nlp, nlp.meta.x0) ) )  cutest_finalize ( nlp )   x0 = [-1.2,1.0]\nfx = 24.199999999999996\ngx = [-215.59999999999997,-87.99999999999999]\nHx =\n    [1, 1]  =  1330.0\n    [2, 1]  =  480.0\n    [2, 2]  =  200.0  Check the  NLPModels API  for details.", 
            "title": "Usage"
        }, 
        {
            "location": "/#working-with-cutest-directly", 
            "text": "We also have implemented function to allow access to the CUTEst functions directly. There is a specialized API which provides a Julian way to access them, and a core API which is only a wrapper for CUTEst. For more information see the section  core , or the documentation  here .", 
            "title": "Working with CUTEst directly"
        }, 
        {
            "location": "/#contents", 
            "text": "API  NLPModels API  Extra Julian API  Core and specialized API  Internal    Working with CUTEst directly  Specialized Interface    Reference  CUTEst.jl documentation  CUTEst brief history  Installing  Usage  Working with CUTEst directly  Contents    Tutorial  NLPModels interface", 
            "title": "Contents"
        }, 
        {
            "location": "/tutorial/", 
            "text": "Tutorial\n\n\nCUTEst can be accessed in three ways. - The first, easiest, and recommended for most users, is using the   \nNLPModels.jl\n.   This is recommended because if you develop something for this an \nNLPModel\n,   then it can work with CUTEst, but also with other models. - The second is the core interface, which is just a wrapper of the Fortran   functions, and is not recommended unless you really need and know what you're   doing. - The third is something in the middle, which we called specialized interface.   It follows the same naming as the core functions, but it is more accessible,   from the Julia point of view.\n\n\n\n\nNLPModels interface\n\n\nNLPModels defines an abstract interface to access the objective, constraints, derivatives, etc. of the problem. A \nreference guide\n is available to check what you need.\n\n\nOnce CUTEst has been installed, open a problem with\n\n\nusing\n \nCUTEst\n\n\n\nnlp\n \n=\n \nCUTEstModel\n(\nROSENBR\n)\n\n\n\n\n\n\nMinimization problem ROSENBR\nnvar = 2, ncon = 0 (0 linear)\n\n\n\n\n\nThat's it. You can use \nnlp\n like any other NLPModel, with one \nimportant exception\n. You have to finalize the model after using it. To be exact, you have to finalize it before opening a new one. There is no problem in closing Julia before finalizing it, for instance.\n\n\ncutest_finalize\n(\nnlp\n)\n\n\n\n\n\n\nBeing a NLPModel means that everything created for an AbstractNLPModel will work for CUTEstModel. For instance, \nOptimize.jl\n has implementations of optimization methods for AbstractNLPModels.\n\n\nLet's make some demonstration of the CUTEstModel.\n\n\nusing\n \nCUTEst\n\n\n\nnlp\n \n=\n \nCUTEstModel\n(\nROSENBR\n)\n\n\nprintln\n(\nx0 = \n$( nlp.meta.x0 )\n)\n\n\nprintln\n(\nfx = \n$( obj(nlp, nlp.meta.x0) )\n)\n\n\nprintln\n(\ngx = \n$( grad(nlp, nlp.meta.x0) )\n)\n\n\nprintln\n(\nHx = \n$( hess(nlp, nlp.meta.x0) )\n)\n\n\n\n\n\n\nx0 = [-1.2,1.0]\nfx = 24.199999999999996\ngx = [-215.59999999999997,-87.99999999999999]\nHx =\n    [1, 1]  =  1330.0\n    [2, 1]  =  480.0\n    [2, 2]  =  200.0\n\n\n\n\n\nRemember to check the \nAPI\n in case of doubts about these functions.\n\n\nNotice how \nhess\n returns a lower triangle matrix. For decompositions that should be enough. For iterative solvers, you may want $\\nabla^2 f(x) v$ instead, so only the lower triangle won't do. But you do have\n\n\nv\n \n=\n \nones\n(\nnlp\n.\nmeta\n.\nnvar\n)\n\n\nhprod\n(\nnlp\n,\n \nnlp\n.\nmeta\n.\nx0\n,\n \nv\n)\n\n\n\n\n\n\n2-element Array{Float64,1}:\n 1810.0\n  680.0\n\n\n\n\n\nYou can also use a \nLinearOperator\n,\n\n\nusing\n \nLinearOperators\n\n\nn\n \n=\n \nnlp\n.\nmeta\n.\nnvar\n\n\n\nH\n \n=\n \nhess_op\n(\nnlp\n,\n \nnlp\n.\nmeta\n.\nx0\n)\n\n\nH\n \n*\n \nv\n\n\n\n\n\n\n2-element Array{Float64,1}:\n 1810.0\n  680.0\n\n\n\n\n\nThis way, you can use a \nKrylov\n method to solve the linear system with the Hessian as matrix. For instance, here is an example computation of a Newton trust-region step.\n\n\n```@example ex1\nusing Krylov\n\n\nDelta = 10.0\nx = nlp.meta.x0\nprintln(\"0: x = $x\")\nfor i = 1:5\n  print(\"$i: \")\n  H = hess_op(nlp, x)\n  d, stats = Krylov.cg(H, -grad(nlp, x), radius=Delta)\n  x = x + d\n  println(\"x = $x\")\nend\n\n\n```julia\ncutest_finalize(nlp)\n\n\n\n\n\nThere is no difference in calling a constrained problem, only that some additional functions are available.\n\n\nusing\n \nCUTEst\n\n\n\nnlp\n \n=\n \nCUTEstModel\n(\nHS35\n)\n\n\n\n\n\n\nMinimization problem HS35\nnvar = 3, ncon = 1 (1 linear)\n\n\n\n\n\nx\n \n=\n \nnlp\n.\nmeta\n.\nx0\n\n\n\ncons\n(\nnlp\n,\n \nx\n)\n\n\n\n\n\n\n1-element Array{Float64,1}:\n 1.0\n\n\n\n\n\njac\n(\nnlp\n,\n \nx\n)\n\n\n\n\n\n\n1x3 sparse matrix with 3 Float64 entries:\n    [1, 1]  =  -1.0\n    [1, 2]  =  -1.0\n    [1, 3]  =  -2.0\n\n\n\n\n\nTo find out whether these constraints are equalities or inequalities we can check \nnlp.meta\n\n\nprint\n(\nnlp\n.\nmeta\n)\n\n\n\n\n\n\nMinimization problem HS35\nnvar = 3, ncon = 1 (1 linear)\nlvar = 0.0  0.0  0.0\nuvar = Inf  Inf  Inf\nlcon = 0.0\nucon = Inf\nx0 = 0.5  0.5  0.5\ny0 = 0.0\nnnzh = 5\nnnzj = 3\nlinear constraints:    1\n\n\n\n\n\ncutest_finalize\n(\nnlp\n)", 
            "title": "Tutorial"
        }, 
        {
            "location": "/tutorial/#tutorial", 
            "text": "CUTEst can be accessed in three ways. - The first, easiest, and recommended for most users, is using the    NLPModels.jl .   This is recommended because if you develop something for this an  NLPModel ,   then it can work with CUTEst, but also with other models. - The second is the core interface, which is just a wrapper of the Fortran   functions, and is not recommended unless you really need and know what you're   doing. - The third is something in the middle, which we called specialized interface.   It follows the same naming as the core functions, but it is more accessible,   from the Julia point of view.", 
            "title": "Tutorial"
        }, 
        {
            "location": "/tutorial/#nlpmodels-interface", 
            "text": "NLPModels defines an abstract interface to access the objective, constraints, derivatives, etc. of the problem. A  reference guide  is available to check what you need.  Once CUTEst has been installed, open a problem with  using   CUTEst  nlp   =   CUTEstModel ( ROSENBR )   Minimization problem ROSENBR\nnvar = 2, ncon = 0 (0 linear)  That's it. You can use  nlp  like any other NLPModel, with one  important exception . You have to finalize the model after using it. To be exact, you have to finalize it before opening a new one. There is no problem in closing Julia before finalizing it, for instance.  cutest_finalize ( nlp )   Being a NLPModel means that everything created for an AbstractNLPModel will work for CUTEstModel. For instance,  Optimize.jl  has implementations of optimization methods for AbstractNLPModels.  Let's make some demonstration of the CUTEstModel.  using   CUTEst  nlp   =   CUTEstModel ( ROSENBR )  println ( x0 =  $( nlp.meta.x0 ) )  println ( fx =  $( obj(nlp, nlp.meta.x0) ) )  println ( gx =  $( grad(nlp, nlp.meta.x0) ) )  println ( Hx =  $( hess(nlp, nlp.meta.x0) ) )   x0 = [-1.2,1.0]\nfx = 24.199999999999996\ngx = [-215.59999999999997,-87.99999999999999]\nHx =\n    [1, 1]  =  1330.0\n    [2, 1]  =  480.0\n    [2, 2]  =  200.0  Remember to check the  API  in case of doubts about these functions.  Notice how  hess  returns a lower triangle matrix. For decompositions that should be enough. For iterative solvers, you may want $\\nabla^2 f(x) v$ instead, so only the lower triangle won't do. But you do have  v   =   ones ( nlp . meta . nvar )  hprod ( nlp ,   nlp . meta . x0 ,   v )   2-element Array{Float64,1}:\n 1810.0\n  680.0  You can also use a  LinearOperator ,  using   LinearOperators  n   =   nlp . meta . nvar  H   =   hess_op ( nlp ,   nlp . meta . x0 )  H   *   v   2-element Array{Float64,1}:\n 1810.0\n  680.0  This way, you can use a  Krylov  method to solve the linear system with the Hessian as matrix. For instance, here is an example computation of a Newton trust-region step.  ```@example ex1\nusing Krylov  Delta = 10.0\nx = nlp.meta.x0\nprintln(\"0: x = $x\")\nfor i = 1:5\n  print(\"$i: \")\n  H = hess_op(nlp, x)\n  d, stats = Krylov.cg(H, -grad(nlp, x), radius=Delta)\n  x = x + d\n  println(\"x = $x\")\nend  ```julia\ncutest_finalize(nlp)  There is no difference in calling a constrained problem, only that some additional functions are available.  using   CUTEst  nlp   =   CUTEstModel ( HS35 )   Minimization problem HS35\nnvar = 3, ncon = 1 (1 linear)  x   =   nlp . meta . x0  cons ( nlp ,   x )   1-element Array{Float64,1}:\n 1.0  jac ( nlp ,   x )   1x3 sparse matrix with 3 Float64 entries:\n    [1, 1]  =  -1.0\n    [1, 2]  =  -1.0\n    [1, 3]  =  -2.0  To find out whether these constraints are equalities or inequalities we can check  nlp.meta  print ( nlp . meta )   Minimization problem HS35\nnvar = 3, ncon = 1 (1 linear)\nlvar = 0.0  0.0  0.0\nuvar = Inf  Inf  Inf\nlcon = 0.0\nucon = Inf\nx0 = 0.5  0.5  0.5\ny0 = 0.0\nnnzh = 5\nnnzj = 3\nlinear constraints:    1  cutest_finalize ( nlp )", 
            "title": "NLPModels interface"
        }, 
        {
            "location": "/api/", 
            "text": "API\n\n\n\n\nNLPModels API\n\n\n#\n\n\nNLPModels.obj\n \n \nFunction\n.\n\n\nobj(nlp, x)\n\n\nEvaluate $f(x)$, the objective function of \nnlp\n at \nx\n.\n\n\n#\n\n\nNLPModels.grad\n \n \nFunction\n.\n\n\ngrad(nlp, x)\n\n\nEvaluate $\\nabla f(x)$, the gradient of the objective function at \nx\n.\n\n\n#\n\n\nNLPModels.grad!\n \n \nFunction\n.\n\n\ngrad!(nlp, x, g)\n\n\nEvaluate $\\nabla f(x)$, the gradient of the objective function at \nx\n in place.\n\n\n#\n\n\nNLPModels.cons\n \n \nFunction\n.\n\n\ncons(nlp, x)\n\n\nEvaluate $c(x)$, the constraints at \nx\n.\n\n\ncons(nlp, x, jac)\n\n\n\n\n\nComputes the constraint vector and, if \njac\n is \ntrue\n, the Jacobian in internal sparse format. Usage:\n\n\nc, J = cons(nlp, x, true)\nc = cons(nlp, x, false)\n\n\n\n\n\n\n\nnlp:  [IN] CUTEstModel\n\n\nx:    [IN] Array{Float64, 1}\n\n\njac:  [IN] Bool\n\n\nc:    [OUT] Array{Float64, 1}\n\n\nJ:    [OUT] Base.SparseMatrix.SparseMatrixCSC{Float64,Int32}\n\n\n\n\n#\n\n\nNLPModels.cons!\n \n \nFunction\n.\n\n\ncons!(nlp, x, c)\n\n\nEvaluate $c(x)$, the constraints at \nx\n in place.\n\n\n#\n\n\nNLPModels.jac_coord\n \n \nFunction\n.\n\n\n(rows,cols,vals) = jac_coord(nlp, x)\n\n\nEvaluate $\\nabla c(x)$, the constraint's Jacobian at \nx\n in sparse coordinate format.\n\n\n#\n\n\nNLPModels.jac\n \n \nFunction\n.\n\n\nJx = jac(nlp, x)\n\n\nEvaluate $\\nabla c(x)$, the constraint's Jacobian at \nx\n as a sparse matrix.\n\n\n#\n\n\nNLPModels.jprod\n \n \nFunction\n.\n\n\nJv = jprod(nlp, x, v)\n\n\nEvaluate $\\nabla c(x)v$, the Jacobian-vector product at \nx\n.\n\n\n#\n\n\nNLPModels.jprod!\n \n \nFunction\n.\n\n\nJv = jprod!(nlp, x, v, Jv)\n\n\nEvaluate $\\nabla c(x)v$, the Jacobian-vector product at \nx\n in place.\n\n\n#\n\n\nNLPModels.jtprod\n \n \nFunction\n.\n\n\nJtv = jtprod(nlp, x, v, Jtv)\n\n\nEvaluate $\\nabla c(x)^Tv$, the transposed-Jacobian-vector product at \nx\n.\n\n\n#\n\n\nNLPModels.jtprod!\n \n \nFunction\n.\n\n\nJtv = jtprod!(nlp, x, v, Jtv)\n\n\nEvaluate $\\nabla c(x)^Tv$, the transposed-Jacobian-vector product at \nx\n in place.\n\n\n#\n\n\nNLPModels.hess_coord\n \n \nFunction\n.\n\n\n(rows,cols,vals) = hess_coord(nlp, x; obj_weight=1.0, y=zeros)\n\n\nEvaluate the Lagrangian Hessian at \n(x,y)\n in sparse coordinate format, with objective function scaled by \nobj_weight\n, i.e.,\n\n\n\n\n \\nabla^2L(x,y) = \\sigma * \\nabla^2 f(x) + \\sum_{i=1}^m y_i\\nabla^2 c_i(x), \n\n\n\n\nwith \u03c3 = obj_weight. Only the lower triangle is returned.\n\n\n#\n\n\nNLPModels.hess\n \n \nFunction\n.\n\n\nHx = hess(nlp, x; obj_weight=1.0, y=zeros)\n\n\nEvaluate the Lagrangian Hessian at \n(x,y)\n as a sparse matrix, with objective function scaled by \nobj_weight\n, i.e.,\n\n\n\n\n \\nabla^2L(x,y) = \\sigma * \\nabla^2 f(x) + \\sum_{i=1}^m y_i\\nabla^2 c_i(x), \n\n\n\n\nwith \u03c3 = obj_weight. Only the lower triangle is returned.\n\n\n#\n\n\nNLPModels.hprod\n \n \nFunction\n.\n\n\nHv = hprod(nlp, x, v; obj_weight=1.0, y=zeros)\n\n\nEvaluate the product of the Lagrangian Hessian at \n(x,y)\n with the vector \nv\n, with objective function scaled by \nobj_weight\n, i.e.,\n\n\n\n\n \\nabla^2L(x,y) = \\sigma * \\nabla^2 f(x) + \\sum_{i=1}^m y_i\\nabla^2 c_i(x), \n\n\n\n\nwith \u03c3 = obj_weight.\n\n\n#\n\n\nNLPModels.hprod!\n \n \nFunction\n.\n\n\nHv = hprod!(nlp, x, v, Hv; obj_weight=1.0, y=zeros)\n\n\nEvaluate the product of the Lagrangian Hessian at \n(x,y)\n with the vector \nv\n in place, with objective function scaled by \nobj_weight\n, i.e.,\n\n\n\n\n \\nabla^2L(x,y) = \\sigma * \\nabla^2 f(x) + \\sum_{i=1}^m y_i\\nabla^2 c_i(x), \n\n\n\n\nwith \u03c3 = obj_weight.\n\n\n#\n\n\nNLPModels.NLPtoMPB\n \n \nFunction\n.\n\n\nmp = NLPtoMPB(nlp, solver)\n\n\n\n\n\nReturn a \nMathProgBase\n model corresponding to an \nAbstractNLPModel\n.\n\n\nArguments\n\n\n\n\nnlp::AbstractNLPModel\n\n\nsolver::AbstractMathProgSolver\n a solver instance, e.g., \nIpoptSolver()\n\n\n\n\nCurrently, all models are treated as nonlinear models.\n\n\nReturn values\n\n\nThe function returns a \nMathProgBase\n model \nmpbmodel\n such that it should be possible to call\n\n\nMathProgBase.optimize!(mpbmodel)\n\n\n\n\n\n#\n\n\nLinearOperators.reset!\n \n \nFunction\n.\n\n\nreset!(counters)\n\n\nReset evaluation counters\n\n\n`reset!(nlp)\n\n\nReset evaluation count in \nnlp\n\n\n\n\nExtra Julian API\n\n\n#\n\n\nCUTEst.objgrad\n \n \nFunction\n.\n\n\nobjgrad(nlp, x, grad)\n\n\n\n\n\nComputes the objective function value and, if grad is \ntrue\n, gradient at x. Usage:\n\n\nf, g = objgrad(nlp, x, true)\nf = objgrad(nlp, x)\n\n\n\n\n\n\n\nnlp:  [IN] CUTEstModel\n\n\nx:    [IN] Array{Float64, 1}\n\n\ngrad: [IN] Bool\n\n\nf:    [OUT] Float64\n\n\ng:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.objcons\n \n \nFunction\n.\n\n\nobjcons(nlp, x)\n\n\n\n\n\nComputes the objective function and constraint vector values at x. Usage:\n\n\nf, c = objcons(nlp, x) # If the problem is constrained\nf = objcons(nlp, x)    # If the problem is unconstrained\n\n\n\n\n\n\n\nnlp: [IN] CUTEstModel\n\n\nx:   [IN] Array{Float64, 1}\n\n\nf:   [OUT] Float64\n\n\nc:   [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cons_coord\n \n \nFunction\n.\n\n\ncons_coord(nlp, x, jac)\n\n\n\n\n\nComputes the constraint vector and, if \njac\n is \ntrue\n, the Jacobian in coordinate format. Usage:\n\n\nc, jrow, jcol, jval = cons_coord(nlp, x, true)\nc = cons_coord(nlp, x, false)\n\n\n\n\n\n\n\nnlp:  [IN] CUTEstModel\n\n\nx:    [IN] Array{Float64, 1}\n\n\njac:  [IN] Bool\n\n\nc:    [OUT] Array{Float64, 1}\n\n\njrow: [OUT] Array{Int32, 1}\n\n\njcol: [OUT] Array{Int32, 1}\n\n\njval: [OUT] Array{Float64, 1}\n\n\n\n\n\n\nCore and specialized API\n\n\n#\n\n\nCUTEst.ccfg\n \n \nMethod\n.\n\n\nccfg\n\n\nThe ccfg subroutine evaluates the values of the constraint functions of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly their gradients. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ccfg\n\n\n\n\n\nUsage:\n\n\nccfg(io_err, n, m, x, c, jtrans, lcjac1, lcjac2, cjac, grad)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nc:       [OUT] Array{Cdouble, 1}\n\n\njtrans:  [IN] Array{Cint, 1}\n\n\nlcjac1:  [IN] Array{Cint, 1}\n\n\nlcjac2:  [IN] Array{Cint, 1}\n\n\ncjac:    [OUT] Array{Cdouble, 2}\n\n\ngrad:    [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ccfsg\n \n \nMethod\n.\n\n\nccfsg\n\n\nThe ccfsg subroutine evaluates the values of the constraint functions of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly their gradients in the constrained minimization case. The gradients are stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ccfsg\n\n\n\n\n\nUsage:\n\n\nccfsg(io_err, n, m, x, c, nnzj, lj, j_val, j_var, j_fun, grad)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nc:       [OUT] Array{Cdouble, 1}\n\n\nnnzj:    [OUT] Array{Cint, 1}\n\n\nlj:      [IN] Array{Cint, 1}\n\n\nj_val:   [OUT] Array{Cdouble, 1}\n\n\nj_var:   [OUT] Array{Cint, 1}\n\n\nj_fun:   [OUT] Array{Cint, 1}\n\n\ngrad:    [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cchprods\n \n \nMethod\n.\n\n\ncchprods\n\n\nThe cchprods subroutine forms the product of a vector with each of the Hessian matrix of the constraint functions c(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point x= X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cchprods\n\n\n\n\n\nUsage:\n\n\ncchprods(io_err, n, m, goth, x, vector, lchp, chp_val, chp_ind, chp_ptr)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\ngoth:    [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nvector:  [IN] Array{Cdouble, 1}\n\n\nlchp:    [IN] Array{Cint, 1}\n\n\nchp_val: [OUT] Array{Cdouble, 1}\n\n\nchp_ind: [IN] Array{Cint, 1}\n\n\nchp_ptr: [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ccifg\n \n \nMethod\n.\n\n\nccifg\n\n\nThe ccifg subroutine evaluates the value of a particular constraint function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient in the constrained minimization case. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ccifg\n\n\n\n\n\nUsage:\n\n\nccifg(io_err, n, icon, x, ci, gci, grad)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nicon:    [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nci:      [OUT] Array{Cdouble, 1}\n\n\ngci:     [OUT] Array{Cdouble, 1}\n\n\ngrad:    [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ccifsg\n \n \nMethod\n.\n\n\nccifsg\n\n\nThe ccifsg subroutine evaluates the value of a particular constraint function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient in the constrained minimization case. The gradient is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ccifsg\n\n\n\n\n\nUsage:\n\n\nccifsg(io_err, n, icon, x, ci, nnzgci, lgci, gci_val, gci_var, grad)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nicon:    [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nci:      [OUT] Array{Cdouble, 1}\n\n\nnnzgci:  [OUT] Array{Cint, 1}\n\n\nlgci:    [IN] Array{Cint, 1}\n\n\ngci_val: [OUT] Array{Cdouble, 1}\n\n\ngci_var: [OUT] Array{Cint, 1}\n\n\ngrad:    [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cdh\n \n \nMethod\n.\n\n\ncdh\n\n\nThe cdh subroutine evaluates the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cdh\n\n\n\n\n\nUsage:\n\n\ncdh(io_err, n, m, x, y, lh1, h_val)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\nlh1:     [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 2}\n\n\n\n\n#\n\n\nCUTEst.cdhc\n \n \nMethod\n.\n\n\ncdhc\n\n\nThe cdhc subroutine evaluates the Hessian matrix of the constraint part of the Lagrangian function yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cdhc\n\n\n\n\n\nUsage:\n\n\ncdhc(io_err, n, m, x, y, lh1, h_val)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\nlh1:     [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 2}\n\n\n\n\n#\n\n\nCUTEst.cdimchp\n \n \nMethod\n.\n\n\ncdimchp\n\n\nThe cdimchp subroutine determines the number of nonzero elements required to store the products of the Hessian matrices of the constraint functions with a specified vector for the problem decoded into OUTSDIF.d in the constrained minimization case. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cdimchp\n\n\n\n\n\nUsage:\n\n\ncdimchp(io_err, nnzchp)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nnnzchp:  [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cdimen\n \n \nMethod\n.\n\n\ncdimen\n\n\nThe cdimen subroutine discovers how many variables and constraints are involved in the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cdimen\n\n\n\n\n\nUsage:\n\n\ncdimen(io_err, input, n, m)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\ninput:   [IN] Array{Cint, 1}\n\n\nn:       [OUT] Array{Cint, 1}\n\n\nm:       [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cdimse\n \n \nMethod\n.\n\n\ncdimse\n\n\nThe cdimse subroutine determines the number of nonzero elements required to store the Hessian matrix of the Lagrangian function for the problem decoded from a SIF file by the script sifdecoder. The matrix is stored in sparse \"finite element\" format H=e\u03a31He, where each square symmetric element He involves a small subset of the rows of the Hessian matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cdimse\n\n\n\n\n\nUsage:\n\n\ncdimse(io_err, ne, he_val_ne, he_row_ne)\n\n\n\n\n\n\n\nio_err:    [OUT] Array{Cint, 1}\n\n\nne:        [OUT] Array{Cint, 1}\n\n\nhe_val_ne: [OUT] Array{Cint, 1}\n\n\nhe_row_ne: [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cdimsh\n \n \nMethod\n.\n\n\ncdimsh\n\n\nThe cdimsh subroutine determines the number of nonzero elements required to store the Hessian matrix of the Lagrangian function for the problem decoded into OUTSDIF.d in the constrained minimization case. The matrix is stored in sparse \"coordinate\" format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cdimsh\n\n\n\n\n\nUsage:\n\n\ncdimsh(io_err, nnzh)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cdimsj\n \n \nMethod\n.\n\n\ncdimsj\n\n\nThe cdimsj subroutine determines the number of nonzero elements required to store the matrix of gradients of the objective function and constraint functions for the problem decoded into OUTSDIF.d in the constrained minimization case. The matrix is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cdimsj\n\n\n\n\n\nUsage:\n\n\ncdimsj(io_err, nnzj)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nnnzj:    [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ceh\n \n \nMethod\n.\n\n\nceh\n\n\nThe ceh subroutine evaluates the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded into OUTSDIF.d at the point (x,y)= (X,Y). This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element He involves a small subset of the rows of the Hessian matrix. The problem under consideration consists in minimizing (or maximizing) an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ceh\n\n\n\n\n\nUsage:\n\n\nceh(io_err, n, m, x, y, ne, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row,\n\n\n\n\n\nhe_row, lhe_val, he_val, byrows)\n\n\n\n\nio_err:     [OUT] Array{Cint, 1}\n\n\nn:          [IN] Array{Cint, 1}\n\n\nm:          [IN] Array{Cint, 1}\n\n\nx:          [IN] Array{Cdouble, 1}\n\n\ny:          [IN] Array{Cdouble, 1}\n\n\nne:         [OUT] Array{Cint, 1}\n\n\nlhe_ptr:    [IN] Array{Cint, 1}\n\n\nhe_row_ptr: [OUT] Array{Cint, 1}\n\n\nhe_val_ptr: [OUT] Array{Cint, 1}\n\n\nlhe_row:    [IN] Array{Cint, 1}\n\n\nhe_row:     [OUT] Array{Cint, 1}\n\n\nlhe_val:    [IN] Array{Cint, 1}\n\n\nhe_val:     [OUT] Array{Cdouble, 1}\n\n\nbyrows:     [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cfn\n \n \nMethod\n.\n\n\ncfn\n\n\nThe cfn subroutine evaluates the value of the objective function and general constraint functions of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cfn\n\n\n\n\n\nUsage:\n\n\ncfn(io_err, n, m, x, f, c)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nf:       [OUT] Array{Cdouble, 1}\n\n\nc:       [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.cgr\n \n \nMethod\n.\n\n\ncgr\n\n\nThe cgr subroutine evaluates the gradients of the general constraints and of either the objective function f(x) or the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cgr\n\n\n\n\n\nUsage:\n\n\ncgr(io_err, n, m, x, y, grlagf, g, jtrans, lj1, lj2, j_val)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\ngrlagf:  [IN] Array{Cint, 1}\n\n\ng:       [OUT] Array{Cdouble, 1}\n\n\njtrans:  [IN] Array{Cint, 1}\n\n\nlj1:     [IN] Array{Cint, 1}\n\n\nlj2:     [IN] Array{Cint, 1}\n\n\nj_val:   [OUT] Array{Cdouble, 2}\n\n\n\n\n#\n\n\nCUTEst.cgrdh\n \n \nMethod\n.\n\n\ncgrdh\n\n\nThe cgrdh subroutine evaluates the gradients of the general constraints and of either the objective function f(x) or the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). It also evaluates the Hessian matrix of the Lagrangian function at (x,y). The gradients and matrices are stored in a dense format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cgrdh\n\n\n\n\n\nUsage:\n\n\ncgrdh(io_err, n, m, x, y, grlagf, g, jtrans, lj1, lj2, j_val, lh1, h_val)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\ngrlagf:  [IN] Array{Cint, 1}\n\n\ng:       [OUT] Array{Cdouble, 1}\n\n\njtrans:  [IN] Array{Cint, 1}\n\n\nlj1:     [IN] Array{Cint, 1}\n\n\nlj2:     [IN] Array{Cint, 1}\n\n\nj_val:   [OUT] Array{Cdouble, 2}\n\n\nlh1:     [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 2}\n\n\n\n\n#\n\n\nCUTEst.chcprod\n \n \nMethod\n.\n\n\nchcprod\n\n\nThe chcprod subroutine forms the product of a vector with the Hessian matrix of the constraint part of the Lagrangian function yTc(x) of the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_chcprod\n\n\n\n\n\nUsage:\n\n\nchcprod(io_err, n, m, goth, x, y, vector, result)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\ngoth:    [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\nvector:  [IN] Array{Cdouble, 1}\n\n\nresult:  [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.chprod\n \n \nMethod\n.\n\n\nchprod\n\n\nThe chprod subroutine forms the product of a vector with the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_chprod\n\n\n\n\n\nUsage:\n\n\nchprod(io_err, n, m, goth, x, y, vector, result)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\ngoth:    [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\nvector:  [IN] Array{Cdouble, 1}\n\n\nresult:  [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.cidh\n \n \nMethod\n.\n\n\ncidh\n\n\nThe cidh subroutine evaluates the Hessian matrix of either the objective function or a constraint function for the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient. The matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cidh\n\n\n\n\n\nUsage:\n\n\ncidh(io_err, n, x, iprob, lh1, h)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\niprob:   [IN] Array{Cint, 1}\n\n\nlh1:     [IN] Array{Cint, 1}\n\n\nh:       [OUT] Array{Cdouble, 2}\n\n\n\n\n#\n\n\nCUTEst.cish\n \n \nMethod\n.\n\n\ncish\n\n\nThe cish subroutine evaluates the Hessian of a particular constraint function or the objective function for the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient. The matrix is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cish\n\n\n\n\n\nUsage:\n\n\ncish(io_err, n, x, iprob, nnzh, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\niprob:   [IN] Array{Cint, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\nlh:      [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 1}\n\n\nh_row:   [OUT] Array{Cint, 1}\n\n\nh_col:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cjprod\n \n \nMethod\n.\n\n\ncjprod\n\n\nThe cjprod subroutine forms the product of a vector with the Jacobian matrix, or with its transpose, of the constraint functions of the problem decoded from a SIF file by the script sifdecoder evaluated at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cjprod\n\n\n\n\n\nUsage:\n\n\ncjprod(io_err, n, m, gotj, jtrans, x, vector, lvector, result, lresult)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\ngotj:    [IN] Array{Cint, 1}\n\n\njtrans:  [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nvector:  [IN] Array{Cdouble, 1}\n\n\nlvector: [IN] Array{Cint, 1}\n\n\nresult:  [OUT] Array{Cdouble, 1}\n\n\nlresult: [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.clfg\n \n \nMethod\n.\n\n\nclfg\n\n\nThe clfg subroutine evaluates the value of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (X,Y), and possibly its gradient. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_clfg\n\n\n\n\n\nUsage:\n\n\nclfg(io_err, n, m, x, y, f, g, grad)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\nf:       [OUT] Array{Cdouble, 1}\n\n\ng:       [OUT] Array{Cdouble, 1}\n\n\ngrad:    [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cnames\n \n \nMethod\n.\n\n\ncnames\n\n\nThe cnames subroutine obtains the names of the problem, its variables and general constraints. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cnames\n\n\n\n\n\nUsage:\n\n\ncnames(io_err, n, m, pname, vname, cname)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\npname:   [OUT] Array{Cchar, 1}\n\n\nvname:   [OUT] Array{Cchar, 1}\n\n\ncname:   [OUT] Array{Cchar, 1}\n\n\n\n\n#\n\n\nCUTEst.cofg\n \n \nMethod\n.\n\n\ncofg\n\n\nThe cofg subroutine evaluates the value of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cofg\n\n\n\n\n\nUsage:\n\n\ncofg(io_err, n, x, f, g, grad)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nf:       [OUT] Array{Cdouble, 1}\n\n\ng:       [OUT] Array{Cdouble, 1}\n\n\ngrad:    [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cofsg\n \n \nMethod\n.\n\n\ncofsg\n\n\nThe cofsg subroutine evaluates the value of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cofsg\n\n\n\n\n\nUsage:\n\n\ncofsg(io_err, n, x, f, nnzg, lg, g_val, g_var, grad)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nf:       [OUT] Array{Cdouble, 1}\n\n\nnnzg:    [OUT] Array{Cint, 1}\n\n\nlg:      [IN] Array{Cint, 1}\n\n\ng_val:   [OUT] Array{Cdouble, 1}\n\n\ng_var:   [OUT] Array{Cint, 1}\n\n\ngrad:    [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.connames\n \n \nMethod\n.\n\n\nconnames\n\n\nThe connames subroutine obtains the names of the general constraints of the problem. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_connames\n\n\n\n\n\nUsage:\n\n\nconnames(io_err, m, cname)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\ncname:   [OUT] Array{Cchar, 1}\n\n\n\n\n#\n\n\nCUTEst.creport\n \n \nMethod\n.\n\n\ncreport\n\n\nThe creport subroutine obtains statistics concerning function evaluation and CPU time used for constrained optimization in a standardized format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_creport\n\n\n\n\n\nUsage:\n\n\ncreport(io_err, calls, time)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\ncalls:   [OUT] Array{Cdouble, 1}\n\n\ntime:    [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.csetup\n \n \nMethod\n.\n\n\ncsetup\n\n\nThe csetup subroutine sets up the correct data structures for subsequent computations on the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_csetup\n\n\n\n\n\nUsage:\n\n\ncsetup(io_err, input, out, io_buffer, n, m, x, x_l, x_u, y, c_l, c_u, equatn,\n\n\n\n\n\nlinear, e_order, l_order, v_order)\n\n\n\n\nio_err:    [OUT] Array{Cint, 1}\n\n\ninput:     [IN] Array{Cint, 1}\n\n\nout:       [IN] Array{Cint, 1}\n\n\nio_buffer: [IN] Array{Cint, 1}\n\n\nn:         [IN] Array{Cint, 1}\n\n\nm:         [IN] Array{Cint, 1}\n\n\nx:         [OUT] Array{Cdouble, 1}\n\n\nx_l:       [OUT] Array{Cdouble, 1}\n\n\nx_u:       [OUT] Array{Cdouble, 1}\n\n\ny:         [OUT] Array{Cdouble, 1}\n\n\nc_l:       [OUT] Array{Cdouble, 1}\n\n\nc_u:       [OUT] Array{Cdouble, 1}\n\n\nequatn:    [OUT] Array{Cint, 1}\n\n\nlinear:    [OUT] Array{Cint, 1}\n\n\ne_order:   [IN] Array{Cint, 1}\n\n\nl_order:   [IN] Array{Cint, 1}\n\n\nv_order:   [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.csgr\n \n \nMethod\n.\n\n\ncsgr\n\n\nThe csgr subroutine evaluates the gradients of the general constraints and of either the objective function or the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). It also evaluates the Hessian matrix of the Lagrangian function at (x,y). The gradients are stored in a sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_csgr\n\n\n\n\n\nUsage:\n\n\ncsgr(io_err, n, m, x, y, grlagf, nnzj, lj, j_val, j_var, j_fun)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\ngrlagf:  [IN] Array{Cint, 1}\n\n\nnnzj:    [OUT] Array{Cint, 1}\n\n\nlj:      [IN] Array{Cint, 1}\n\n\nj_val:   [OUT] Array{Cdouble, 1}\n\n\nj_var:   [OUT] Array{Cint, 1}\n\n\nj_fun:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.csgreh\n \n \nMethod\n.\n\n\ncsgreh\n\n\nThe csgreh subroutine evaluates both the gradients of the general constraint functions and the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded into OUTSDIF.d at the point (x,y)= (X,Y). This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element He involves a small subset of the rows of the Hessian matrix. The subroutine also obtains the gradient of either the objective function or the Lagrangian function, stored in a sparse format. The problem under consideration consists in minimizing (or maximizing) an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_csgreh\n\n\n\n\n\nUsage:\n\n\ncsgreh(io_err, n, m, x, y, grlagf, nnzj, lj, j_val, j_var, j_fun, ne,\n\n\n\n\n\nlhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\nio_err:     [OUT] Array{Cint, 1}\n\n\nn:          [IN] Array{Cint, 1}\n\n\nm:          [IN] Array{Cint, 1}\n\n\nx:          [IN] Array{Cdouble, 1}\n\n\ny:          [IN] Array{Cdouble, 1}\n\n\ngrlagf:     [IN] Array{Cint, 1}\n\n\nnnzj:       [OUT] Array{Cint, 1}\n\n\nlj:         [IN] Array{Cint, 1}\n\n\nj_val:      [OUT] Array{Cdouble, 1}\n\n\nj_var:      [OUT] Array{Cint, 1}\n\n\nj_fun:      [OUT] Array{Cint, 1}\n\n\nne:         [OUT] Array{Cint, 1}\n\n\nlhe_ptr:    [IN] Array{Cint, 1}\n\n\nhe_row_ptr: [OUT] Array{Cint, 1}\n\n\nhe_val_ptr: [OUT] Array{Cint, 1}\n\n\nlhe_row:    [IN] Array{Cint, 1}\n\n\nhe_row:     [OUT] Array{Cint, 1}\n\n\nlhe_val:    [IN] Array{Cint, 1}\n\n\nhe_val:     [OUT] Array{Cdouble, 1}\n\n\nbyrows:     [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.csgrsh\n \n \nMethod\n.\n\n\ncsgrsh\n\n\nThe csgrsh subroutine evaluates the gradients of the general constraints, the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) and the gradient of either the objective function or the Lagrangian corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The data is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_csgrsh\n\n\n\n\n\nUsage:\n\n\ncsgrsh(io_err, n, m, x, y, grlagf, nnzj, lj, j_val, j_var, j_fun, nnzh, lh,\n\n\n\n\n\nh_val, h_row, h_col)\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\ngrlagf:  [IN] Array{Cint, 1}\n\n\nnnzj:    [OUT] Array{Cint, 1}\n\n\nlj:      [IN] Array{Cint, 1}\n\n\nj_val:   [OUT] Array{Cdouble, 1}\n\n\nj_var:   [OUT] Array{Cint, 1}\n\n\nj_fun:   [OUT] Array{Cint, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\nlh:      [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 1}\n\n\nh_row:   [OUT] Array{Cint, 1}\n\n\nh_col:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.csh\n \n \nMethod\n.\n\n\ncsh\n\n\nThe csh subroutine evaluates the Hessian of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The matrix is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_csh\n\n\n\n\n\nUsage:\n\n\ncsh(io_err, n, m, x, y, nnzh, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\nlh:      [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 1}\n\n\nh_row:   [OUT] Array{Cint, 1}\n\n\nh_col:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cshc\n \n \nMethod\n.\n\n\ncshc\n\n\nThe cshc subroutine evaluates the Hessian matrix of the constraint part of the Lagrangian function yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The matrix is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cshc\n\n\n\n\n\nUsage:\n\n\ncshc(io_err, n, m, x, y, nnzh, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nm:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ny:       [IN] Array{Cdouble, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\nlh:      [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 1}\n\n\nh_row:   [OUT] Array{Cint, 1}\n\n\nh_col:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cshcprod\n \n \nMethod\n.\n\n\ncshcprod\n\n\nThe cshcprod subroutine forms the product of a sparse vector with the Hessian matrix of the constraint part of the Lagrangian function yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cshcprod\n\n\n\n\n\nUsage:\n\n\ncshcprod(io_err, n, m, goth, x, y, nnz_vector, index_nz_vector, vector,\n\n\n\n\n\nnnz_result, index_nz_result, result)\n\n\n\n\nio_err:          [OUT] Array{Cint, 1}\n\n\nn:               [IN] Array{Cint, 1}\n\n\nm:               [IN] Array{Cint, 1}\n\n\ngoth:            [IN] Array{Cint, 1}\n\n\nx:               [IN] Array{Cdouble, 1}\n\n\ny:               [IN] Array{Cdouble, 1}\n\n\nnnz_vector:      [IN] Array{Cint, 1}\n\n\nindex_nz_vector: [IN] Array{Cint, 1}\n\n\nvector:          [IN] Array{Cdouble, 1}\n\n\nnnz_result:      [OUT] Array{Cint, 1}\n\n\nindex_nz_result: [OUT] Array{Cint, 1}\n\n\nresult:          [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.cshp\n \n \nMethod\n.\n\n\ncshp\n\n\nThe cshp subroutine evaluates the sparsity pattern of the Hessian of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem, decoded from a SIF file by the script sifdecoder, in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cshp\n\n\n\n\n\nUsage:\n\n\ncshp(io_err, n, nnzh, lh, h_row, h_col)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\nlh:      [IN] Array{Cint, 1}\n\n\nh_row:   [OUT] Array{Cint, 1}\n\n\nh_col:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cshprod\n \n \nMethod\n.\n\n\ncshprod\n\n\nThe cshprod subroutine forms the product of a sparse vector with the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cshprod\n\n\n\n\n\nUsage:\n\n\ncshprod(io_err, n, m, goth, x, y, nnz_vector, index_nz_vector, vector,\n\n\n\n\n\nnnz_result, index_nz_result, result)\n\n\n\n\nio_err:          [OUT] Array{Cint, 1}\n\n\nn:               [IN] Array{Cint, 1}\n\n\nm:               [IN] Array{Cint, 1}\n\n\ngoth:            [IN] Array{Cint, 1}\n\n\nx:               [IN] Array{Cdouble, 1}\n\n\ny:               [IN] Array{Cdouble, 1}\n\n\nnnz_vector:      [IN] Array{Cint, 1}\n\n\nindex_nz_vector: [IN] Array{Cint, 1}\n\n\nvector:          [IN] Array{Cdouble, 1}\n\n\nnnz_result:      [OUT] Array{Cint, 1}\n\n\nindex_nz_result: [OUT] Array{Cint, 1}\n\n\nresult:          [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.csjprod\n \n \nMethod\n.\n\n\ncsjprod\n\n\nThe csjprod subroutine forms the product of a sparse vector with the Jacobian matrix, or with its transpose, of the constraint functions of the problem decoded from a SIF file by the script sifdecoder evaluated at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_csjprod\n\n\n\n\n\nUsage:\n\n\ncsjprod(io_err, n, m, gotj, jtrans, x, nnz_vector, index_nz_vector, vector,\n\n\n\n\n\nlvector, nnz_result, index_nz_result, result, lresult)\n\n\n\n\nio_err:          [OUT] Array{Cint, 1}\n\n\nn:               [IN] Array{Cint, 1}\n\n\nm:               [IN] Array{Cint, 1}\n\n\ngotj:            [IN] Array{Cint, 1}\n\n\njtrans:          [IN] Array{Cint, 1}\n\n\nx:               [IN] Array{Cdouble, 1}\n\n\nnnz_vector:      [IN] Array{Cint, 1}\n\n\nindex_nz_vector: [IN] Array{Cint, 1}\n\n\nvector:          [IN] Array{Cdouble, 1}\n\n\nlvector:         [IN] Array{Cint, 1}\n\n\nnnz_result:      [OUT] Array{Cint, 1}\n\n\nindex_nz_result: [OUT] Array{Cint, 1}\n\n\nresult:          [OUT] Array{Cdouble, 1}\n\n\nlresult:         [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cstats\n \n \nMethod\n.\n\n\ncstats\n\n\ncstats(io_err, nonlinear_variables_objective,\n\n\n\n\n\nnonlinear_variables_constraints, equality_constraints, linear_constraints)\n\n\n\n\nio_err:                          [OUT] Array{Cint, 1}\n\n\nnonlinear_variables_objective:   [OUT] Array{Cint, 1}\n\n\nnonlinear_variables_constraints: [OUT] Array{Cint, 1}\n\n\nequality_constraints:            [OUT] Array{Cint, 1}\n\n\nlinear_constraints:              [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cterminate\n \n \nMethod\n.\n\n\ncterminate\n\n\nThe uterminate subroutine deallocates all workspace arrays created since the last call to csetup.\n\n\nFor more information, run the shell command\n\n\nman cutest_cterminate\n\n\n\n\n\nUsage:\n\n\ncterminate(io_err)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.cvartype\n \n \nMethod\n.\n\n\ncvartype\n\n\nThe cvartype subroutine determines the type (continuous, 0-1, integer) of each variable involved in the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_cvartype\n\n\n\n\n\nUsage:\n\n\ncvartype(io_err, n, x_type)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx_type:  [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.pname\n \n \nMethod\n.\n\n\npname\n\n\nThe pname subroutine obtains the name of the problem directly from the datafile OUTSDIF.d that was created by the script sifdecoder when decoding a SIF file. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_pname\n\n\n\n\n\nUsage:\n\n\npname(io_err, input, pname)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\ninput:   [IN] Array{Cint, 1}\n\n\npname:   [OUT] Array{Cchar, 1}\n\n\n\n\n#\n\n\nCUTEst.probname\n \n \nMethod\n.\n\n\nprobname\n\n\nThe probname subroutine obtains the name of the problem. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_probname\n\n\n\n\n\nUsage:\n\n\nprobname(io_err, pname)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\npname:   [OUT] Array{Cchar, 1}\n\n\n\n\n#\n\n\nCUTEst.ubandh\n \n \nMethod\n.\n\n\nubandh\n\n\nThe ubandh subroutine extracts the elements which lie within a band of given semi-bandwidth out of the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ubandh\n\n\n\n\n\nUsage:\n\n\nubandh(io_err, n, x, semibandwidth, h_band, lbandh, max_semibandwidth)\n\n\n\n\n\n\n\nio_err:            [OUT] Array{Cint, 1}\n\n\nn:                 [IN] Array{Cint, 1}\n\n\nx:                 [IN] Array{Cdouble, 1}\n\n\nsemibandwidth:     [IN] Array{Cint, 1}\n\n\nh_band:            [OUT] Array{Cdouble, 2}\n\n\nlbandh:            [IN] Array{Cint, 1}\n\n\nmax_semibandwidth: [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.udh\n \n \nMethod\n.\n\n\nudh\n\n\nThe udh subroutine evaluates the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_udh\n\n\n\n\n\nUsage:\n\n\nudh(io_err, n, x, lh1, h)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nlh1:     [IN] Array{Cint, 1}\n\n\nh:       [OUT] Array{Cdouble, 2}\n\n\n\n\n#\n\n\nCUTEst.udimen\n \n \nMethod\n.\n\n\nudimen\n\n\nThe udimen subroutine discovers how many variables are involved in the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_udimen\n\n\n\n\n\nUsage:\n\n\nudimen(io_err, input, n)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\ninput:   [IN] Array{Cint, 1}\n\n\nn:       [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.udimse\n \n \nMethod\n.\n\n\nudimse\n\n\nThe udimse subroutine determine the number of nonzeros required to store the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element H_i involves a small subset of the rows of the Hessian matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_udimse\n\n\n\n\n\nUsage:\n\n\nudimse(io_err, ne, he_val_ne, he_row_ne)\n\n\n\n\n\n\n\nio_err:    [OUT] Array{Cint, 1}\n\n\nne:        [OUT] Array{Cint, 1}\n\n\nhe_val_ne: [OUT] Array{Cint, 1}\n\n\nhe_row_ne: [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.udimsh\n \n \nMethod\n.\n\n\nudimsh\n\n\nThe udimsh subroutine determine the number of nonzeros required to store the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_udimsh\n\n\n\n\n\nUsage:\n\n\nudimsh(io_err, nnzh)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ueh\n \n \nMethod\n.\n\n\nueh\n\n\nThe ueh subroutine evaluates the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element He involves a small subset of the rows of the Hessian matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ueh\n\n\n\n\n\nUsage:\n\n\nueh(io_err, n, x, ne, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row,\n\n\n\n\n\nlhe_val, he_val, byrows)\n\n\n\n\nio_err:     [OUT] Array{Cint, 1}\n\n\nn:          [IN] Array{Cint, 1}\n\n\nx:          [IN] Array{Cdouble, 1}\n\n\nne:         [OUT] Array{Cint, 1}\n\n\nlhe_ptr:    [IN] Array{Cint, 1}\n\n\nhe_row_ptr: [OUT] Array{Cint, 1}\n\n\nhe_val_ptr: [OUT] Array{Cint, 1}\n\n\nlhe_row:    [IN] Array{Cint, 1}\n\n\nhe_row:     [OUT] Array{Cint, 1}\n\n\nlhe_val:    [IN] Array{Cint, 1}\n\n\nhe_val:     [OUT] Array{Cdouble, 1}\n\n\nbyrows:     [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ufn\n \n \nMethod\n.\n\n\nufn\n\n\nThe ufn subroutine evaluates the value of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ufn\n\n\n\n\n\nUsage:\n\n\nufn(io_err, n, x, f)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nf:       [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.ugr\n \n \nMethod\n.\n\n\nugr\n\n\nThe ugr subroutine evaluates the gradient of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ugr\n\n\n\n\n\nUsage:\n\n\nugr(io_err, n, x, g)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ng:       [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.ugrdh\n \n \nMethod\n.\n\n\nugrdh\n\n\nThe ugrdh subroutine evaluates the gradient and Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ugrdh\n\n\n\n\n\nUsage:\n\n\nugrdh(io_err, n, x, g, lh1, h)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ng:       [OUT] Array{Cdouble, 1}\n\n\nlh1:     [IN] Array{Cint, 1}\n\n\nh:       [OUT] Array{Cdouble, 2}\n\n\n\n\n#\n\n\nCUTEst.ugreh\n \n \nMethod\n.\n\n\nugreh\n\n\nThe ugreh subroutine evaluates the gradient and Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element H sub e involves a small subset of the rows of the Hessian matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ugreh\n\n\n\n\n\nUsage:\n\n\nugreh(io_err, n, x, g, ne, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row,\n\n\n\n\n\nlhe_val, he_val, byrows)\n\n\n\n\nio_err:     [OUT] Array{Cint, 1}\n\n\nn:          [IN] Array{Cint, 1}\n\n\nx:          [IN] Array{Cdouble, 1}\n\n\ng:          [OUT] Array{Cdouble, 1}\n\n\nne:         [OUT] Array{Cint, 1}\n\n\nlhe_ptr:    [IN] Array{Cint, 1}\n\n\nhe_row_ptr: [OUT] Array{Cint, 1}\n\n\nhe_val_ptr: [OUT] Array{Cint, 1}\n\n\nlhe_row:    [IN] Array{Cint, 1}\n\n\nhe_row:     [OUT] Array{Cint, 1}\n\n\nlhe_val:    [IN] Array{Cint, 1}\n\n\nhe_val:     [OUT] Array{Cdouble, 1}\n\n\nbyrows:     [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ugrsh\n \n \nMethod\n.\n\n\nugrsh\n\n\nThe ugrsh subroutine evaluates the gradient and Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ugrsh\n\n\n\n\n\nUsage:\n\n\nugrsh(io_err, n, x, g, nnzh, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\ng:       [OUT] Array{Cdouble, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\nlh:      [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 1}\n\n\nh_row:   [OUT] Array{Cint, 1}\n\n\nh_col:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.uhprod\n \n \nMethod\n.\n\n\nuhprod\n\n\nThe uhprod subroutine forms the product of a vector with the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_uhprod\n\n\n\n\n\nUsage:\n\n\nuhprod(io_err, n, goth, x, vector, result)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\ngoth:    [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nvector:  [IN] Array{Cdouble, 1}\n\n\nresult:  [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.unames\n \n \nMethod\n.\n\n\nunames\n\n\nThe unames subroutine obtains the names of the problem and its variables. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_unames\n\n\n\n\n\nUsage:\n\n\nunames(io_err, n, pname, vname)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\npname:   [OUT] Array{Cchar, 1}\n\n\nvname:   [OUT] Array{Cchar, 1}\n\n\n\n\n#\n\n\nCUTEst.uofg\n \n \nMethod\n.\n\n\nuofg\n\n\nThe uofg subroutine evaluates the value of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_uofg\n\n\n\n\n\nUsage:\n\n\nuofg(io_err, n, x, f, g, grad)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nf:       [OUT] Array{Cdouble, 1}\n\n\ng:       [OUT] Array{Cdouble, 1}\n\n\ngrad:    [IN] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ureport\n \n \nMethod\n.\n\n\nureport\n\n\nThe ureport subroutine obtains statistics concerning function evaluation and CPU time used for unconstrained or bound-constrained optimization in a standardized format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ureport\n\n\n\n\n\nUsage:\n\n\nureport(io_err, calls, time)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\ncalls:   [OUT] Array{Cdouble, 1}\n\n\ntime:    [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.usetup\n \n \nMethod\n.\n\n\nusetup\n\n\nThe usetup subroutine sets up the correct data structures for subsequent computations in the case where the only possible constraints are bound constraints. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_usetup\n\n\n\n\n\nUsage:\n\n\nusetup(io_err, input, out, io_buffer, n, x, x_l, x_u)\n\n\n\n\n\n\n\nio_err:    [OUT] Array{Cint, 1}\n\n\ninput:     [IN] Array{Cint, 1}\n\n\nout:       [IN] Array{Cint, 1}\n\n\nio_buffer: [IN] Array{Cint, 1}\n\n\nn:         [IN] Array{Cint, 1}\n\n\nx:         [OUT] Array{Cdouble, 1}\n\n\nx_l:       [OUT] Array{Cdouble, 1}\n\n\nx_u:       [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.ush\n \n \nMethod\n.\n\n\nush\n\n\nThe ush subroutine evaluates the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ush\n\n\n\n\n\nUsage:\n\n\nush(io_err, n, x, nnzh, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx:       [IN] Array{Cdouble, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\nlh:      [IN] Array{Cint, 1}\n\n\nh_val:   [OUT] Array{Cdouble, 1}\n\n\nh_row:   [OUT] Array{Cint, 1}\n\n\nh_col:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ushp\n \n \nMethod\n.\n\n\nushp\n\n\nThe ushp subroutine evaluates the sparsity pattern of the Hessian matrix of the objective function of the problem, decoded from a SIF file by the script sifdecoder, in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ushp\n\n\n\n\n\nUsage:\n\n\nushp(io_err, n, nnzh, lh, h_row, h_col)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nnnzh:    [OUT] Array{Cint, 1}\n\n\nlh:      [IN] Array{Cint, 1}\n\n\nh_row:   [OUT] Array{Cint, 1}\n\n\nh_col:   [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.ushprod\n \n \nMethod\n.\n\n\nushprod\n\n\nThe ushprod subroutine forms the product of a sparse vector with the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_ushprod\n\n\n\n\n\nUsage:\n\n\nushprod(io_err, n, goth, x, nnz_vector, index_nz_vector, vector, nnz_result,\n\n\n\n\n\nindex_nz_result, result)\n\n\n\n\nio_err:          [OUT] Array{Cint, 1}\n\n\nn:               [IN] Array{Cint, 1}\n\n\ngoth:            [IN] Array{Cint, 1}\n\n\nx:               [IN] Array{Cdouble, 1}\n\n\nnnz_vector:      [IN] Array{Cint, 1}\n\n\nindex_nz_vector: [IN] Array{Cint, 1}\n\n\nvector:          [IN] Array{Cdouble, 1}\n\n\nnnz_result:      [OUT] Array{Cint, 1}\n\n\nindex_nz_result: [OUT] Array{Cint, 1}\n\n\nresult:          [OUT] Array{Cdouble, 1}\n\n\n\n\n#\n\n\nCUTEst.uterminate\n \n \nMethod\n.\n\n\nuterminate\n\n\nThe uterminate subroutine deallocates all workspace arrays created since the last call to usetup.\n\n\nFor more information, run the shell command\n\n\nman cutest_uterminate\n\n\n\n\n\nUsage:\n\n\nuterminate(io_err)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.uvartype\n \n \nMethod\n.\n\n\nuvartype\n\n\nThe uvartype subroutine determines the type (continuous, 0-1, integer) of each variable involved in the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_uvartype\n\n\n\n\n\nUsage:\n\n\nuvartype(io_err, n, x_type)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nx_type:  [OUT] Array{Cint, 1}\n\n\n\n\n#\n\n\nCUTEst.varnames\n \n \nMethod\n.\n\n\nvarnames\n\n\nThe varnames subroutine obtains the names of the problem variables. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\n\nFor more information, run the shell command\n\n\nman cutest_varnames\n\n\n\n\n\nUsage:\n\n\nvarnames(io_err, n, vname)\n\n\n\n\n\n\n\nio_err:  [OUT] Array{Cint, 1}\n\n\nn:       [IN] Array{Cint, 1}\n\n\nvname:   [OUT] Array{Cchar, 1}\n\n\n\n\n#\n\n\nCUTEst.ccfg!\n \n \nMethod\n.\n\n\nccfg!(nlp, x, c, jtrans, lcjac1, lcjac2, cjac, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nc:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlcjac1:  [IN] Int\n\n\nlcjac2:  [IN] Int\n\n\ncjac:    [OUT] Array{Float64, 2}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccfg!\n \n \nMethod\n.\n\n\nccfg!(n, m, x, c, jtrans, lcjac1, lcjac2, cjac, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nc:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlcjac1:  [IN] Int\n\n\nlcjac2:  [IN] Int\n\n\ncjac:    [OUT] Array{Float64, 2}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccfg\n \n \nMethod\n.\n\n\nc, cjac = ccfg(nlp, x, jtrans, lcjac1, lcjac2, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nc:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlcjac1:  [IN] Int\n\n\nlcjac2:  [IN] Int\n\n\ncjac:    [OUT] Array{Float64, 2}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccfg\n \n \nMethod\n.\n\n\nc, cjac = ccfg(n, m, x, jtrans, lcjac1, lcjac2, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nc:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlcjac1:  [IN] Int\n\n\nlcjac2:  [IN] Int\n\n\ncjac:    [OUT] Array{Float64, 2}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccfsg!\n \n \nMethod\n.\n\n\nnnzj = ccfsg!(nlp, x, c, j_val, j_var, j_fun, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nc:       [OUT] Array{Float64, 1}\n\n\nnnzj:    [OUT] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccfsg!\n \n \nMethod\n.\n\n\nnnzj = ccfsg!(n, m, x, c, lj, j_val, j_var, j_fun, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nc:       [OUT] Array{Float64, 1}\n\n\nnnzj:    [OUT] Int\n\n\nlj:      [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccfsg\n \n \nMethod\n.\n\n\nc, nnzj, j_val, j_var, j_fun = ccfsg(nlp, x, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nc:       [OUT] Array{Float64, 1}\n\n\nnnzj:    [OUT] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccfsg\n \n \nMethod\n.\n\n\nc, nnzj, j_val, j_var, j_fun = ccfsg(n, m, x, lj, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nc:       [OUT] Array{Float64, 1}\n\n\nnnzj:    [OUT] Int\n\n\nlj:      [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cchprods!\n \n \nMethod\n.\n\n\ncchprods!(nlp, goth, x, vector, lchp, chp_val, chp_ind, chp_ptr)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nlchp:    [IN] Int\n\n\nchp_val: [OUT] Array{Float64, 1}\n\n\nchp_ind: [IN] Array{Int, 1}\n\n\nchp_ptr: [IN] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cchprods!\n \n \nMethod\n.\n\n\ncchprods!(n, m, goth, x, vector, lchp, chp_val, chp_ind, chp_ptr)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nlchp:    [IN] Int\n\n\nchp_val: [OUT] Array{Float64, 1}\n\n\nchp_ind: [IN] Array{Int, 1}\n\n\nchp_ptr: [IN] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cchprods\n \n \nMethod\n.\n\n\nchp_val = cchprods(nlp, goth, x, vector, lchp, chp_ind, chp_ptr)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nlchp:    [IN] Int\n\n\nchp_val: [OUT] Array{Float64, 1}\n\n\nchp_ind: [IN] Array{Int, 1}\n\n\nchp_ptr: [IN] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cchprods\n \n \nMethod\n.\n\n\nchp_val = cchprods(n, m, goth, x, vector, lchp, chp_ind, chp_ptr)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nlchp:    [IN] Int\n\n\nchp_val: [OUT] Array{Float64, 1}\n\n\nchp_ind: [IN] Array{Int, 1}\n\n\nchp_ptr: [IN] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ccifg!\n \n \nMethod\n.\n\n\nci = ccifg!(nlp, icon, x, gci, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nicon:    [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nci:      [OUT] Float64\n\n\ngci:     [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccifg!\n \n \nMethod\n.\n\n\nci = ccifg!(n, icon, x, gci, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nicon:    [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nci:      [OUT] Float64\n\n\ngci:     [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccifg\n \n \nMethod\n.\n\n\nci, gci = ccifg(nlp, icon, x, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nicon:    [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nci:      [OUT] Float64\n\n\ngci:     [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccifg\n \n \nMethod\n.\n\n\nci, gci = ccifg(n, icon, x, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nicon:    [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nci:      [OUT] Float64\n\n\ngci:     [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccifsg!\n \n \nMethod\n.\n\n\nci, nnzgci = ccifsg!(nlp, icon, x, lgci, gci_val, gci_var, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nicon:    [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nci:      [OUT] Float64\n\n\nnnzgci:  [OUT] Int\n\n\nlgci:    [IN] Int\n\n\ngci_val: [OUT] Array{Float64, 1}\n\n\ngci_var: [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccifsg!\n \n \nMethod\n.\n\n\nci, nnzgci = ccifsg!(n, icon, x, lgci, gci_val, gci_var, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nicon:    [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nci:      [OUT] Float64\n\n\nnnzgci:  [OUT] Int\n\n\nlgci:    [IN] Int\n\n\ngci_val: [OUT] Array{Float64, 1}\n\n\ngci_var: [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccifsg\n \n \nMethod\n.\n\n\nci, nnzgci, gci_val, gci_var = ccifsg(nlp, icon, x, lgci, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nicon:    [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nci:      [OUT] Float64\n\n\nnnzgci:  [OUT] Int\n\n\nlgci:    [IN] Int\n\n\ngci_val: [OUT] Array{Float64, 1}\n\n\ngci_var: [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ccifsg\n \n \nMethod\n.\n\n\nci, nnzgci, gci_val, gci_var = ccifsg(n, icon, x, lgci, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nicon:    [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nci:      [OUT] Float64\n\n\nnnzgci:  [OUT] Int\n\n\nlgci:    [IN] Int\n\n\ngci_val: [OUT] Array{Float64, 1}\n\n\ngci_var: [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cdh!\n \n \nMethod\n.\n\n\ncdh!(nlp, x, y, lh1, h_val)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cdh!\n \n \nMethod\n.\n\n\ncdh!(n, m, x, y, lh1, h_val)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cdh\n \n \nMethod\n.\n\n\nh_val = cdh(nlp, x, y, lh1)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cdh\n \n \nMethod\n.\n\n\nh_val = cdh(n, m, x, y, lh1)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cdhc!\n \n \nMethod\n.\n\n\ncdhc!(nlp, x, y, lh1, h_val)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cdhc!\n \n \nMethod\n.\n\n\ncdhc!(n, m, x, y, lh1, h_val)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cdhc\n \n \nMethod\n.\n\n\nh_val = cdhc(nlp, x, y, lh1)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cdhc\n \n \nMethod\n.\n\n\nh_val = cdhc(n, m, x, y, lh1)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cdimchp\n \n \nMethod\n.\n\n\nnnzchp = cdimchp(nlp)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nnnzchp:  [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.cdimchp\n \n \nMethod\n.\n\n\nnnzchp = cdimchp()\n\n\n\n\n\n\n\nnnzchp:  [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.cdimen\n \n \nMethod\n.\n\n\nn, m = cdimen(input)\n\n\n\n\n\n\n\ninput:   [IN] Int\n\n\nn:       [OUT] Int\n\n\nm:       [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.cdimse\n \n \nMethod\n.\n\n\nne, he_val_ne, he_row_ne = cdimse()\n\n\n\n\n\n\n\nne:        [OUT] Int\n\n\nhe_val_ne: [OUT] Int\n\n\nhe_row_ne: [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.cdimsh\n \n \nMethod\n.\n\n\nnnzh = cdimsh()\n\n\n\n\n\n\n\nnnzh:    [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.cdimsj\n \n \nMethod\n.\n\n\nnnzj = cdimsj()\n\n\n\n\n\n\n\nnnzj:    [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.ceh!\n \n \nMethod\n.\n\n\nne = ceh!(nlp, x, y, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\n\n\n\nnlp:        [IN] CUTEstModel\n\n\nx:          [IN] Array{Float64, 1}\n\n\ny:          [IN] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ceh!\n \n \nMethod\n.\n\n\nne = ceh!(n, m, x, y, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\n\n\n\nn:          [IN] Int\n\n\nm:          [IN] Int\n\n\nx:          [IN] Array{Float64, 1}\n\n\ny:          [IN] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ceh\n \n \nMethod\n.\n\n\nne, he_row_ptr, he_val_ptr, he_row, he_val = ceh(nlp, x, y, lhe_ptr, lhe_row, lhe_val, byrows)\n\n\n\n\n\n\n\nnlp:        [IN] CUTEstModel\n\n\nx:          [IN] Array{Float64, 1}\n\n\ny:          [IN] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ceh\n \n \nMethod\n.\n\n\nne, he_row_ptr, he_val_ptr, he_row, he_val = ceh(n, m, x, y, lhe_ptr, lhe_row, lhe_val, byrows)\n\n\n\n\n\n\n\nn:          [IN] Int\n\n\nm:          [IN] Int\n\n\nx:          [IN] Array{Float64, 1}\n\n\ny:          [IN] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cfn!\n \n \nMethod\n.\n\n\nf = cfn!(nlp, x, c)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\nc:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cfn!\n \n \nMethod\n.\n\n\nf = cfn!(n, m, x, c)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\nc:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cfn\n \n \nMethod\n.\n\n\nf, c = cfn(nlp, x)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\nc:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cfn\n \n \nMethod\n.\n\n\nf, c = cfn(n, m, x)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\nc:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cgr!\n \n \nMethod\n.\n\n\ncgr!(nlp, x, y, grlagf, g, jtrans, lj1, lj2, j_val)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\ng:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlj1:     [IN] Int\n\n\nlj2:     [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cgr!\n \n \nMethod\n.\n\n\ncgr!(n, m, x, y, grlagf, g, jtrans, lj1, lj2, j_val)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\ng:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlj1:     [IN] Int\n\n\nlj2:     [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cgr\n \n \nMethod\n.\n\n\ng, j_val = cgr(nlp, x, y, grlagf, jtrans, lj1, lj2)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\ng:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlj1:     [IN] Int\n\n\nlj2:     [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cgr\n \n \nMethod\n.\n\n\ng, j_val = cgr(n, m, x, y, grlagf, jtrans, lj1, lj2)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\ng:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlj1:     [IN] Int\n\n\nlj2:     [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cgrdh!\n \n \nMethod\n.\n\n\ncgrdh!(nlp, x, y, grlagf, g, jtrans, lj1, lj2, j_val, lh1, h_val)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\ng:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlj1:     [IN] Int\n\n\nlj2:     [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 2}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cgrdh!\n \n \nMethod\n.\n\n\ncgrdh!(n, m, x, y, grlagf, g, jtrans, lj1, lj2, j_val, lh1, h_val)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\ng:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlj1:     [IN] Int\n\n\nlj2:     [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 2}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cgrdh\n \n \nMethod\n.\n\n\ng, j_val, h_val = cgrdh(nlp, x, y, grlagf, jtrans, lj1, lj2, lh1)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\ng:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlj1:     [IN] Int\n\n\nlj2:     [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 2}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cgrdh\n \n \nMethod\n.\n\n\ng, j_val, h_val = cgrdh(n, m, x, y, grlagf, jtrans, lj1, lj2, lh1)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\ng:       [OUT] Array{Float64, 1}\n\n\njtrans:  [IN] Bool\n\n\nlj1:     [IN] Int\n\n\nlj2:     [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 2}\n\n\nlh1:     [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.chcprod!\n \n \nMethod\n.\n\n\nchcprod!(nlp, goth, x, y, vector, result)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.chcprod!\n \n \nMethod\n.\n\n\nchcprod!(n, m, goth, x, y, vector, result)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.chcprod\n \n \nMethod\n.\n\n\nresult = chcprod(nlp, goth, x, y, vector)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.chcprod\n \n \nMethod\n.\n\n\nresult = chcprod(n, m, goth, x, y, vector)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.chprod!\n \n \nMethod\n.\n\n\nchprod!(nlp, goth, x, y, vector, result)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.chprod!\n \n \nMethod\n.\n\n\nchprod!(n, m, goth, x, y, vector, result)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.chprod\n \n \nMethod\n.\n\n\nresult = chprod(nlp, goth, x, y, vector)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.chprod\n \n \nMethod\n.\n\n\nresult = chprod(n, m, goth, x, y, vector)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cidh!\n \n \nMethod\n.\n\n\ncidh!(nlp, x, iprob, lh1, h)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\niprob:   [IN] Int\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cidh!\n \n \nMethod\n.\n\n\ncidh!(n, x, iprob, lh1, h)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\niprob:   [IN] Int\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cidh\n \n \nMethod\n.\n\n\nh = cidh(nlp, x, iprob, lh1)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\niprob:   [IN] Int\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cidh\n \n \nMethod\n.\n\n\nh = cidh(n, x, iprob, lh1)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\niprob:   [IN] Int\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.cish!\n \n \nMethod\n.\n\n\nnnzh = cish!(nlp, x, iprob, h_val, h_row, h_col)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\niprob:   [IN] Int\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cish!\n \n \nMethod\n.\n\n\nnnzh = cish!(n, x, iprob, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\niprob:   [IN] Int\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cish\n \n \nMethod\n.\n\n\nnnzh, h_val, h_row, h_col = cish(nlp, x, iprob)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\niprob:   [IN] Int\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cish\n \n \nMethod\n.\n\n\nnnzh, h_val, h_row, h_col = cish(n, x, iprob, lh)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\niprob:   [IN] Int\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cjprod!\n \n \nMethod\n.\n\n\ncjprod!(nlp, gotj, jtrans, x, vector, lvector, result, lresult)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngotj:    [IN] Bool\n\n\njtrans:  [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nlvector: [IN] Int\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\nlresult: [IN] Int\n\n\n\n\n#\n\n\nCUTEst.cjprod!\n \n \nMethod\n.\n\n\ncjprod!(n, m, gotj, jtrans, x, vector, lvector, result, lresult)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\ngotj:    [IN] Bool\n\n\njtrans:  [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nlvector: [IN] Int\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\nlresult: [IN] Int\n\n\n\n\n#\n\n\nCUTEst.cjprod\n \n \nMethod\n.\n\n\nresult = cjprod(nlp, gotj, jtrans, x, vector, lvector, lresult)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngotj:    [IN] Bool\n\n\njtrans:  [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nlvector: [IN] Int\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\nlresult: [IN] Int\n\n\n\n\n#\n\n\nCUTEst.cjprod\n \n \nMethod\n.\n\n\nresult = cjprod(n, m, gotj, jtrans, x, vector, lvector, lresult)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\ngotj:    [IN] Bool\n\n\njtrans:  [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nlvector: [IN] Int\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\nlresult: [IN] Int\n\n\n\n\n#\n\n\nCUTEst.clfg!\n \n \nMethod\n.\n\n\nf = clfg!(nlp, x, y, g, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.clfg!\n \n \nMethod\n.\n\n\nf = clfg!(n, m, x, y, g, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.clfg\n \n \nMethod\n.\n\n\nf, g = clfg(nlp, x, y, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.clfg\n \n \nMethod\n.\n\n\nf, g = clfg(n, m, x, y, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cnames!\n \n \nMethod\n.\n\n\npname = cnames!(nlp, vname, cname)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\npname:   [OUT] UInt8\n\n\nvname:   [OUT] Array{UInt8, 1}\n\n\ncname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.cnames!\n \n \nMethod\n.\n\n\npname = cnames!(n, m, vname, cname)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\npname:   [OUT] UInt8\n\n\nvname:   [OUT] Array{UInt8, 1}\n\n\ncname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.cnames\n \n \nMethod\n.\n\n\npname, vname, cname = cnames(nlp)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\npname:   [OUT] UInt8\n\n\nvname:   [OUT] Array{UInt8, 1}\n\n\ncname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.cnames\n \n \nMethod\n.\n\n\npname, vname, cname = cnames(n, m)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\npname:   [OUT] UInt8\n\n\nvname:   [OUT] Array{UInt8, 1}\n\n\ncname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.cofg!\n \n \nMethod\n.\n\n\nf = cofg!(nlp, x, g, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cofg!\n \n \nMethod\n.\n\n\nf = cofg!(n, x, g, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cofg\n \n \nMethod\n.\n\n\nf, g = cofg(nlp, x, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cofg\n \n \nMethod\n.\n\n\nf, g = cofg(n, x, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cofsg!\n \n \nMethod\n.\n\n\nf, nnzg = cofsg!(nlp, x, lg, g_val, g_var, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\nnnzg:    [OUT] Int\n\n\nlg:      [IN] Int\n\n\ng_val:   [OUT] Array{Float64, 1}\n\n\ng_var:   [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cofsg!\n \n \nMethod\n.\n\n\nf, nnzg = cofsg!(n, x, lg, g_val, g_var, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\nnnzg:    [OUT] Int\n\n\nlg:      [IN] Int\n\n\ng_val:   [OUT] Array{Float64, 1}\n\n\ng_var:   [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cofsg\n \n \nMethod\n.\n\n\nf, nnzg, g_val, g_var = cofsg(nlp, x, lg, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\nnnzg:    [OUT] Int\n\n\nlg:      [IN] Int\n\n\ng_val:   [OUT] Array{Float64, 1}\n\n\ng_var:   [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.cofsg\n \n \nMethod\n.\n\n\nf, nnzg, g_val, g_var = cofsg(n, x, lg, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\nnnzg:    [OUT] Int\n\n\nlg:      [IN] Int\n\n\ng_val:   [OUT] Array{Float64, 1}\n\n\ng_var:   [OUT] Array{Int, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.connames!\n \n \nMethod\n.\n\n\nconnames!(nlp, cname)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ncname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.connames!\n \n \nMethod\n.\n\n\nconnames!(m, cname)\n\n\n\n\n\n\n\nm:       [IN] Int\n\n\ncname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.connames\n \n \nMethod\n.\n\n\ncname = connames(nlp)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ncname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.connames\n \n \nMethod\n.\n\n\ncname = connames(m)\n\n\n\n\n\n\n\nm:       [IN] Int\n\n\ncname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.creport!\n \n \nMethod\n.\n\n\ncreport!(calls, time)\n\n\n\n\n\n\n\ncalls:   [OUT] Array{Float64, 1}\n\n\ntime:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.creport!\n \n \nMethod\n.\n\n\ncreport!(nlp, calls, time)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ncalls:   [OUT] Array{Float64, 1}\n\n\ntime:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.creport\n \n \nMethod\n.\n\n\ncalls, time = creport(nlp)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ncalls:   [OUT] Array{Float64, 1}\n\n\ntime:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.creport\n \n \nMethod\n.\n\n\ncalls, time = creport()\n\n\n\n\n\n\n\ncalls:   [OUT] Array{Float64, 1}\n\n\ntime:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.csetup!\n \n \nMethod\n.\n\n\ncsetup!(input, out, io_buffer, n, m, x, x_l, x_u, y, c_l, c_u, equatn, linear, e_order, l_order, v_order)\n\n\n\n\n\n\n\ninput:     [IN] Int\n\n\nout:       [IN] Int\n\n\nio_buffer: [IN] Int\n\n\nn:         [IN] Int\n\n\nm:         [IN] Int\n\n\nx:         [OUT] Array{Float64, 1}\n\n\nx_l:       [OUT] Array{Float64, 1}\n\n\nx_u:       [OUT] Array{Float64, 1}\n\n\ny:         [OUT] Array{Float64, 1}\n\n\nc_l:       [OUT] Array{Float64, 1}\n\n\nc_u:       [OUT] Array{Float64, 1}\n\n\nequatn:    [OUT] Array{Bool, 1}\n\n\nlinear:    [OUT] Array{Bool, 1}\n\n\ne_order:   [IN] Int\n\n\nl_order:   [IN] Int\n\n\nv_order:   [IN] Int\n\n\n\n\n#\n\n\nCUTEst.csetup\n \n \nMethod\n.\n\n\nx, x_l, x_u, y, c_l, c_u, equatn, linear = csetup(input, out, io_buffer, n, m, e_order, l_order, v_order)\n\n\n\n\n\n\n\ninput:     [IN] Int\n\n\nout:       [IN] Int\n\n\nio_buffer: [IN] Int\n\n\nn:         [IN] Int\n\n\nm:         [IN] Int\n\n\nx:         [OUT] Array{Float64, 1}\n\n\nx_l:       [OUT] Array{Float64, 1}\n\n\nx_u:       [OUT] Array{Float64, 1}\n\n\ny:         [OUT] Array{Float64, 1}\n\n\nc_l:       [OUT] Array{Float64, 1}\n\n\nc_u:       [OUT] Array{Float64, 1}\n\n\nequatn:    [OUT] Array{Bool, 1}\n\n\nlinear:    [OUT] Array{Bool, 1}\n\n\ne_order:   [IN] Int\n\n\nl_order:   [IN] Int\n\n\nv_order:   [IN] Int\n\n\n\n\n#\n\n\nCUTEst.csgr!\n \n \nMethod\n.\n\n\nnnzj = csgr!(nlp, x, y, grlagf, j_val, j_var, j_fun)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\nnnzj:    [OUT] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csgr!\n \n \nMethod\n.\n\n\nnnzj = csgr!(n, m, x, y, grlagf, lj, j_val, j_var, j_fun)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\nnnzj:    [OUT] Int\n\n\nlj:      [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csgr\n \n \nMethod\n.\n\n\nnnzj, j_val, j_var, j_fun = csgr(nlp, x, y, grlagf)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\nnnzj:    [OUT] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csgr\n \n \nMethod\n.\n\n\nnnzj, j_val, j_var, j_fun = csgr(n, m, x, y, grlagf, lj)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\nnnzj:    [OUT] Int\n\n\nlj:      [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csgreh!\n \n \nMethod\n.\n\n\nnnzj, ne = csgreh!(nlp, x, y, grlagf, j_val, j_var, j_fun, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\n\n\n\nnlp:        [IN] CUTEstModel\n\n\nx:          [IN] Array{Float64, 1}\n\n\ny:          [IN] Array{Float64, 1}\n\n\ngrlagf:     [IN] Bool\n\n\nnnzj:       [OUT] Int\n\n\nj_val:      [OUT] Array{Float64, 1}\n\n\nj_var:      [OUT] Array{Int, 1}\n\n\nj_fun:      [OUT] Array{Int, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.csgreh!\n \n \nMethod\n.\n\n\nnnzj, ne = csgreh!(n, m, x, y, grlagf, lj, j_val, j_var, j_fun, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\n\n\n\nn:          [IN] Int\n\n\nm:          [IN] Int\n\n\nx:          [IN] Array{Float64, 1}\n\n\ny:          [IN] Array{Float64, 1}\n\n\ngrlagf:     [IN] Bool\n\n\nnnzj:       [OUT] Int\n\n\nlj:         [IN] Int\n\n\nj_val:      [OUT] Array{Float64, 1}\n\n\nj_var:      [OUT] Array{Int, 1}\n\n\nj_fun:      [OUT] Array{Int, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.csgreh\n \n \nMethod\n.\n\n\nnnzj, j_val, j_var, j_fun, ne, he_row_ptr, he_val_ptr, he_row, he_val = csgreh(nlp, x, y, grlagf, lhe_ptr, lhe_row, lhe_val, byrows)\n\n\n\n\n\n\n\nnlp:        [IN] CUTEstModel\n\n\nx:          [IN] Array{Float64, 1}\n\n\ny:          [IN] Array{Float64, 1}\n\n\ngrlagf:     [IN] Bool\n\n\nnnzj:       [OUT] Int\n\n\nj_val:      [OUT] Array{Float64, 1}\n\n\nj_var:      [OUT] Array{Int, 1}\n\n\nj_fun:      [OUT] Array{Int, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.csgreh\n \n \nMethod\n.\n\n\nnnzj, j_val, j_var, j_fun, ne, he_row_ptr, he_val_ptr, he_row, he_val = csgreh(n, m, x, y, grlagf, lj, lhe_ptr, lhe_row, lhe_val, byrows)\n\n\n\n\n\n\n\nn:          [IN] Int\n\n\nm:          [IN] Int\n\n\nx:          [IN] Array{Float64, 1}\n\n\ny:          [IN] Array{Float64, 1}\n\n\ngrlagf:     [IN] Bool\n\n\nnnzj:       [OUT] Int\n\n\nlj:         [IN] Int\n\n\nj_val:      [OUT] Array{Float64, 1}\n\n\nj_var:      [OUT] Array{Int, 1}\n\n\nj_fun:      [OUT] Array{Int, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.csgrsh!\n \n \nMethod\n.\n\n\nnnzj, nnzh = csgrsh!(nlp, x, y, grlagf, j_val, j_var, j_fun, h_val, h_row, h_col)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\nnnzj:    [OUT] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csgrsh!\n \n \nMethod\n.\n\n\nnnzj, nnzh = csgrsh!(n, m, x, y, grlagf, lj, j_val, j_var, j_fun, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\nnnzj:    [OUT] Int\n\n\nlj:      [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csgrsh\n \n \nMethod\n.\n\n\nnnzj, j_val, j_var, j_fun, nnzh, h_val, h_row, h_col = csgrsh(nlp, x, y, grlagf)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\nnnzj:    [OUT] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csgrsh\n \n \nMethod\n.\n\n\nnnzj, j_val, j_var, j_fun, nnzh, h_val, h_row, h_col = csgrsh(n, m, x, y, grlagf, lj, lh)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\ngrlagf:  [IN] Bool\n\n\nnnzj:    [OUT] Int\n\n\nlj:      [IN] Int\n\n\nj_val:   [OUT] Array{Float64, 1}\n\n\nj_var:   [OUT] Array{Int, 1}\n\n\nj_fun:   [OUT] Array{Int, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csh!\n \n \nMethod\n.\n\n\nnnzh = csh!(nlp, x, y, h_val, h_row, h_col)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csh!\n \n \nMethod\n.\n\n\nnnzh = csh!(n, m, x, y, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csh\n \n \nMethod\n.\n\n\nnnzh, h_val, h_row, h_col = csh(nlp, x, y)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.csh\n \n \nMethod\n.\n\n\nnnzh, h_val, h_row, h_col = csh(n, m, x, y, lh)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshc!\n \n \nMethod\n.\n\n\nnnzh = cshc!(nlp, x, y, h_val, h_row, h_col)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshc!\n \n \nMethod\n.\n\n\nnnzh = cshc!(n, m, x, y, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshc\n \n \nMethod\n.\n\n\nnnzh, h_val, h_row, h_col = cshc(nlp, x, y)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshc\n \n \nMethod\n.\n\n\nnnzh, h_val, h_row, h_col = cshc(n, m, x, y, lh)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nm:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ny:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshcprod!\n \n \nMethod\n.\n\n\nnnz_result = cshcprod!(nlp, goth, x, y, nnz_vector, index_nz_vector, vector, index_nz_result, result)\n\n\n\n\n\n\n\nnlp:             [IN] CUTEstModel\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\ny:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cshcprod!\n \n \nMethod\n.\n\n\nnnz_result = cshcprod!(n, m, goth, x, y, nnz_vector, index_nz_vector, vector, index_nz_result, result)\n\n\n\n\n\n\n\nn:               [IN] Int\n\n\nm:               [IN] Int\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\ny:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cshcprod\n \n \nMethod\n.\n\n\nnnz_result, index_nz_result, result = cshcprod(nlp, goth, x, y, nnz_vector, index_nz_vector, vector)\n\n\n\n\n\n\n\nnlp:             [IN] CUTEstModel\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\ny:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cshcprod\n \n \nMethod\n.\n\n\nnnz_result, index_nz_result, result = cshcprod(n, m, goth, x, y, nnz_vector, index_nz_vector, vector)\n\n\n\n\n\n\n\nn:               [IN] Int\n\n\nm:               [IN] Int\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\ny:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cshp!\n \n \nMethod\n.\n\n\nnnzh = cshp!(nlp, h_row, h_col)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nnnzh:    [OUT] Int\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshp!\n \n \nMethod\n.\n\n\nnnzh = cshp!(n, lh, h_row, h_col)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshp\n \n \nMethod\n.\n\n\nnnzh, h_row, h_col = cshp(nlp)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nnnzh:    [OUT] Int\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshp\n \n \nMethod\n.\n\n\nnnzh, h_row, h_col = cshp(n, lh)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cshprod!\n \n \nMethod\n.\n\n\nnnz_result = cshprod!(nlp, goth, x, y, nnz_vector, index_nz_vector, vector, index_nz_result, result)\n\n\n\n\n\n\n\nnlp:             [IN] CUTEstModel\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\ny:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cshprod!\n \n \nMethod\n.\n\n\nnnz_result = cshprod!(n, m, goth, x, y, nnz_vector, index_nz_vector, vector, index_nz_result, result)\n\n\n\n\n\n\n\nn:               [IN] Int\n\n\nm:               [IN] Int\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\ny:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cshprod\n \n \nMethod\n.\n\n\nnnz_result, index_nz_result, result = cshprod(nlp, goth, x, y, nnz_vector, index_nz_vector, vector)\n\n\n\n\n\n\n\nnlp:             [IN] CUTEstModel\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\ny:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.cshprod\n \n \nMethod\n.\n\n\nnnz_result, index_nz_result, result = cshprod(n, m, goth, x, y, nnz_vector, index_nz_vector, vector)\n\n\n\n\n\n\n\nn:               [IN] Int\n\n\nm:               [IN] Int\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\ny:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.csjprod!\n \n \nMethod\n.\n\n\nnnz_result = csjprod!(nlp, gotj, jtrans, x, nnz_vector, index_nz_vector, vector, lvector, index_nz_result, result, lresult)\n\n\n\n\n\n\n\nnlp:             [IN] CUTEstModel\n\n\ngotj:            [IN] Bool\n\n\njtrans:          [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nlvector:         [IN] Int\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\nlresult:         [IN] Int\n\n\n\n\n#\n\n\nCUTEst.csjprod!\n \n \nMethod\n.\n\n\nnnz_result = csjprod!(n, m, gotj, jtrans, x, nnz_vector, index_nz_vector, vector, lvector, index_nz_result, result, lresult)\n\n\n\n\n\n\n\nn:               [IN] Int\n\n\nm:               [IN] Int\n\n\ngotj:            [IN] Bool\n\n\njtrans:          [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nlvector:         [IN] Int\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\nlresult:         [IN] Int\n\n\n\n\n#\n\n\nCUTEst.csjprod\n \n \nMethod\n.\n\n\nnnz_result, index_nz_result, result = csjprod(nlp, gotj, jtrans, x, nnz_vector, index_nz_vector, vector, lvector, lresult)\n\n\n\n\n\n\n\nnlp:             [IN] CUTEstModel\n\n\ngotj:            [IN] Bool\n\n\njtrans:          [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nlvector:         [IN] Int\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\nlresult:         [IN] Int\n\n\n\n\n#\n\n\nCUTEst.csjprod\n \n \nMethod\n.\n\n\nnnz_result, index_nz_result, result = csjprod(n, m, gotj, jtrans, x, nnz_vector, index_nz_vector, vector, lvector, lresult)\n\n\n\n\n\n\n\nn:               [IN] Int\n\n\nm:               [IN] Int\n\n\ngotj:            [IN] Bool\n\n\njtrans:          [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nlvector:         [IN] Int\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\nlresult:         [IN] Int\n\n\n\n\n#\n\n\nCUTEst.cstats\n \n \nMethod\n.\n\n\n#\n\n\nCUTEst.cstats\n \n \nMethod\n.\n\n\n#\n\n\nCUTEst.cterminate\n \n \nMethod\n.\n\n\ncterminate()\n\n\n\n\n\n#\n\n\nCUTEst.cvartype!\n \n \nMethod\n.\n\n\ncvartype!(n, x_type)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx_type:  [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.cvartype\n \n \nMethod\n.\n\n\nx_type = cvartype(n)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx_type:  [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.pname\n \n \nMethod\n.\n\n\npname = pname(nlp, input)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ninput:   [IN] Int\n\n\npname:   [OUT] UInt8\n\n\n\n\n#\n\n\nCUTEst.pname\n \n \nMethod\n.\n\n\npname = pname(input)\n\n\n\n\n\n\n\ninput:   [IN] Int\n\n\npname:   [OUT] UInt8\n\n\n\n\n#\n\n\nCUTEst.probname\n \n \nMethod\n.\n\n\npname = probname(nlp)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\npname:   [OUT] UInt8\n\n\n\n\n#\n\n\nCUTEst.probname\n \n \nMethod\n.\n\n\npname = probname()\n\n\n\n\n\n\n\npname:   [OUT] UInt8\n\n\n\n\n#\n\n\nCUTEst.ubandh!\n \n \nMethod\n.\n\n\nmax_semibandwidth = ubandh!(nlp, x, semibandwidth, h_band, lbandh)\n\n\n\n\n\n\n\nnlp:               [IN] CUTEstModel\n\n\nx:                 [IN] Array{Float64, 1}\n\n\nsemibandwidth:     [IN] Int\n\n\nh_band:            [OUT] Array{Float64, 2}\n\n\nlbandh:            [IN] Int\n\n\nmax_semibandwidth: [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.ubandh!\n \n \nMethod\n.\n\n\nmax_semibandwidth = ubandh!(n, x, semibandwidth, h_band, lbandh)\n\n\n\n\n\n\n\nn:                 [IN] Int\n\n\nx:                 [IN] Array{Float64, 1}\n\n\nsemibandwidth:     [IN] Int\n\n\nh_band:            [OUT] Array{Float64, 2}\n\n\nlbandh:            [IN] Int\n\n\nmax_semibandwidth: [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.ubandh\n \n \nMethod\n.\n\n\nh_band, max_semibandwidth = ubandh(nlp, x, semibandwidth, lbandh)\n\n\n\n\n\n\n\nnlp:               [IN] CUTEstModel\n\n\nx:                 [IN] Array{Float64, 1}\n\n\nsemibandwidth:     [IN] Int\n\n\nh_band:            [OUT] Array{Float64, 2}\n\n\nlbandh:            [IN] Int\n\n\nmax_semibandwidth: [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.ubandh\n \n \nMethod\n.\n\n\nh_band, max_semibandwidth = ubandh(n, x, semibandwidth, lbandh)\n\n\n\n\n\n\n\nn:                 [IN] Int\n\n\nx:                 [IN] Array{Float64, 1}\n\n\nsemibandwidth:     [IN] Int\n\n\nh_band:            [OUT] Array{Float64, 2}\n\n\nlbandh:            [IN] Int\n\n\nmax_semibandwidth: [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.udh!\n \n \nMethod\n.\n\n\nudh!(nlp, x, lh1, h)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.udh!\n \n \nMethod\n.\n\n\nudh!(n, x, lh1, h)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.udh\n \n \nMethod\n.\n\n\nh = udh(nlp, x, lh1)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.udh\n \n \nMethod\n.\n\n\nh = udh(n, x, lh1)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.udimen\n \n \nMethod\n.\n\n\nn = udimen(input)\n\n\n\n\n\n\n\ninput:   [IN] Int\n\n\nn:       [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.udimse\n \n \nMethod\n.\n\n\nne, he_val_ne, he_row_ne = udimse()\n\n\n\n\n\n\n\nne:        [OUT] Int\n\n\nhe_val_ne: [OUT] Int\n\n\nhe_row_ne: [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.udimsh\n \n \nMethod\n.\n\n\nnnzh = udimsh()\n\n\n\n\n\n\n\nnnzh:    [OUT] Int\n\n\n\n\n#\n\n\nCUTEst.ueh!\n \n \nMethod\n.\n\n\nne = ueh!(nlp, x, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\n\n\n\nnlp:        [IN] CUTEstModel\n\n\nx:          [IN] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ueh!\n \n \nMethod\n.\n\n\nne = ueh!(n, x, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\n\n\n\nn:          [IN] Int\n\n\nx:          [IN] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ueh\n \n \nMethod\n.\n\n\nne, he_row_ptr, he_val_ptr, he_row, he_val = ueh(nlp, x, lhe_ptr, lhe_row, lhe_val, byrows)\n\n\n\n\n\n\n\nnlp:        [IN] CUTEstModel\n\n\nx:          [IN] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ueh\n \n \nMethod\n.\n\n\nne, he_row_ptr, he_val_ptr, he_row, he_val = ueh(n, x, lhe_ptr, lhe_row, lhe_val, byrows)\n\n\n\n\n\n\n\nn:          [IN] Int\n\n\nx:          [IN] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ufn\n \n \nMethod\n.\n\n\nf = ufn(nlp, x)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\n\n\n#\n\n\nCUTEst.ufn\n \n \nMethod\n.\n\n\nf = ufn(n, x)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\n\n\n#\n\n\nCUTEst.ugr!\n \n \nMethod\n.\n\n\nugr!(nlp, x, g)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ugr!\n \n \nMethod\n.\n\n\nugr!(n, x, g)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ugr\n \n \nMethod\n.\n\n\ng = ugr(nlp, x)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ugr\n \n \nMethod\n.\n\n\ng = ugr(n, x)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ugrdh!\n \n \nMethod\n.\n\n\nugrdh!(nlp, x, g, lh1, h)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.ugrdh!\n \n \nMethod\n.\n\n\nugrdh!(n, x, g, lh1, h)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.ugrdh\n \n \nMethod\n.\n\n\ng, h = ugrdh(nlp, x, lh1)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.ugrdh\n \n \nMethod\n.\n\n\ng, h = ugrdh(n, x, lh1)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\nlh1:     [IN] Int\n\n\nh:       [OUT] Array{Float64, 2}\n\n\n\n\n#\n\n\nCUTEst.ugreh!\n \n \nMethod\n.\n\n\nne = ugreh!(nlp, x, g, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\n\n\n\nnlp:        [IN] CUTEstModel\n\n\nx:          [IN] Array{Float64, 1}\n\n\ng:          [OUT] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ugreh!\n \n \nMethod\n.\n\n\nne = ugreh!(n, x, g, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)\n\n\n\n\n\n\n\nn:          [IN] Int\n\n\nx:          [IN] Array{Float64, 1}\n\n\ng:          [OUT] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ugreh\n \n \nMethod\n.\n\n\ng, ne, he_row_ptr, he_val_ptr, he_row, he_val = ugreh(nlp, x, lhe_ptr, lhe_row, lhe_val, byrows)\n\n\n\n\n\n\n\nnlp:        [IN] CUTEstModel\n\n\nx:          [IN] Array{Float64, 1}\n\n\ng:          [OUT] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ugreh\n \n \nMethod\n.\n\n\ng, ne, he_row_ptr, he_val_ptr, he_row, he_val = ugreh(n, x, lhe_ptr, lhe_row, lhe_val, byrows)\n\n\n\n\n\n\n\nn:          [IN] Int\n\n\nx:          [IN] Array{Float64, 1}\n\n\ng:          [OUT] Array{Float64, 1}\n\n\nne:         [OUT] Int\n\n\nlhe_ptr:    [IN] Int\n\n\nhe_row_ptr: [OUT] Array{Int, 1}\n\n\nhe_val_ptr: [OUT] Array{Int, 1}\n\n\nlhe_row:    [IN] Int\n\n\nhe_row:     [OUT] Array{Int, 1}\n\n\nlhe_val:    [IN] Int\n\n\nhe_val:     [OUT] Array{Float64, 1}\n\n\nbyrows:     [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ugrsh!\n \n \nMethod\n.\n\n\nnnzh = ugrsh!(nlp, x, g, h_val, h_row, h_col)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ugrsh!\n \n \nMethod\n.\n\n\nnnzh = ugrsh!(n, x, g, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ugrsh\n \n \nMethod\n.\n\n\ng, nnzh, h_val, h_row, h_col = ugrsh(nlp, x)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ugrsh\n \n \nMethod\n.\n\n\ng, nnzh, h_val, h_row, h_col = ugrsh(n, x, lh)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\ng:       [OUT] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.uhprod!\n \n \nMethod\n.\n\n\nuhprod!(nlp, goth, x, vector, result)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.uhprod!\n \n \nMethod\n.\n\n\nuhprod!(n, goth, x, vector, result)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.uhprod\n \n \nMethod\n.\n\n\nresult = uhprod(nlp, goth, x, vector)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.uhprod\n \n \nMethod\n.\n\n\nresult = uhprod(n, goth, x, vector)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\ngoth:    [IN] Bool\n\n\nx:       [IN] Array{Float64, 1}\n\n\nvector:  [IN] Array{Float64, 1}\n\n\nresult:  [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.unames!\n \n \nMethod\n.\n\n\npname = unames!(n, vname)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\npname:   [OUT] UInt8\n\n\nvname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.unames\n \n \nMethod\n.\n\n\npname, vname = unames(n)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\npname:   [OUT] UInt8\n\n\nvname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.uofg!\n \n \nMethod\n.\n\n\nf = uofg!(nlp, x, g, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.uofg!\n \n \nMethod\n.\n\n\nf = uofg!(n, x, g, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.uofg\n \n \nMethod\n.\n\n\nf, g = uofg(nlp, x, grad)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.uofg\n \n \nMethod\n.\n\n\nf, g = uofg(n, x, grad)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nf:       [OUT] Float64\n\n\ng:       [OUT] Array{Float64, 1}\n\n\ngrad:    [IN] Bool\n\n\n\n\n#\n\n\nCUTEst.ureport!\n \n \nMethod\n.\n\n\nureport!(calls, time)\n\n\n\n\n\n\n\ncalls:   [OUT] Array{Float64, 1}\n\n\ntime:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ureport!\n \n \nMethod\n.\n\n\nureport!(nlp, calls, time)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ncalls:   [OUT] Array{Float64, 1}\n\n\ntime:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ureport\n \n \nMethod\n.\n\n\ncalls, time = ureport(nlp)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\ncalls:   [OUT] Array{Float64, 1}\n\n\ntime:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ureport\n \n \nMethod\n.\n\n\ncalls, time = ureport()\n\n\n\n\n\n\n\ncalls:   [OUT] Array{Float64, 1}\n\n\ntime:    [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.usetup!\n \n \nMethod\n.\n\n\nusetup!(input, out, io_buffer, n, x, x_l, x_u)\n\n\n\n\n\n\n\ninput:     [IN] Int\n\n\nout:       [IN] Int\n\n\nio_buffer: [IN] Int\n\n\nn:         [IN] Int\n\n\nx:         [OUT] Array{Float64, 1}\n\n\nx_l:       [OUT] Array{Float64, 1}\n\n\nx_u:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.usetup\n \n \nMethod\n.\n\n\nx, x_l, x_u = usetup(input, out, io_buffer, n)\n\n\n\n\n\n\n\ninput:     [IN] Int\n\n\nout:       [IN] Int\n\n\nio_buffer: [IN] Int\n\n\nn:         [IN] Int\n\n\nx:         [OUT] Array{Float64, 1}\n\n\nx_l:       [OUT] Array{Float64, 1}\n\n\nx_u:       [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ush!\n \n \nMethod\n.\n\n\nnnzh = ush!(nlp, x, h_val, h_row, h_col)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ush!\n \n \nMethod\n.\n\n\nnnzh = ush!(n, x, lh, h_val, h_row, h_col)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ush\n \n \nMethod\n.\n\n\nnnzh, h_val, h_row, h_col = ush(nlp, x)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nx:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ush\n \n \nMethod\n.\n\n\nnnzh, h_val, h_row, h_col = ush(n, x, lh)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx:       [IN] Array{Float64, 1}\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_val:   [OUT] Array{Float64, 1}\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ushp!\n \n \nMethod\n.\n\n\nnnzh = ushp!(nlp, h_row, h_col)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nnnzh:    [OUT] Int\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ushp!\n \n \nMethod\n.\n\n\nnnzh = ushp!(n, lh, h_row, h_col)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ushp\n \n \nMethod\n.\n\n\nnnzh, h_row, h_col = ushp(nlp)\n\n\n\n\n\n\n\nnlp:     [IN] CUTEstModel\n\n\nnnzh:    [OUT] Int\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ushp\n \n \nMethod\n.\n\n\nnnzh, h_row, h_col = ushp(n, lh)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nnnzh:    [OUT] Int\n\n\nlh:      [IN] Int\n\n\nh_row:   [OUT] Array{Int, 1}\n\n\nh_col:   [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.ushprod!\n \n \nMethod\n.\n\n\nnnz_result = ushprod!(nlp, goth, x, nnz_vector, index_nz_vector, vector, index_nz_result, result)\n\n\n\n\n\n\n\nnlp:             [IN] CUTEstModel\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ushprod!\n \n \nMethod\n.\n\n\nnnz_result = ushprod!(n, goth, x, nnz_vector, index_nz_vector, vector, index_nz_result, result)\n\n\n\n\n\n\n\nn:               [IN] Int\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ushprod\n \n \nMethod\n.\n\n\nnnz_result, index_nz_result, result = ushprod(nlp, goth, x, nnz_vector, index_nz_vector, vector)\n\n\n\n\n\n\n\nnlp:             [IN] CUTEstModel\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.ushprod\n \n \nMethod\n.\n\n\nnnz_result, index_nz_result, result = ushprod(n, goth, x, nnz_vector, index_nz_vector, vector)\n\n\n\n\n\n\n\nn:               [IN] Int\n\n\ngoth:            [IN] Bool\n\n\nx:               [IN] Array{Float64, 1}\n\n\nnnz_vector:      [IN] Int\n\n\nindex_nz_vector: [IN] Array{Int, 1}\n\n\nvector:          [IN] Array{Float64, 1}\n\n\nnnz_result:      [OUT] Int\n\n\nindex_nz_result: [OUT] Array{Int, 1}\n\n\nresult:          [OUT] Array{Float64, 1}\n\n\n\n\n#\n\n\nCUTEst.uterminate\n \n \nMethod\n.\n\n\nuterminate()\n\n\n\n\n\n#\n\n\nCUTEst.uvartype!\n \n \nMethod\n.\n\n\nuvartype!(n, x_type)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx_type:  [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.uvartype\n \n \nMethod\n.\n\n\nx_type = uvartype(n)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nx_type:  [OUT] Array{Int, 1}\n\n\n\n\n#\n\n\nCUTEst.varnames!\n \n \nMethod\n.\n\n\nvarnames!(n, vname)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nvname:   [OUT] Array{UInt8, 1}\n\n\n\n\n#\n\n\nCUTEst.varnames\n \n \nMethod\n.\n\n\nvname = varnames(n)\n\n\n\n\n\n\n\nn:       [IN] Int\n\n\nvname:   [OUT] Array{UInt8, 1}\n\n\n\n\n\n\nInternal\n\n\n#\n\n\nCUTEst.sifdecoder\n \n \nMethod\n.\n\n\nDecode problem and build shared library.\n\n\nOptional arguments are passed directly to the SIF decoder. Example:     \nsifdecoder(\"DIXMAANJ\", \"-param\", \"M=30\")\n.", 
            "title": "API"
        }, 
        {
            "location": "/api/#api", 
            "text": "", 
            "title": "API"
        }, 
        {
            "location": "/api/#nlpmodels-api", 
            "text": "#  NLPModels.obj     Function .  obj(nlp, x)  Evaluate $f(x)$, the objective function of  nlp  at  x .  #  NLPModels.grad     Function .  grad(nlp, x)  Evaluate $\\nabla f(x)$, the gradient of the objective function at  x .  #  NLPModels.grad!     Function .  grad!(nlp, x, g)  Evaluate $\\nabla f(x)$, the gradient of the objective function at  x  in place.  #  NLPModels.cons     Function .  cons(nlp, x)  Evaluate $c(x)$, the constraints at  x .  cons(nlp, x, jac)  Computes the constraint vector and, if  jac  is  true , the Jacobian in internal sparse format. Usage:  c, J = cons(nlp, x, true)\nc = cons(nlp, x, false)   nlp:  [IN] CUTEstModel  x:    [IN] Array{Float64, 1}  jac:  [IN] Bool  c:    [OUT] Array{Float64, 1}  J:    [OUT] Base.SparseMatrix.SparseMatrixCSC{Float64,Int32}   #  NLPModels.cons!     Function .  cons!(nlp, x, c)  Evaluate $c(x)$, the constraints at  x  in place.  #  NLPModels.jac_coord     Function .  (rows,cols,vals) = jac_coord(nlp, x)  Evaluate $\\nabla c(x)$, the constraint's Jacobian at  x  in sparse coordinate format.  #  NLPModels.jac     Function .  Jx = jac(nlp, x)  Evaluate $\\nabla c(x)$, the constraint's Jacobian at  x  as a sparse matrix.  #  NLPModels.jprod     Function .  Jv = jprod(nlp, x, v)  Evaluate $\\nabla c(x)v$, the Jacobian-vector product at  x .  #  NLPModels.jprod!     Function .  Jv = jprod!(nlp, x, v, Jv)  Evaluate $\\nabla c(x)v$, the Jacobian-vector product at  x  in place.  #  NLPModels.jtprod     Function .  Jtv = jtprod(nlp, x, v, Jtv)  Evaluate $\\nabla c(x)^Tv$, the transposed-Jacobian-vector product at  x .  #  NLPModels.jtprod!     Function .  Jtv = jtprod!(nlp, x, v, Jtv)  Evaluate $\\nabla c(x)^Tv$, the transposed-Jacobian-vector product at  x  in place.  #  NLPModels.hess_coord     Function .  (rows,cols,vals) = hess_coord(nlp, x; obj_weight=1.0, y=zeros)  Evaluate the Lagrangian Hessian at  (x,y)  in sparse coordinate format, with objective function scaled by  obj_weight , i.e.,    \\nabla^2L(x,y) = \\sigma * \\nabla^2 f(x) + \\sum_{i=1}^m y_i\\nabla^2 c_i(x),    with \u03c3 = obj_weight. Only the lower triangle is returned.  #  NLPModels.hess     Function .  Hx = hess(nlp, x; obj_weight=1.0, y=zeros)  Evaluate the Lagrangian Hessian at  (x,y)  as a sparse matrix, with objective function scaled by  obj_weight , i.e.,    \\nabla^2L(x,y) = \\sigma * \\nabla^2 f(x) + \\sum_{i=1}^m y_i\\nabla^2 c_i(x),    with \u03c3 = obj_weight. Only the lower triangle is returned.  #  NLPModels.hprod     Function .  Hv = hprod(nlp, x, v; obj_weight=1.0, y=zeros)  Evaluate the product of the Lagrangian Hessian at  (x,y)  with the vector  v , with objective function scaled by  obj_weight , i.e.,    \\nabla^2L(x,y) = \\sigma * \\nabla^2 f(x) + \\sum_{i=1}^m y_i\\nabla^2 c_i(x),    with \u03c3 = obj_weight.  #  NLPModels.hprod!     Function .  Hv = hprod!(nlp, x, v, Hv; obj_weight=1.0, y=zeros)  Evaluate the product of the Lagrangian Hessian at  (x,y)  with the vector  v  in place, with objective function scaled by  obj_weight , i.e.,    \\nabla^2L(x,y) = \\sigma * \\nabla^2 f(x) + \\sum_{i=1}^m y_i\\nabla^2 c_i(x),    with \u03c3 = obj_weight.  #  NLPModels.NLPtoMPB     Function .  mp = NLPtoMPB(nlp, solver)  Return a  MathProgBase  model corresponding to an  AbstractNLPModel .  Arguments   nlp::AbstractNLPModel  solver::AbstractMathProgSolver  a solver instance, e.g.,  IpoptSolver()   Currently, all models are treated as nonlinear models.  Return values  The function returns a  MathProgBase  model  mpbmodel  such that it should be possible to call  MathProgBase.optimize!(mpbmodel)  #  LinearOperators.reset!     Function .  reset!(counters)  Reset evaluation counters  `reset!(nlp)  Reset evaluation count in  nlp", 
            "title": "NLPModels API"
        }, 
        {
            "location": "/api/#extra-julian-api", 
            "text": "#  CUTEst.objgrad     Function .  objgrad(nlp, x, grad)  Computes the objective function value and, if grad is  true , gradient at x. Usage:  f, g = objgrad(nlp, x, true)\nf = objgrad(nlp, x)   nlp:  [IN] CUTEstModel  x:    [IN] Array{Float64, 1}  grad: [IN] Bool  f:    [OUT] Float64  g:    [OUT] Array{Float64, 1}   #  CUTEst.objcons     Function .  objcons(nlp, x)  Computes the objective function and constraint vector values at x. Usage:  f, c = objcons(nlp, x) # If the problem is constrained\nf = objcons(nlp, x)    # If the problem is unconstrained   nlp: [IN] CUTEstModel  x:   [IN] Array{Float64, 1}  f:   [OUT] Float64  c:   [OUT] Array{Float64, 1}   #  CUTEst.cons_coord     Function .  cons_coord(nlp, x, jac)  Computes the constraint vector and, if  jac  is  true , the Jacobian in coordinate format. Usage:  c, jrow, jcol, jval = cons_coord(nlp, x, true)\nc = cons_coord(nlp, x, false)   nlp:  [IN] CUTEstModel  x:    [IN] Array{Float64, 1}  jac:  [IN] Bool  c:    [OUT] Array{Float64, 1}  jrow: [OUT] Array{Int32, 1}  jcol: [OUT] Array{Int32, 1}  jval: [OUT] Array{Float64, 1}", 
            "title": "Extra Julian API"
        }, 
        {
            "location": "/api/#core-and-specialized-api", 
            "text": "#  CUTEst.ccfg     Method .  ccfg  The ccfg subroutine evaluates the values of the constraint functions of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly their gradients. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_ccfg  Usage:  ccfg(io_err, n, m, x, c, jtrans, lcjac1, lcjac2, cjac, grad)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  c:       [OUT] Array{Cdouble, 1}  jtrans:  [IN] Array{Cint, 1}  lcjac1:  [IN] Array{Cint, 1}  lcjac2:  [IN] Array{Cint, 1}  cjac:    [OUT] Array{Cdouble, 2}  grad:    [IN] Array{Cint, 1}   #  CUTEst.ccfsg     Method .  ccfsg  The ccfsg subroutine evaluates the values of the constraint functions of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly their gradients in the constrained minimization case. The gradients are stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_ccfsg  Usage:  ccfsg(io_err, n, m, x, c, nnzj, lj, j_val, j_var, j_fun, grad)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  c:       [OUT] Array{Cdouble, 1}  nnzj:    [OUT] Array{Cint, 1}  lj:      [IN] Array{Cint, 1}  j_val:   [OUT] Array{Cdouble, 1}  j_var:   [OUT] Array{Cint, 1}  j_fun:   [OUT] Array{Cint, 1}  grad:    [IN] Array{Cint, 1}   #  CUTEst.cchprods     Method .  cchprods  The cchprods subroutine forms the product of a vector with each of the Hessian matrix of the constraint functions c(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point x= X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cchprods  Usage:  cchprods(io_err, n, m, goth, x, vector, lchp, chp_val, chp_ind, chp_ptr)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  goth:    [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  vector:  [IN] Array{Cdouble, 1}  lchp:    [IN] Array{Cint, 1}  chp_val: [OUT] Array{Cdouble, 1}  chp_ind: [IN] Array{Cint, 1}  chp_ptr: [IN] Array{Cint, 1}   #  CUTEst.ccifg     Method .  ccifg  The ccifg subroutine evaluates the value of a particular constraint function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient in the constrained minimization case. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_ccifg  Usage:  ccifg(io_err, n, icon, x, ci, gci, grad)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  icon:    [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  ci:      [OUT] Array{Cdouble, 1}  gci:     [OUT] Array{Cdouble, 1}  grad:    [IN] Array{Cint, 1}   #  CUTEst.ccifsg     Method .  ccifsg  The ccifsg subroutine evaluates the value of a particular constraint function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient in the constrained minimization case. The gradient is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_ccifsg  Usage:  ccifsg(io_err, n, icon, x, ci, nnzgci, lgci, gci_val, gci_var, grad)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  icon:    [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  ci:      [OUT] Array{Cdouble, 1}  nnzgci:  [OUT] Array{Cint, 1}  lgci:    [IN] Array{Cint, 1}  gci_val: [OUT] Array{Cdouble, 1}  gci_var: [OUT] Array{Cint, 1}  grad:    [IN] Array{Cint, 1}   #  CUTEst.cdh     Method .  cdh  The cdh subroutine evaluates the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cdh  Usage:  cdh(io_err, n, m, x, y, lh1, h_val)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  lh1:     [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 2}   #  CUTEst.cdhc     Method .  cdhc  The cdhc subroutine evaluates the Hessian matrix of the constraint part of the Lagrangian function yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cdhc  Usage:  cdhc(io_err, n, m, x, y, lh1, h_val)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  lh1:     [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 2}   #  CUTEst.cdimchp     Method .  cdimchp  The cdimchp subroutine determines the number of nonzero elements required to store the products of the Hessian matrices of the constraint functions with a specified vector for the problem decoded into OUTSDIF.d in the constrained minimization case. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cdimchp  Usage:  cdimchp(io_err, nnzchp)   io_err:  [OUT] Array{Cint, 1}  nnzchp:  [OUT] Array{Cint, 1}   #  CUTEst.cdimen     Method .  cdimen  The cdimen subroutine discovers how many variables and constraints are involved in the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cdimen  Usage:  cdimen(io_err, input, n, m)   io_err:  [OUT] Array{Cint, 1}  input:   [IN] Array{Cint, 1}  n:       [OUT] Array{Cint, 1}  m:       [OUT] Array{Cint, 1}   #  CUTEst.cdimse     Method .  cdimse  The cdimse subroutine determines the number of nonzero elements required to store the Hessian matrix of the Lagrangian function for the problem decoded from a SIF file by the script sifdecoder. The matrix is stored in sparse \"finite element\" format H=e\u03a31He, where each square symmetric element He involves a small subset of the rows of the Hessian matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cdimse  Usage:  cdimse(io_err, ne, he_val_ne, he_row_ne)   io_err:    [OUT] Array{Cint, 1}  ne:        [OUT] Array{Cint, 1}  he_val_ne: [OUT] Array{Cint, 1}  he_row_ne: [OUT] Array{Cint, 1}   #  CUTEst.cdimsh     Method .  cdimsh  The cdimsh subroutine determines the number of nonzero elements required to store the Hessian matrix of the Lagrangian function for the problem decoded into OUTSDIF.d in the constrained minimization case. The matrix is stored in sparse \"coordinate\" format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cdimsh  Usage:  cdimsh(io_err, nnzh)   io_err:  [OUT] Array{Cint, 1}  nnzh:    [OUT] Array{Cint, 1}   #  CUTEst.cdimsj     Method .  cdimsj  The cdimsj subroutine determines the number of nonzero elements required to store the matrix of gradients of the objective function and constraint functions for the problem decoded into OUTSDIF.d in the constrained minimization case. The matrix is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cdimsj  Usage:  cdimsj(io_err, nnzj)   io_err:  [OUT] Array{Cint, 1}  nnzj:    [OUT] Array{Cint, 1}   #  CUTEst.ceh     Method .  ceh  The ceh subroutine evaluates the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded into OUTSDIF.d at the point (x,y)= (X,Y). This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element He involves a small subset of the rows of the Hessian matrix. The problem under consideration consists in minimizing (or maximizing) an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_ceh  Usage:  ceh(io_err, n, m, x, y, ne, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row,  he_row, lhe_val, he_val, byrows)   io_err:     [OUT] Array{Cint, 1}  n:          [IN] Array{Cint, 1}  m:          [IN] Array{Cint, 1}  x:          [IN] Array{Cdouble, 1}  y:          [IN] Array{Cdouble, 1}  ne:         [OUT] Array{Cint, 1}  lhe_ptr:    [IN] Array{Cint, 1}  he_row_ptr: [OUT] Array{Cint, 1}  he_val_ptr: [OUT] Array{Cint, 1}  lhe_row:    [IN] Array{Cint, 1}  he_row:     [OUT] Array{Cint, 1}  lhe_val:    [IN] Array{Cint, 1}  he_val:     [OUT] Array{Cdouble, 1}  byrows:     [IN] Array{Cint, 1}   #  CUTEst.cfn     Method .  cfn  The cfn subroutine evaluates the value of the objective function and general constraint functions of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cfn  Usage:  cfn(io_err, n, m, x, f, c)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  f:       [OUT] Array{Cdouble, 1}  c:       [OUT] Array{Cdouble, 1}   #  CUTEst.cgr     Method .  cgr  The cgr subroutine evaluates the gradients of the general constraints and of either the objective function f(x) or the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cgr  Usage:  cgr(io_err, n, m, x, y, grlagf, g, jtrans, lj1, lj2, j_val)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  grlagf:  [IN] Array{Cint, 1}  g:       [OUT] Array{Cdouble, 1}  jtrans:  [IN] Array{Cint, 1}  lj1:     [IN] Array{Cint, 1}  lj2:     [IN] Array{Cint, 1}  j_val:   [OUT] Array{Cdouble, 2}   #  CUTEst.cgrdh     Method .  cgrdh  The cgrdh subroutine evaluates the gradients of the general constraints and of either the objective function f(x) or the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). It also evaluates the Hessian matrix of the Lagrangian function at (x,y). The gradients and matrices are stored in a dense format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cgrdh  Usage:  cgrdh(io_err, n, m, x, y, grlagf, g, jtrans, lj1, lj2, j_val, lh1, h_val)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  grlagf:  [IN] Array{Cint, 1}  g:       [OUT] Array{Cdouble, 1}  jtrans:  [IN] Array{Cint, 1}  lj1:     [IN] Array{Cint, 1}  lj2:     [IN] Array{Cint, 1}  j_val:   [OUT] Array{Cdouble, 2}  lh1:     [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 2}   #  CUTEst.chcprod     Method .  chcprod  The chcprod subroutine forms the product of a vector with the Hessian matrix of the constraint part of the Lagrangian function yTc(x) of the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_chcprod  Usage:  chcprod(io_err, n, m, goth, x, y, vector, result)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  goth:    [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  vector:  [IN] Array{Cdouble, 1}  result:  [OUT] Array{Cdouble, 1}   #  CUTEst.chprod     Method .  chprod  The chprod subroutine forms the product of a vector with the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_chprod  Usage:  chprod(io_err, n, m, goth, x, y, vector, result)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  goth:    [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  vector:  [IN] Array{Cdouble, 1}  result:  [OUT] Array{Cdouble, 1}   #  CUTEst.cidh     Method .  cidh  The cidh subroutine evaluates the Hessian matrix of either the objective function or a constraint function for the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient. The matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cidh  Usage:  cidh(io_err, n, x, iprob, lh1, h)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  iprob:   [IN] Array{Cint, 1}  lh1:     [IN] Array{Cint, 1}  h:       [OUT] Array{Cdouble, 2}   #  CUTEst.cish     Method .  cish  The cish subroutine evaluates the Hessian of a particular constraint function or the objective function for the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient. The matrix is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cish  Usage:  cish(io_err, n, x, iprob, nnzh, lh, h_val, h_row, h_col)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  iprob:   [IN] Array{Cint, 1}  nnzh:    [OUT] Array{Cint, 1}  lh:      [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 1}  h_row:   [OUT] Array{Cint, 1}  h_col:   [OUT] Array{Cint, 1}   #  CUTEst.cjprod     Method .  cjprod  The cjprod subroutine forms the product of a vector with the Jacobian matrix, or with its transpose, of the constraint functions of the problem decoded from a SIF file by the script sifdecoder evaluated at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cjprod  Usage:  cjprod(io_err, n, m, gotj, jtrans, x, vector, lvector, result, lresult)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  gotj:    [IN] Array{Cint, 1}  jtrans:  [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  vector:  [IN] Array{Cdouble, 1}  lvector: [IN] Array{Cint, 1}  result:  [OUT] Array{Cdouble, 1}  lresult: [IN] Array{Cint, 1}   #  CUTEst.clfg     Method .  clfg  The clfg subroutine evaluates the value of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (X,Y), and possibly its gradient. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_clfg  Usage:  clfg(io_err, n, m, x, y, f, g, grad)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  f:       [OUT] Array{Cdouble, 1}  g:       [OUT] Array{Cdouble, 1}  grad:    [IN] Array{Cint, 1}   #  CUTEst.cnames     Method .  cnames  The cnames subroutine obtains the names of the problem, its variables and general constraints. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cnames  Usage:  cnames(io_err, n, m, pname, vname, cname)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  pname:   [OUT] Array{Cchar, 1}  vname:   [OUT] Array{Cchar, 1}  cname:   [OUT] Array{Cchar, 1}   #  CUTEst.cofg     Method .  cofg  The cofg subroutine evaluates the value of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cofg  Usage:  cofg(io_err, n, x, f, g, grad)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  f:       [OUT] Array{Cdouble, 1}  g:       [OUT] Array{Cdouble, 1}  grad:    [IN] Array{Cint, 1}   #  CUTEst.cofsg     Method .  cofsg  The cofsg subroutine evaluates the value of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cofsg  Usage:  cofsg(io_err, n, x, f, nnzg, lg, g_val, g_var, grad)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  f:       [OUT] Array{Cdouble, 1}  nnzg:    [OUT] Array{Cint, 1}  lg:      [IN] Array{Cint, 1}  g_val:   [OUT] Array{Cdouble, 1}  g_var:   [OUT] Array{Cint, 1}  grad:    [IN] Array{Cint, 1}   #  CUTEst.connames     Method .  connames  The connames subroutine obtains the names of the general constraints of the problem. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_connames  Usage:  connames(io_err, m, cname)   io_err:  [OUT] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  cname:   [OUT] Array{Cchar, 1}   #  CUTEst.creport     Method .  creport  The creport subroutine obtains statistics concerning function evaluation and CPU time used for constrained optimization in a standardized format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_creport  Usage:  creport(io_err, calls, time)   io_err:  [OUT] Array{Cint, 1}  calls:   [OUT] Array{Cdouble, 1}  time:    [OUT] Array{Cdouble, 1}   #  CUTEst.csetup     Method .  csetup  The csetup subroutine sets up the correct data structures for subsequent computations on the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_csetup  Usage:  csetup(io_err, input, out, io_buffer, n, m, x, x_l, x_u, y, c_l, c_u, equatn,  linear, e_order, l_order, v_order)   io_err:    [OUT] Array{Cint, 1}  input:     [IN] Array{Cint, 1}  out:       [IN] Array{Cint, 1}  io_buffer: [IN] Array{Cint, 1}  n:         [IN] Array{Cint, 1}  m:         [IN] Array{Cint, 1}  x:         [OUT] Array{Cdouble, 1}  x_l:       [OUT] Array{Cdouble, 1}  x_u:       [OUT] Array{Cdouble, 1}  y:         [OUT] Array{Cdouble, 1}  c_l:       [OUT] Array{Cdouble, 1}  c_u:       [OUT] Array{Cdouble, 1}  equatn:    [OUT] Array{Cint, 1}  linear:    [OUT] Array{Cint, 1}  e_order:   [IN] Array{Cint, 1}  l_order:   [IN] Array{Cint, 1}  v_order:   [IN] Array{Cint, 1}   #  CUTEst.csgr     Method .  csgr  The csgr subroutine evaluates the gradients of the general constraints and of either the objective function or the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). It also evaluates the Hessian matrix of the Lagrangian function at (x,y). The gradients are stored in a sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_csgr  Usage:  csgr(io_err, n, m, x, y, grlagf, nnzj, lj, j_val, j_var, j_fun)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  grlagf:  [IN] Array{Cint, 1}  nnzj:    [OUT] Array{Cint, 1}  lj:      [IN] Array{Cint, 1}  j_val:   [OUT] Array{Cdouble, 1}  j_var:   [OUT] Array{Cint, 1}  j_fun:   [OUT] Array{Cint, 1}   #  CUTEst.csgreh     Method .  csgreh  The csgreh subroutine evaluates both the gradients of the general constraint functions and the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded into OUTSDIF.d at the point (x,y)= (X,Y). This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element He involves a small subset of the rows of the Hessian matrix. The subroutine also obtains the gradient of either the objective function or the Lagrangian function, stored in a sparse format. The problem under consideration consists in minimizing (or maximizing) an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_csgreh  Usage:  csgreh(io_err, n, m, x, y, grlagf, nnzj, lj, j_val, j_var, j_fun, ne,  lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   io_err:     [OUT] Array{Cint, 1}  n:          [IN] Array{Cint, 1}  m:          [IN] Array{Cint, 1}  x:          [IN] Array{Cdouble, 1}  y:          [IN] Array{Cdouble, 1}  grlagf:     [IN] Array{Cint, 1}  nnzj:       [OUT] Array{Cint, 1}  lj:         [IN] Array{Cint, 1}  j_val:      [OUT] Array{Cdouble, 1}  j_var:      [OUT] Array{Cint, 1}  j_fun:      [OUT] Array{Cint, 1}  ne:         [OUT] Array{Cint, 1}  lhe_ptr:    [IN] Array{Cint, 1}  he_row_ptr: [OUT] Array{Cint, 1}  he_val_ptr: [OUT] Array{Cint, 1}  lhe_row:    [IN] Array{Cint, 1}  he_row:     [OUT] Array{Cint, 1}  lhe_val:    [IN] Array{Cint, 1}  he_val:     [OUT] Array{Cdouble, 1}  byrows:     [IN] Array{Cint, 1}   #  CUTEst.csgrsh     Method .  csgrsh  The csgrsh subroutine evaluates the gradients of the general constraints, the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) and the gradient of either the objective function or the Lagrangian corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The data is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_csgrsh  Usage:  csgrsh(io_err, n, m, x, y, grlagf, nnzj, lj, j_val, j_var, j_fun, nnzh, lh,  h_val, h_row, h_col)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  grlagf:  [IN] Array{Cint, 1}  nnzj:    [OUT] Array{Cint, 1}  lj:      [IN] Array{Cint, 1}  j_val:   [OUT] Array{Cdouble, 1}  j_var:   [OUT] Array{Cint, 1}  j_fun:   [OUT] Array{Cint, 1}  nnzh:    [OUT] Array{Cint, 1}  lh:      [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 1}  h_row:   [OUT] Array{Cint, 1}  h_col:   [OUT] Array{Cint, 1}   #  CUTEst.csh     Method .  csh  The csh subroutine evaluates the Hessian of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The matrix is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_csh  Usage:  csh(io_err, n, m, x, y, nnzh, lh, h_val, h_row, h_col)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  nnzh:    [OUT] Array{Cint, 1}  lh:      [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 1}  h_row:   [OUT] Array{Cint, 1}  h_col:   [OUT] Array{Cint, 1}   #  CUTEst.cshc     Method .  cshc  The cshc subroutine evaluates the Hessian matrix of the constraint part of the Lagrangian function yTc(x) for the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The matrix is stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cshc  Usage:  cshc(io_err, n, m, x, y, nnzh, lh, h_val, h_row, h_col)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  m:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  y:       [IN] Array{Cdouble, 1}  nnzh:    [OUT] Array{Cint, 1}  lh:      [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 1}  h_row:   [OUT] Array{Cint, 1}  h_col:   [OUT] Array{Cint, 1}   #  CUTEst.cshcprod     Method .  cshcprod  The cshcprod subroutine forms the product of a sparse vector with the Hessian matrix of the constraint part of the Lagrangian function yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cshcprod  Usage:  cshcprod(io_err, n, m, goth, x, y, nnz_vector, index_nz_vector, vector,  nnz_result, index_nz_result, result)   io_err:          [OUT] Array{Cint, 1}  n:               [IN] Array{Cint, 1}  m:               [IN] Array{Cint, 1}  goth:            [IN] Array{Cint, 1}  x:               [IN] Array{Cdouble, 1}  y:               [IN] Array{Cdouble, 1}  nnz_vector:      [IN] Array{Cint, 1}  index_nz_vector: [IN] Array{Cint, 1}  vector:          [IN] Array{Cdouble, 1}  nnz_result:      [OUT] Array{Cint, 1}  index_nz_result: [OUT] Array{Cint, 1}  result:          [OUT] Array{Cdouble, 1}   #  CUTEst.cshp     Method .  cshp  The cshp subroutine evaluates the sparsity pattern of the Hessian of the Lagrangian function l(x,y)=f(x)+yTc(x) for the problem, decoded from a SIF file by the script sifdecoder, in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cshp  Usage:  cshp(io_err, n, nnzh, lh, h_row, h_col)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  nnzh:    [OUT] Array{Cint, 1}  lh:      [IN] Array{Cint, 1}  h_row:   [OUT] Array{Cint, 1}  h_col:   [OUT] Array{Cint, 1}   #  CUTEst.cshprod     Method .  cshprod  The cshprod subroutine forms the product of a sparse vector with the Hessian matrix of the Lagrangian function l(x,y)=f(x)+yTc(x) corresponding to the problem decoded from a SIF file by the script sifdecoder at the point (x,y)= (X,Y). The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cshprod  Usage:  cshprod(io_err, n, m, goth, x, y, nnz_vector, index_nz_vector, vector,  nnz_result, index_nz_result, result)   io_err:          [OUT] Array{Cint, 1}  n:               [IN] Array{Cint, 1}  m:               [IN] Array{Cint, 1}  goth:            [IN] Array{Cint, 1}  x:               [IN] Array{Cdouble, 1}  y:               [IN] Array{Cdouble, 1}  nnz_vector:      [IN] Array{Cint, 1}  index_nz_vector: [IN] Array{Cint, 1}  vector:          [IN] Array{Cdouble, 1}  nnz_result:      [OUT] Array{Cint, 1}  index_nz_result: [OUT] Array{Cint, 1}  result:          [OUT] Array{Cdouble, 1}   #  CUTEst.csjprod     Method .  csjprod  The csjprod subroutine forms the product of a sparse vector with the Jacobian matrix, or with its transpose, of the constraint functions of the problem decoded from a SIF file by the script sifdecoder evaluated at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_csjprod  Usage:  csjprod(io_err, n, m, gotj, jtrans, x, nnz_vector, index_nz_vector, vector,  lvector, nnz_result, index_nz_result, result, lresult)   io_err:          [OUT] Array{Cint, 1}  n:               [IN] Array{Cint, 1}  m:               [IN] Array{Cint, 1}  gotj:            [IN] Array{Cint, 1}  jtrans:          [IN] Array{Cint, 1}  x:               [IN] Array{Cdouble, 1}  nnz_vector:      [IN] Array{Cint, 1}  index_nz_vector: [IN] Array{Cint, 1}  vector:          [IN] Array{Cdouble, 1}  lvector:         [IN] Array{Cint, 1}  nnz_result:      [OUT] Array{Cint, 1}  index_nz_result: [OUT] Array{Cint, 1}  result:          [OUT] Array{Cdouble, 1}  lresult:         [IN] Array{Cint, 1}   #  CUTEst.cstats     Method .  cstats  cstats(io_err, nonlinear_variables_objective,  nonlinear_variables_constraints, equality_constraints, linear_constraints)   io_err:                          [OUT] Array{Cint, 1}  nonlinear_variables_objective:   [OUT] Array{Cint, 1}  nonlinear_variables_constraints: [OUT] Array{Cint, 1}  equality_constraints:            [OUT] Array{Cint, 1}  linear_constraints:              [OUT] Array{Cint, 1}   #  CUTEst.cterminate     Method .  cterminate  The uterminate subroutine deallocates all workspace arrays created since the last call to csetup.  For more information, run the shell command  man cutest_cterminate  Usage:  cterminate(io_err)   io_err:  [OUT] Array{Cint, 1}   #  CUTEst.cvartype     Method .  cvartype  The cvartype subroutine determines the type (continuous, 0-1, integer) of each variable involved in the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_cvartype  Usage:  cvartype(io_err, n, x_type)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x_type:  [OUT] Array{Cint, 1}   #  CUTEst.pname     Method .  pname  The pname subroutine obtains the name of the problem directly from the datafile OUTSDIF.d that was created by the script sifdecoder when decoding a SIF file. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_pname  Usage:  pname(io_err, input, pname)   io_err:  [OUT] Array{Cint, 1}  input:   [IN] Array{Cint, 1}  pname:   [OUT] Array{Cchar, 1}   #  CUTEst.probname     Method .  probname  The probname subroutine obtains the name of the problem. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_probname  Usage:  probname(io_err, pname)   io_err:  [OUT] Array{Cint, 1}  pname:   [OUT] Array{Cchar, 1}   #  CUTEst.ubandh     Method .  ubandh  The ubandh subroutine extracts the elements which lie within a band of given semi-bandwidth out of the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.  For more information, run the shell command  man cutest_ubandh  Usage:  ubandh(io_err, n, x, semibandwidth, h_band, lbandh, max_semibandwidth)   io_err:            [OUT] Array{Cint, 1}  n:                 [IN] Array{Cint, 1}  x:                 [IN] Array{Cdouble, 1}  semibandwidth:     [IN] Array{Cint, 1}  h_band:            [OUT] Array{Cdouble, 2}  lbandh:            [IN] Array{Cint, 1}  max_semibandwidth: [OUT] Array{Cint, 1}   #  CUTEst.udh     Method .  udh  The udh subroutine evaluates the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_udh  Usage:  udh(io_err, n, x, lh1, h)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  lh1:     [IN] Array{Cint, 1}  h:       [OUT] Array{Cdouble, 2}   #  CUTEst.udimen     Method .  udimen  The udimen subroutine discovers how many variables are involved in the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_udimen  Usage:  udimen(io_err, input, n)   io_err:  [OUT] Array{Cint, 1}  input:   [IN] Array{Cint, 1}  n:       [OUT] Array{Cint, 1}   #  CUTEst.udimse     Method .  udimse  The udimse subroutine determine the number of nonzeros required to store the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element H_i involves a small subset of the rows of the Hessian matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_udimse  Usage:  udimse(io_err, ne, he_val_ne, he_row_ne)   io_err:    [OUT] Array{Cint, 1}  ne:        [OUT] Array{Cint, 1}  he_val_ne: [OUT] Array{Cint, 1}  he_row_ne: [OUT] Array{Cint, 1}   #  CUTEst.udimsh     Method .  udimsh  The udimsh subroutine determine the number of nonzeros required to store the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_udimsh  Usage:  udimsh(io_err, nnzh)   io_err:  [OUT] Array{Cint, 1}  nnzh:    [OUT] Array{Cint, 1}   #  CUTEst.ueh     Method .  ueh  The ueh subroutine evaluates the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element He involves a small subset of the rows of the Hessian matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_ueh  Usage:  ueh(io_err, n, x, ne, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row,  lhe_val, he_val, byrows)   io_err:     [OUT] Array{Cint, 1}  n:          [IN] Array{Cint, 1}  x:          [IN] Array{Cdouble, 1}  ne:         [OUT] Array{Cint, 1}  lhe_ptr:    [IN] Array{Cint, 1}  he_row_ptr: [OUT] Array{Cint, 1}  he_val_ptr: [OUT] Array{Cint, 1}  lhe_row:    [IN] Array{Cint, 1}  he_row:     [OUT] Array{Cint, 1}  lhe_val:    [IN] Array{Cint, 1}  he_val:     [OUT] Array{Cdouble, 1}  byrows:     [IN] Array{Cint, 1}   #  CUTEst.ufn     Method .  ufn  The ufn subroutine evaluates the value of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_ufn  Usage:  ufn(io_err, n, x, f)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  f:       [OUT] Array{Cdouble, 1}   #  CUTEst.ugr     Method .  ugr  The ugr subroutine evaluates the gradient of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_ugr  Usage:  ugr(io_err, n, x, g)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  g:       [OUT] Array{Cdouble, 1}   #  CUTEst.ugrdh     Method .  ugrdh  The ugrdh subroutine evaluates the gradient and Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a dense matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_ugrdh  Usage:  ugrdh(io_err, n, x, g, lh1, h)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  g:       [OUT] Array{Cdouble, 1}  lh1:     [IN] Array{Cint, 1}  h:       [OUT] Array{Cdouble, 2}   #  CUTEst.ugreh     Method .  ugreh  The ugreh subroutine evaluates the gradient and Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in finite element format H=e\u03a31He, where each square symmetric element H sub e involves a small subset of the rows of the Hessian matrix. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_ugreh  Usage:  ugreh(io_err, n, x, g, ne, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row,  lhe_val, he_val, byrows)   io_err:     [OUT] Array{Cint, 1}  n:          [IN] Array{Cint, 1}  x:          [IN] Array{Cdouble, 1}  g:          [OUT] Array{Cdouble, 1}  ne:         [OUT] Array{Cint, 1}  lhe_ptr:    [IN] Array{Cint, 1}  he_row_ptr: [OUT] Array{Cint, 1}  he_val_ptr: [OUT] Array{Cint, 1}  lhe_row:    [IN] Array{Cint, 1}  he_row:     [OUT] Array{Cint, 1}  lhe_val:    [IN] Array{Cint, 1}  he_val:     [OUT] Array{Cdouble, 1}  byrows:     [IN] Array{Cint, 1}   #  CUTEst.ugrsh     Method .  ugrsh  The ugrsh subroutine evaluates the gradient and Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.  For more information, run the shell command  man cutest_ugrsh  Usage:  ugrsh(io_err, n, x, g, nnzh, lh, h_val, h_row, h_col)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  g:       [OUT] Array{Cdouble, 1}  nnzh:    [OUT] Array{Cint, 1}  lh:      [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 1}  h_row:   [OUT] Array{Cint, 1}  h_col:   [OUT] Array{Cint, 1}   #  CUTEst.uhprod     Method .  uhprod  The uhprod subroutine forms the product of a vector with the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_uhprod  Usage:  uhprod(io_err, n, goth, x, vector, result)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  goth:    [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  vector:  [IN] Array{Cdouble, 1}  result:  [OUT] Array{Cdouble, 1}   #  CUTEst.unames     Method .  unames  The unames subroutine obtains the names of the problem and its variables. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_unames  Usage:  unames(io_err, n, pname, vname)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  pname:   [OUT] Array{Cchar, 1}  vname:   [OUT] Array{Cchar, 1}   #  CUTEst.uofg     Method .  uofg  The uofg subroutine evaluates the value of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly its gradient. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.  For more information, run the shell command  man cutest_uofg  Usage:  uofg(io_err, n, x, f, g, grad)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  f:       [OUT] Array{Cdouble, 1}  g:       [OUT] Array{Cdouble, 1}  grad:    [IN] Array{Cint, 1}   #  CUTEst.ureport     Method .  ureport  The ureport subroutine obtains statistics concerning function evaluation and CPU time used for unconstrained or bound-constrained optimization in a standardized format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.  For more information, run the shell command  man cutest_ureport  Usage:  ureport(io_err, calls, time)   io_err:  [OUT] Array{Cint, 1}  calls:   [OUT] Array{Cdouble, 1}  time:    [OUT] Array{Cdouble, 1}   #  CUTEst.usetup     Method .  usetup  The usetup subroutine sets up the correct data structures for subsequent computations in the case where the only possible constraints are bound constraints. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.  For more information, run the shell command  man cutest_usetup  Usage:  usetup(io_err, input, out, io_buffer, n, x, x_l, x_u)   io_err:    [OUT] Array{Cint, 1}  input:     [IN] Array{Cint, 1}  out:       [IN] Array{Cint, 1}  io_buffer: [IN] Array{Cint, 1}  n:         [IN] Array{Cint, 1}  x:         [OUT] Array{Cdouble, 1}  x_l:       [OUT] Array{Cdouble, 1}  x_u:       [OUT] Array{Cdouble, 1}   #  CUTEst.ush     Method .  ush  The ush subroutine evaluates the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. This Hessian matrix is stored as a sparse matrix in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group- partially separable.  For more information, run the shell command  man cutest_ush  Usage:  ush(io_err, n, x, nnzh, lh, h_val, h_row, h_col)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x:       [IN] Array{Cdouble, 1}  nnzh:    [OUT] Array{Cint, 1}  lh:      [IN] Array{Cint, 1}  h_val:   [OUT] Array{Cdouble, 1}  h_row:   [OUT] Array{Cint, 1}  h_col:   [OUT] Array{Cint, 1}   #  CUTEst.ushp     Method .  ushp  The ushp subroutine evaluates the sparsity pattern of the Hessian matrix of the objective function of the problem, decoded from a SIF file by the script sifdecoder, in coordinate format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_ushp  Usage:  ushp(io_err, n, nnzh, lh, h_row, h_col)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  nnzh:    [OUT] Array{Cint, 1}  lh:      [IN] Array{Cint, 1}  h_row:   [OUT] Array{Cint, 1}  h_col:   [OUT] Array{Cint, 1}   #  CUTEst.ushprod     Method .  ushprod  The ushprod subroutine forms the product of a sparse vector with the Hessian matrix of the objective function of the problem decoded from a SIF file by the script sifdecoder at the point X. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_ushprod  Usage:  ushprod(io_err, n, goth, x, nnz_vector, index_nz_vector, vector, nnz_result,  index_nz_result, result)   io_err:          [OUT] Array{Cint, 1}  n:               [IN] Array{Cint, 1}  goth:            [IN] Array{Cint, 1}  x:               [IN] Array{Cdouble, 1}  nnz_vector:      [IN] Array{Cint, 1}  index_nz_vector: [IN] Array{Cint, 1}  vector:          [IN] Array{Cdouble, 1}  nnz_result:      [OUT] Array{Cint, 1}  index_nz_result: [OUT] Array{Cint, 1}  result:          [OUT] Array{Cdouble, 1}   #  CUTEst.uterminate     Method .  uterminate  The uterminate subroutine deallocates all workspace arrays created since the last call to usetup.  For more information, run the shell command  man cutest_uterminate  Usage:  uterminate(io_err)   io_err:  [OUT] Array{Cint, 1}   #  CUTEst.uvartype     Method .  uvartype  The uvartype subroutine determines the type (continuous, 0-1, integer) of each variable involved in the problem decoded from a SIF file by the script sifdecoder. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to the simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable.  For more information, run the shell command  man cutest_uvartype  Usage:  uvartype(io_err, n, x_type)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  x_type:  [OUT] Array{Cint, 1}   #  CUTEst.varnames     Method .  varnames  The varnames subroutine obtains the names of the problem variables. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.  For more information, run the shell command  man cutest_varnames  Usage:  varnames(io_err, n, vname)   io_err:  [OUT] Array{Cint, 1}  n:       [IN] Array{Cint, 1}  vname:   [OUT] Array{Cchar, 1}   #  CUTEst.ccfg!     Method .  ccfg!(nlp, x, c, jtrans, lcjac1, lcjac2, cjac, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  c:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lcjac1:  [IN] Int  lcjac2:  [IN] Int  cjac:    [OUT] Array{Float64, 2}  grad:    [IN] Bool   #  CUTEst.ccfg!     Method .  ccfg!(n, m, x, c, jtrans, lcjac1, lcjac2, cjac, grad)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  c:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lcjac1:  [IN] Int  lcjac2:  [IN] Int  cjac:    [OUT] Array{Float64, 2}  grad:    [IN] Bool   #  CUTEst.ccfg     Method .  c, cjac = ccfg(nlp, x, jtrans, lcjac1, lcjac2, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  c:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lcjac1:  [IN] Int  lcjac2:  [IN] Int  cjac:    [OUT] Array{Float64, 2}  grad:    [IN] Bool   #  CUTEst.ccfg     Method .  c, cjac = ccfg(n, m, x, jtrans, lcjac1, lcjac2, grad)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  c:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lcjac1:  [IN] Int  lcjac2:  [IN] Int  cjac:    [OUT] Array{Float64, 2}  grad:    [IN] Bool   #  CUTEst.ccfsg!     Method .  nnzj = ccfsg!(nlp, x, c, j_val, j_var, j_fun, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  c:       [OUT] Array{Float64, 1}  nnzj:    [OUT] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.ccfsg!     Method .  nnzj = ccfsg!(n, m, x, c, lj, j_val, j_var, j_fun, grad)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  c:       [OUT] Array{Float64, 1}  nnzj:    [OUT] Int  lj:      [IN] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.ccfsg     Method .  c, nnzj, j_val, j_var, j_fun = ccfsg(nlp, x, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  c:       [OUT] Array{Float64, 1}  nnzj:    [OUT] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.ccfsg     Method .  c, nnzj, j_val, j_var, j_fun = ccfsg(n, m, x, lj, grad)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  c:       [OUT] Array{Float64, 1}  nnzj:    [OUT] Int  lj:      [IN] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.cchprods!     Method .  cchprods!(nlp, goth, x, vector, lchp, chp_val, chp_ind, chp_ptr)   nlp:     [IN] CUTEstModel  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  lchp:    [IN] Int  chp_val: [OUT] Array{Float64, 1}  chp_ind: [IN] Array{Int, 1}  chp_ptr: [IN] Array{Int, 1}   #  CUTEst.cchprods!     Method .  cchprods!(n, m, goth, x, vector, lchp, chp_val, chp_ind, chp_ptr)   n:       [IN] Int  m:       [IN] Int  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  lchp:    [IN] Int  chp_val: [OUT] Array{Float64, 1}  chp_ind: [IN] Array{Int, 1}  chp_ptr: [IN] Array{Int, 1}   #  CUTEst.cchprods     Method .  chp_val = cchprods(nlp, goth, x, vector, lchp, chp_ind, chp_ptr)   nlp:     [IN] CUTEstModel  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  lchp:    [IN] Int  chp_val: [OUT] Array{Float64, 1}  chp_ind: [IN] Array{Int, 1}  chp_ptr: [IN] Array{Int, 1}   #  CUTEst.cchprods     Method .  chp_val = cchprods(n, m, goth, x, vector, lchp, chp_ind, chp_ptr)   n:       [IN] Int  m:       [IN] Int  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  lchp:    [IN] Int  chp_val: [OUT] Array{Float64, 1}  chp_ind: [IN] Array{Int, 1}  chp_ptr: [IN] Array{Int, 1}   #  CUTEst.ccifg!     Method .  ci = ccifg!(nlp, icon, x, gci, grad)   nlp:     [IN] CUTEstModel  icon:    [IN] Int  x:       [IN] Array{Float64, 1}  ci:      [OUT] Float64  gci:     [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.ccifg!     Method .  ci = ccifg!(n, icon, x, gci, grad)   n:       [IN] Int  icon:    [IN] Int  x:       [IN] Array{Float64, 1}  ci:      [OUT] Float64  gci:     [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.ccifg     Method .  ci, gci = ccifg(nlp, icon, x, grad)   nlp:     [IN] CUTEstModel  icon:    [IN] Int  x:       [IN] Array{Float64, 1}  ci:      [OUT] Float64  gci:     [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.ccifg     Method .  ci, gci = ccifg(n, icon, x, grad)   n:       [IN] Int  icon:    [IN] Int  x:       [IN] Array{Float64, 1}  ci:      [OUT] Float64  gci:     [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.ccifsg!     Method .  ci, nnzgci = ccifsg!(nlp, icon, x, lgci, gci_val, gci_var, grad)   nlp:     [IN] CUTEstModel  icon:    [IN] Int  x:       [IN] Array{Float64, 1}  ci:      [OUT] Float64  nnzgci:  [OUT] Int  lgci:    [IN] Int  gci_val: [OUT] Array{Float64, 1}  gci_var: [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.ccifsg!     Method .  ci, nnzgci = ccifsg!(n, icon, x, lgci, gci_val, gci_var, grad)   n:       [IN] Int  icon:    [IN] Int  x:       [IN] Array{Float64, 1}  ci:      [OUT] Float64  nnzgci:  [OUT] Int  lgci:    [IN] Int  gci_val: [OUT] Array{Float64, 1}  gci_var: [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.ccifsg     Method .  ci, nnzgci, gci_val, gci_var = ccifsg(nlp, icon, x, lgci, grad)   nlp:     [IN] CUTEstModel  icon:    [IN] Int  x:       [IN] Array{Float64, 1}  ci:      [OUT] Float64  nnzgci:  [OUT] Int  lgci:    [IN] Int  gci_val: [OUT] Array{Float64, 1}  gci_var: [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.ccifsg     Method .  ci, nnzgci, gci_val, gci_var = ccifsg(n, icon, x, lgci, grad)   n:       [IN] Int  icon:    [IN] Int  x:       [IN] Array{Float64, 1}  ci:      [OUT] Float64  nnzgci:  [OUT] Int  lgci:    [IN] Int  gci_val: [OUT] Array{Float64, 1}  gci_var: [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.cdh!     Method .  cdh!(nlp, x, y, lh1, h_val)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cdh!     Method .  cdh!(n, m, x, y, lh1, h_val)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cdh     Method .  h_val = cdh(nlp, x, y, lh1)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cdh     Method .  h_val = cdh(n, m, x, y, lh1)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cdhc!     Method .  cdhc!(nlp, x, y, lh1, h_val)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cdhc!     Method .  cdhc!(n, m, x, y, lh1, h_val)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cdhc     Method .  h_val = cdhc(nlp, x, y, lh1)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cdhc     Method .  h_val = cdhc(n, m, x, y, lh1)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cdimchp     Method .  nnzchp = cdimchp(nlp)   nlp:     [IN] CUTEstModel  nnzchp:  [OUT] Int   #  CUTEst.cdimchp     Method .  nnzchp = cdimchp()   nnzchp:  [OUT] Int   #  CUTEst.cdimen     Method .  n, m = cdimen(input)   input:   [IN] Int  n:       [OUT] Int  m:       [OUT] Int   #  CUTEst.cdimse     Method .  ne, he_val_ne, he_row_ne = cdimse()   ne:        [OUT] Int  he_val_ne: [OUT] Int  he_row_ne: [OUT] Int   #  CUTEst.cdimsh     Method .  nnzh = cdimsh()   nnzh:    [OUT] Int   #  CUTEst.cdimsj     Method .  nnzj = cdimsj()   nnzj:    [OUT] Int   #  CUTEst.ceh!     Method .  ne = ceh!(nlp, x, y, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   nlp:        [IN] CUTEstModel  x:          [IN] Array{Float64, 1}  y:          [IN] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ceh!     Method .  ne = ceh!(n, m, x, y, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   n:          [IN] Int  m:          [IN] Int  x:          [IN] Array{Float64, 1}  y:          [IN] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ceh     Method .  ne, he_row_ptr, he_val_ptr, he_row, he_val = ceh(nlp, x, y, lhe_ptr, lhe_row, lhe_val, byrows)   nlp:        [IN] CUTEstModel  x:          [IN] Array{Float64, 1}  y:          [IN] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ceh     Method .  ne, he_row_ptr, he_val_ptr, he_row, he_val = ceh(n, m, x, y, lhe_ptr, lhe_row, lhe_val, byrows)   n:          [IN] Int  m:          [IN] Int  x:          [IN] Array{Float64, 1}  y:          [IN] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.cfn!     Method .  f = cfn!(nlp, x, c)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  c:       [OUT] Array{Float64, 1}   #  CUTEst.cfn!     Method .  f = cfn!(n, m, x, c)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  c:       [OUT] Array{Float64, 1}   #  CUTEst.cfn     Method .  f, c = cfn(nlp, x)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  c:       [OUT] Array{Float64, 1}   #  CUTEst.cfn     Method .  f, c = cfn(n, m, x)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  c:       [OUT] Array{Float64, 1}   #  CUTEst.cgr!     Method .  cgr!(nlp, x, y, grlagf, g, jtrans, lj1, lj2, j_val)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  g:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lj1:     [IN] Int  lj2:     [IN] Int  j_val:   [OUT] Array{Float64, 2}   #  CUTEst.cgr!     Method .  cgr!(n, m, x, y, grlagf, g, jtrans, lj1, lj2, j_val)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  g:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lj1:     [IN] Int  lj2:     [IN] Int  j_val:   [OUT] Array{Float64, 2}   #  CUTEst.cgr     Method .  g, j_val = cgr(nlp, x, y, grlagf, jtrans, lj1, lj2)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  g:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lj1:     [IN] Int  lj2:     [IN] Int  j_val:   [OUT] Array{Float64, 2}   #  CUTEst.cgr     Method .  g, j_val = cgr(n, m, x, y, grlagf, jtrans, lj1, lj2)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  g:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lj1:     [IN] Int  lj2:     [IN] Int  j_val:   [OUT] Array{Float64, 2}   #  CUTEst.cgrdh!     Method .  cgrdh!(nlp, x, y, grlagf, g, jtrans, lj1, lj2, j_val, lh1, h_val)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  g:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lj1:     [IN] Int  lj2:     [IN] Int  j_val:   [OUT] Array{Float64, 2}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cgrdh!     Method .  cgrdh!(n, m, x, y, grlagf, g, jtrans, lj1, lj2, j_val, lh1, h_val)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  g:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lj1:     [IN] Int  lj2:     [IN] Int  j_val:   [OUT] Array{Float64, 2}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cgrdh     Method .  g, j_val, h_val = cgrdh(nlp, x, y, grlagf, jtrans, lj1, lj2, lh1)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  g:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lj1:     [IN] Int  lj2:     [IN] Int  j_val:   [OUT] Array{Float64, 2}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.cgrdh     Method .  g, j_val, h_val = cgrdh(n, m, x, y, grlagf, jtrans, lj1, lj2, lh1)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  g:       [OUT] Array{Float64, 1}  jtrans:  [IN] Bool  lj1:     [IN] Int  lj2:     [IN] Int  j_val:   [OUT] Array{Float64, 2}  lh1:     [IN] Int  h_val:   [OUT] Array{Float64, 2}   #  CUTEst.chcprod!     Method .  chcprod!(nlp, goth, x, y, vector, result)   nlp:     [IN] CUTEstModel  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.chcprod!     Method .  chcprod!(n, m, goth, x, y, vector, result)   n:       [IN] Int  m:       [IN] Int  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.chcprod     Method .  result = chcprod(nlp, goth, x, y, vector)   nlp:     [IN] CUTEstModel  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.chcprod     Method .  result = chcprod(n, m, goth, x, y, vector)   n:       [IN] Int  m:       [IN] Int  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.chprod!     Method .  chprod!(nlp, goth, x, y, vector, result)   nlp:     [IN] CUTEstModel  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.chprod!     Method .  chprod!(n, m, goth, x, y, vector, result)   n:       [IN] Int  m:       [IN] Int  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.chprod     Method .  result = chprod(nlp, goth, x, y, vector)   nlp:     [IN] CUTEstModel  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.chprod     Method .  result = chprod(n, m, goth, x, y, vector)   n:       [IN] Int  m:       [IN] Int  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.cidh!     Method .  cidh!(nlp, x, iprob, lh1, h)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  iprob:   [IN] Int  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.cidh!     Method .  cidh!(n, x, iprob, lh1, h)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  iprob:   [IN] Int  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.cidh     Method .  h = cidh(nlp, x, iprob, lh1)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  iprob:   [IN] Int  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.cidh     Method .  h = cidh(n, x, iprob, lh1)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  iprob:   [IN] Int  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.cish!     Method .  nnzh = cish!(nlp, x, iprob, h_val, h_row, h_col)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  iprob:   [IN] Int  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cish!     Method .  nnzh = cish!(n, x, iprob, lh, h_val, h_row, h_col)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  iprob:   [IN] Int  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cish     Method .  nnzh, h_val, h_row, h_col = cish(nlp, x, iprob)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  iprob:   [IN] Int  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cish     Method .  nnzh, h_val, h_row, h_col = cish(n, x, iprob, lh)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  iprob:   [IN] Int  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cjprod!     Method .  cjprod!(nlp, gotj, jtrans, x, vector, lvector, result, lresult)   nlp:     [IN] CUTEstModel  gotj:    [IN] Bool  jtrans:  [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  lvector: [IN] Int  result:  [OUT] Array{Float64, 1}  lresult: [IN] Int   #  CUTEst.cjprod!     Method .  cjprod!(n, m, gotj, jtrans, x, vector, lvector, result, lresult)   n:       [IN] Int  m:       [IN] Int  gotj:    [IN] Bool  jtrans:  [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  lvector: [IN] Int  result:  [OUT] Array{Float64, 1}  lresult: [IN] Int   #  CUTEst.cjprod     Method .  result = cjprod(nlp, gotj, jtrans, x, vector, lvector, lresult)   nlp:     [IN] CUTEstModel  gotj:    [IN] Bool  jtrans:  [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  lvector: [IN] Int  result:  [OUT] Array{Float64, 1}  lresult: [IN] Int   #  CUTEst.cjprod     Method .  result = cjprod(n, m, gotj, jtrans, x, vector, lvector, lresult)   n:       [IN] Int  m:       [IN] Int  gotj:    [IN] Bool  jtrans:  [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  lvector: [IN] Int  result:  [OUT] Array{Float64, 1}  lresult: [IN] Int   #  CUTEst.clfg!     Method .  f = clfg!(nlp, x, y, g, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.clfg!     Method .  f = clfg!(n, m, x, y, g, grad)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.clfg     Method .  f, g = clfg(nlp, x, y, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.clfg     Method .  f, g = clfg(n, m, x, y, grad)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.cnames!     Method .  pname = cnames!(nlp, vname, cname)   nlp:     [IN] CUTEstModel  pname:   [OUT] UInt8  vname:   [OUT] Array{UInt8, 1}  cname:   [OUT] Array{UInt8, 1}   #  CUTEst.cnames!     Method .  pname = cnames!(n, m, vname, cname)   n:       [IN] Int  m:       [IN] Int  pname:   [OUT] UInt8  vname:   [OUT] Array{UInt8, 1}  cname:   [OUT] Array{UInt8, 1}   #  CUTEst.cnames     Method .  pname, vname, cname = cnames(nlp)   nlp:     [IN] CUTEstModel  pname:   [OUT] UInt8  vname:   [OUT] Array{UInt8, 1}  cname:   [OUT] Array{UInt8, 1}   #  CUTEst.cnames     Method .  pname, vname, cname = cnames(n, m)   n:       [IN] Int  m:       [IN] Int  pname:   [OUT] UInt8  vname:   [OUT] Array{UInt8, 1}  cname:   [OUT] Array{UInt8, 1}   #  CUTEst.cofg!     Method .  f = cofg!(nlp, x, g, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.cofg!     Method .  f = cofg!(n, x, g, grad)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.cofg     Method .  f, g = cofg(nlp, x, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.cofg     Method .  f, g = cofg(n, x, grad)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.cofsg!     Method .  f, nnzg = cofsg!(nlp, x, lg, g_val, g_var, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  nnzg:    [OUT] Int  lg:      [IN] Int  g_val:   [OUT] Array{Float64, 1}  g_var:   [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.cofsg!     Method .  f, nnzg = cofsg!(n, x, lg, g_val, g_var, grad)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  nnzg:    [OUT] Int  lg:      [IN] Int  g_val:   [OUT] Array{Float64, 1}  g_var:   [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.cofsg     Method .  f, nnzg, g_val, g_var = cofsg(nlp, x, lg, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  nnzg:    [OUT] Int  lg:      [IN] Int  g_val:   [OUT] Array{Float64, 1}  g_var:   [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.cofsg     Method .  f, nnzg, g_val, g_var = cofsg(n, x, lg, grad)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  nnzg:    [OUT] Int  lg:      [IN] Int  g_val:   [OUT] Array{Float64, 1}  g_var:   [OUT] Array{Int, 1}  grad:    [IN] Bool   #  CUTEst.connames!     Method .  connames!(nlp, cname)   nlp:     [IN] CUTEstModel  cname:   [OUT] Array{UInt8, 1}   #  CUTEst.connames!     Method .  connames!(m, cname)   m:       [IN] Int  cname:   [OUT] Array{UInt8, 1}   #  CUTEst.connames     Method .  cname = connames(nlp)   nlp:     [IN] CUTEstModel  cname:   [OUT] Array{UInt8, 1}   #  CUTEst.connames     Method .  cname = connames(m)   m:       [IN] Int  cname:   [OUT] Array{UInt8, 1}   #  CUTEst.creport!     Method .  creport!(calls, time)   calls:   [OUT] Array{Float64, 1}  time:    [OUT] Array{Float64, 1}   #  CUTEst.creport!     Method .  creport!(nlp, calls, time)   nlp:     [IN] CUTEstModel  calls:   [OUT] Array{Float64, 1}  time:    [OUT] Array{Float64, 1}   #  CUTEst.creport     Method .  calls, time = creport(nlp)   nlp:     [IN] CUTEstModel  calls:   [OUT] Array{Float64, 1}  time:    [OUT] Array{Float64, 1}   #  CUTEst.creport     Method .  calls, time = creport()   calls:   [OUT] Array{Float64, 1}  time:    [OUT] Array{Float64, 1}   #  CUTEst.csetup!     Method .  csetup!(input, out, io_buffer, n, m, x, x_l, x_u, y, c_l, c_u, equatn, linear, e_order, l_order, v_order)   input:     [IN] Int  out:       [IN] Int  io_buffer: [IN] Int  n:         [IN] Int  m:         [IN] Int  x:         [OUT] Array{Float64, 1}  x_l:       [OUT] Array{Float64, 1}  x_u:       [OUT] Array{Float64, 1}  y:         [OUT] Array{Float64, 1}  c_l:       [OUT] Array{Float64, 1}  c_u:       [OUT] Array{Float64, 1}  equatn:    [OUT] Array{Bool, 1}  linear:    [OUT] Array{Bool, 1}  e_order:   [IN] Int  l_order:   [IN] Int  v_order:   [IN] Int   #  CUTEst.csetup     Method .  x, x_l, x_u, y, c_l, c_u, equatn, linear = csetup(input, out, io_buffer, n, m, e_order, l_order, v_order)   input:     [IN] Int  out:       [IN] Int  io_buffer: [IN] Int  n:         [IN] Int  m:         [IN] Int  x:         [OUT] Array{Float64, 1}  x_l:       [OUT] Array{Float64, 1}  x_u:       [OUT] Array{Float64, 1}  y:         [OUT] Array{Float64, 1}  c_l:       [OUT] Array{Float64, 1}  c_u:       [OUT] Array{Float64, 1}  equatn:    [OUT] Array{Bool, 1}  linear:    [OUT] Array{Bool, 1}  e_order:   [IN] Int  l_order:   [IN] Int  v_order:   [IN] Int   #  CUTEst.csgr!     Method .  nnzj = csgr!(nlp, x, y, grlagf, j_val, j_var, j_fun)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  nnzj:    [OUT] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}   #  CUTEst.csgr!     Method .  nnzj = csgr!(n, m, x, y, grlagf, lj, j_val, j_var, j_fun)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  nnzj:    [OUT] Int  lj:      [IN] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}   #  CUTEst.csgr     Method .  nnzj, j_val, j_var, j_fun = csgr(nlp, x, y, grlagf)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  nnzj:    [OUT] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}   #  CUTEst.csgr     Method .  nnzj, j_val, j_var, j_fun = csgr(n, m, x, y, grlagf, lj)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  nnzj:    [OUT] Int  lj:      [IN] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}   #  CUTEst.csgreh!     Method .  nnzj, ne = csgreh!(nlp, x, y, grlagf, j_val, j_var, j_fun, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   nlp:        [IN] CUTEstModel  x:          [IN] Array{Float64, 1}  y:          [IN] Array{Float64, 1}  grlagf:     [IN] Bool  nnzj:       [OUT] Int  j_val:      [OUT] Array{Float64, 1}  j_var:      [OUT] Array{Int, 1}  j_fun:      [OUT] Array{Int, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.csgreh!     Method .  nnzj, ne = csgreh!(n, m, x, y, grlagf, lj, j_val, j_var, j_fun, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   n:          [IN] Int  m:          [IN] Int  x:          [IN] Array{Float64, 1}  y:          [IN] Array{Float64, 1}  grlagf:     [IN] Bool  nnzj:       [OUT] Int  lj:         [IN] Int  j_val:      [OUT] Array{Float64, 1}  j_var:      [OUT] Array{Int, 1}  j_fun:      [OUT] Array{Int, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.csgreh     Method .  nnzj, j_val, j_var, j_fun, ne, he_row_ptr, he_val_ptr, he_row, he_val = csgreh(nlp, x, y, grlagf, lhe_ptr, lhe_row, lhe_val, byrows)   nlp:        [IN] CUTEstModel  x:          [IN] Array{Float64, 1}  y:          [IN] Array{Float64, 1}  grlagf:     [IN] Bool  nnzj:       [OUT] Int  j_val:      [OUT] Array{Float64, 1}  j_var:      [OUT] Array{Int, 1}  j_fun:      [OUT] Array{Int, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.csgreh     Method .  nnzj, j_val, j_var, j_fun, ne, he_row_ptr, he_val_ptr, he_row, he_val = csgreh(n, m, x, y, grlagf, lj, lhe_ptr, lhe_row, lhe_val, byrows)   n:          [IN] Int  m:          [IN] Int  x:          [IN] Array{Float64, 1}  y:          [IN] Array{Float64, 1}  grlagf:     [IN] Bool  nnzj:       [OUT] Int  lj:         [IN] Int  j_val:      [OUT] Array{Float64, 1}  j_var:      [OUT] Array{Int, 1}  j_fun:      [OUT] Array{Int, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.csgrsh!     Method .  nnzj, nnzh = csgrsh!(nlp, x, y, grlagf, j_val, j_var, j_fun, h_val, h_row, h_col)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  nnzj:    [OUT] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.csgrsh!     Method .  nnzj, nnzh = csgrsh!(n, m, x, y, grlagf, lj, j_val, j_var, j_fun, lh, h_val, h_row, h_col)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  nnzj:    [OUT] Int  lj:      [IN] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.csgrsh     Method .  nnzj, j_val, j_var, j_fun, nnzh, h_val, h_row, h_col = csgrsh(nlp, x, y, grlagf)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  nnzj:    [OUT] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.csgrsh     Method .  nnzj, j_val, j_var, j_fun, nnzh, h_val, h_row, h_col = csgrsh(n, m, x, y, grlagf, lj, lh)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  grlagf:  [IN] Bool  nnzj:    [OUT] Int  lj:      [IN] Int  j_val:   [OUT] Array{Float64, 1}  j_var:   [OUT] Array{Int, 1}  j_fun:   [OUT] Array{Int, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.csh!     Method .  nnzh = csh!(nlp, x, y, h_val, h_row, h_col)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.csh!     Method .  nnzh = csh!(n, m, x, y, lh, h_val, h_row, h_col)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.csh     Method .  nnzh, h_val, h_row, h_col = csh(nlp, x, y)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.csh     Method .  nnzh, h_val, h_row, h_col = csh(n, m, x, y, lh)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshc!     Method .  nnzh = cshc!(nlp, x, y, h_val, h_row, h_col)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshc!     Method .  nnzh = cshc!(n, m, x, y, lh, h_val, h_row, h_col)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshc     Method .  nnzh, h_val, h_row, h_col = cshc(nlp, x, y)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshc     Method .  nnzh, h_val, h_row, h_col = cshc(n, m, x, y, lh)   n:       [IN] Int  m:       [IN] Int  x:       [IN] Array{Float64, 1}  y:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshcprod!     Method .  nnz_result = cshcprod!(nlp, goth, x, y, nnz_vector, index_nz_vector, vector, index_nz_result, result)   nlp:             [IN] CUTEstModel  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  y:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.cshcprod!     Method .  nnz_result = cshcprod!(n, m, goth, x, y, nnz_vector, index_nz_vector, vector, index_nz_result, result)   n:               [IN] Int  m:               [IN] Int  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  y:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.cshcprod     Method .  nnz_result, index_nz_result, result = cshcprod(nlp, goth, x, y, nnz_vector, index_nz_vector, vector)   nlp:             [IN] CUTEstModel  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  y:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.cshcprod     Method .  nnz_result, index_nz_result, result = cshcprod(n, m, goth, x, y, nnz_vector, index_nz_vector, vector)   n:               [IN] Int  m:               [IN] Int  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  y:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.cshp!     Method .  nnzh = cshp!(nlp, h_row, h_col)   nlp:     [IN] CUTEstModel  nnzh:    [OUT] Int  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshp!     Method .  nnzh = cshp!(n, lh, h_row, h_col)   n:       [IN] Int  nnzh:    [OUT] Int  lh:      [IN] Int  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshp     Method .  nnzh, h_row, h_col = cshp(nlp)   nlp:     [IN] CUTEstModel  nnzh:    [OUT] Int  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshp     Method .  nnzh, h_row, h_col = cshp(n, lh)   n:       [IN] Int  nnzh:    [OUT] Int  lh:      [IN] Int  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.cshprod!     Method .  nnz_result = cshprod!(nlp, goth, x, y, nnz_vector, index_nz_vector, vector, index_nz_result, result)   nlp:             [IN] CUTEstModel  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  y:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.cshprod!     Method .  nnz_result = cshprod!(n, m, goth, x, y, nnz_vector, index_nz_vector, vector, index_nz_result, result)   n:               [IN] Int  m:               [IN] Int  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  y:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.cshprod     Method .  nnz_result, index_nz_result, result = cshprod(nlp, goth, x, y, nnz_vector, index_nz_vector, vector)   nlp:             [IN] CUTEstModel  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  y:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.cshprod     Method .  nnz_result, index_nz_result, result = cshprod(n, m, goth, x, y, nnz_vector, index_nz_vector, vector)   n:               [IN] Int  m:               [IN] Int  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  y:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.csjprod!     Method .  nnz_result = csjprod!(nlp, gotj, jtrans, x, nnz_vector, index_nz_vector, vector, lvector, index_nz_result, result, lresult)   nlp:             [IN] CUTEstModel  gotj:            [IN] Bool  jtrans:          [IN] Bool  x:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  lvector:         [IN] Int  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}  lresult:         [IN] Int   #  CUTEst.csjprod!     Method .  nnz_result = csjprod!(n, m, gotj, jtrans, x, nnz_vector, index_nz_vector, vector, lvector, index_nz_result, result, lresult)   n:               [IN] Int  m:               [IN] Int  gotj:            [IN] Bool  jtrans:          [IN] Bool  x:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  lvector:         [IN] Int  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}  lresult:         [IN] Int   #  CUTEst.csjprod     Method .  nnz_result, index_nz_result, result = csjprod(nlp, gotj, jtrans, x, nnz_vector, index_nz_vector, vector, lvector, lresult)   nlp:             [IN] CUTEstModel  gotj:            [IN] Bool  jtrans:          [IN] Bool  x:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  lvector:         [IN] Int  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}  lresult:         [IN] Int   #  CUTEst.csjprod     Method .  nnz_result, index_nz_result, result = csjprod(n, m, gotj, jtrans, x, nnz_vector, index_nz_vector, vector, lvector, lresult)   n:               [IN] Int  m:               [IN] Int  gotj:            [IN] Bool  jtrans:          [IN] Bool  x:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  lvector:         [IN] Int  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}  lresult:         [IN] Int   #  CUTEst.cstats     Method .  #  CUTEst.cstats     Method .  #  CUTEst.cterminate     Method .  cterminate()  #  CUTEst.cvartype!     Method .  cvartype!(n, x_type)   n:       [IN] Int  x_type:  [OUT] Array{Int, 1}   #  CUTEst.cvartype     Method .  x_type = cvartype(n)   n:       [IN] Int  x_type:  [OUT] Array{Int, 1}   #  CUTEst.pname     Method .  pname = pname(nlp, input)   nlp:     [IN] CUTEstModel  input:   [IN] Int  pname:   [OUT] UInt8   #  CUTEst.pname     Method .  pname = pname(input)   input:   [IN] Int  pname:   [OUT] UInt8   #  CUTEst.probname     Method .  pname = probname(nlp)   nlp:     [IN] CUTEstModel  pname:   [OUT] UInt8   #  CUTEst.probname     Method .  pname = probname()   pname:   [OUT] UInt8   #  CUTEst.ubandh!     Method .  max_semibandwidth = ubandh!(nlp, x, semibandwidth, h_band, lbandh)   nlp:               [IN] CUTEstModel  x:                 [IN] Array{Float64, 1}  semibandwidth:     [IN] Int  h_band:            [OUT] Array{Float64, 2}  lbandh:            [IN] Int  max_semibandwidth: [OUT] Int   #  CUTEst.ubandh!     Method .  max_semibandwidth = ubandh!(n, x, semibandwidth, h_band, lbandh)   n:                 [IN] Int  x:                 [IN] Array{Float64, 1}  semibandwidth:     [IN] Int  h_band:            [OUT] Array{Float64, 2}  lbandh:            [IN] Int  max_semibandwidth: [OUT] Int   #  CUTEst.ubandh     Method .  h_band, max_semibandwidth = ubandh(nlp, x, semibandwidth, lbandh)   nlp:               [IN] CUTEstModel  x:                 [IN] Array{Float64, 1}  semibandwidth:     [IN] Int  h_band:            [OUT] Array{Float64, 2}  lbandh:            [IN] Int  max_semibandwidth: [OUT] Int   #  CUTEst.ubandh     Method .  h_band, max_semibandwidth = ubandh(n, x, semibandwidth, lbandh)   n:                 [IN] Int  x:                 [IN] Array{Float64, 1}  semibandwidth:     [IN] Int  h_band:            [OUT] Array{Float64, 2}  lbandh:            [IN] Int  max_semibandwidth: [OUT] Int   #  CUTEst.udh!     Method .  udh!(nlp, x, lh1, h)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.udh!     Method .  udh!(n, x, lh1, h)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.udh     Method .  h = udh(nlp, x, lh1)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.udh     Method .  h = udh(n, x, lh1)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.udimen     Method .  n = udimen(input)   input:   [IN] Int  n:       [OUT] Int   #  CUTEst.udimse     Method .  ne, he_val_ne, he_row_ne = udimse()   ne:        [OUT] Int  he_val_ne: [OUT] Int  he_row_ne: [OUT] Int   #  CUTEst.udimsh     Method .  nnzh = udimsh()   nnzh:    [OUT] Int   #  CUTEst.ueh!     Method .  ne = ueh!(nlp, x, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   nlp:        [IN] CUTEstModel  x:          [IN] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ueh!     Method .  ne = ueh!(n, x, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   n:          [IN] Int  x:          [IN] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ueh     Method .  ne, he_row_ptr, he_val_ptr, he_row, he_val = ueh(nlp, x, lhe_ptr, lhe_row, lhe_val, byrows)   nlp:        [IN] CUTEstModel  x:          [IN] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ueh     Method .  ne, he_row_ptr, he_val_ptr, he_row, he_val = ueh(n, x, lhe_ptr, lhe_row, lhe_val, byrows)   n:          [IN] Int  x:          [IN] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ufn     Method .  f = ufn(nlp, x)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64   #  CUTEst.ufn     Method .  f = ufn(n, x)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64   #  CUTEst.ugr!     Method .  ugr!(nlp, x, g)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}   #  CUTEst.ugr!     Method .  ugr!(n, x, g)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}   #  CUTEst.ugr     Method .  g = ugr(nlp, x)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}   #  CUTEst.ugr     Method .  g = ugr(n, x)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}   #  CUTEst.ugrdh!     Method .  ugrdh!(nlp, x, g, lh1, h)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.ugrdh!     Method .  ugrdh!(n, x, g, lh1, h)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.ugrdh     Method .  g, h = ugrdh(nlp, x, lh1)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.ugrdh     Method .  g, h = ugrdh(n, x, lh1)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}  lh1:     [IN] Int  h:       [OUT] Array{Float64, 2}   #  CUTEst.ugreh!     Method .  ne = ugreh!(nlp, x, g, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   nlp:        [IN] CUTEstModel  x:          [IN] Array{Float64, 1}  g:          [OUT] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ugreh!     Method .  ne = ugreh!(n, x, g, lhe_ptr, he_row_ptr, he_val_ptr, lhe_row, he_row, lhe_val, he_val, byrows)   n:          [IN] Int  x:          [IN] Array{Float64, 1}  g:          [OUT] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ugreh     Method .  g, ne, he_row_ptr, he_val_ptr, he_row, he_val = ugreh(nlp, x, lhe_ptr, lhe_row, lhe_val, byrows)   nlp:        [IN] CUTEstModel  x:          [IN] Array{Float64, 1}  g:          [OUT] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ugreh     Method .  g, ne, he_row_ptr, he_val_ptr, he_row, he_val = ugreh(n, x, lhe_ptr, lhe_row, lhe_val, byrows)   n:          [IN] Int  x:          [IN] Array{Float64, 1}  g:          [OUT] Array{Float64, 1}  ne:         [OUT] Int  lhe_ptr:    [IN] Int  he_row_ptr: [OUT] Array{Int, 1}  he_val_ptr: [OUT] Array{Int, 1}  lhe_row:    [IN] Int  he_row:     [OUT] Array{Int, 1}  lhe_val:    [IN] Int  he_val:     [OUT] Array{Float64, 1}  byrows:     [IN] Bool   #  CUTEst.ugrsh!     Method .  nnzh = ugrsh!(nlp, x, g, h_val, h_row, h_col)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ugrsh!     Method .  nnzh = ugrsh!(n, x, g, lh, h_val, h_row, h_col)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ugrsh     Method .  g, nnzh, h_val, h_row, h_col = ugrsh(nlp, x)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ugrsh     Method .  g, nnzh, h_val, h_row, h_col = ugrsh(n, x, lh)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  g:       [OUT] Array{Float64, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.uhprod!     Method .  uhprod!(nlp, goth, x, vector, result)   nlp:     [IN] CUTEstModel  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.uhprod!     Method .  uhprod!(n, goth, x, vector, result)   n:       [IN] Int  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.uhprod     Method .  result = uhprod(nlp, goth, x, vector)   nlp:     [IN] CUTEstModel  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.uhprod     Method .  result = uhprod(n, goth, x, vector)   n:       [IN] Int  goth:    [IN] Bool  x:       [IN] Array{Float64, 1}  vector:  [IN] Array{Float64, 1}  result:  [OUT] Array{Float64, 1}   #  CUTEst.unames!     Method .  pname = unames!(n, vname)   n:       [IN] Int  pname:   [OUT] UInt8  vname:   [OUT] Array{UInt8, 1}   #  CUTEst.unames     Method .  pname, vname = unames(n)   n:       [IN] Int  pname:   [OUT] UInt8  vname:   [OUT] Array{UInt8, 1}   #  CUTEst.uofg!     Method .  f = uofg!(nlp, x, g, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.uofg!     Method .  f = uofg!(n, x, g, grad)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.uofg     Method .  f, g = uofg(nlp, x, grad)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.uofg     Method .  f, g = uofg(n, x, grad)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  f:       [OUT] Float64  g:       [OUT] Array{Float64, 1}  grad:    [IN] Bool   #  CUTEst.ureport!     Method .  ureport!(calls, time)   calls:   [OUT] Array{Float64, 1}  time:    [OUT] Array{Float64, 1}   #  CUTEst.ureport!     Method .  ureport!(nlp, calls, time)   nlp:     [IN] CUTEstModel  calls:   [OUT] Array{Float64, 1}  time:    [OUT] Array{Float64, 1}   #  CUTEst.ureport     Method .  calls, time = ureport(nlp)   nlp:     [IN] CUTEstModel  calls:   [OUT] Array{Float64, 1}  time:    [OUT] Array{Float64, 1}   #  CUTEst.ureport     Method .  calls, time = ureport()   calls:   [OUT] Array{Float64, 1}  time:    [OUT] Array{Float64, 1}   #  CUTEst.usetup!     Method .  usetup!(input, out, io_buffer, n, x, x_l, x_u)   input:     [IN] Int  out:       [IN] Int  io_buffer: [IN] Int  n:         [IN] Int  x:         [OUT] Array{Float64, 1}  x_l:       [OUT] Array{Float64, 1}  x_u:       [OUT] Array{Float64, 1}   #  CUTEst.usetup     Method .  x, x_l, x_u = usetup(input, out, io_buffer, n)   input:     [IN] Int  out:       [IN] Int  io_buffer: [IN] Int  n:         [IN] Int  x:         [OUT] Array{Float64, 1}  x_l:       [OUT] Array{Float64, 1}  x_u:       [OUT] Array{Float64, 1}   #  CUTEst.ush!     Method .  nnzh = ush!(nlp, x, h_val, h_row, h_col)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ush!     Method .  nnzh = ush!(n, x, lh, h_val, h_row, h_col)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ush     Method .  nnzh, h_val, h_row, h_col = ush(nlp, x)   nlp:     [IN] CUTEstModel  x:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ush     Method .  nnzh, h_val, h_row, h_col = ush(n, x, lh)   n:       [IN] Int  x:       [IN] Array{Float64, 1}  nnzh:    [OUT] Int  lh:      [IN] Int  h_val:   [OUT] Array{Float64, 1}  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ushp!     Method .  nnzh = ushp!(nlp, h_row, h_col)   nlp:     [IN] CUTEstModel  nnzh:    [OUT] Int  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ushp!     Method .  nnzh = ushp!(n, lh, h_row, h_col)   n:       [IN] Int  nnzh:    [OUT] Int  lh:      [IN] Int  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ushp     Method .  nnzh, h_row, h_col = ushp(nlp)   nlp:     [IN] CUTEstModel  nnzh:    [OUT] Int  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ushp     Method .  nnzh, h_row, h_col = ushp(n, lh)   n:       [IN] Int  nnzh:    [OUT] Int  lh:      [IN] Int  h_row:   [OUT] Array{Int, 1}  h_col:   [OUT] Array{Int, 1}   #  CUTEst.ushprod!     Method .  nnz_result = ushprod!(nlp, goth, x, nnz_vector, index_nz_vector, vector, index_nz_result, result)   nlp:             [IN] CUTEstModel  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.ushprod!     Method .  nnz_result = ushprod!(n, goth, x, nnz_vector, index_nz_vector, vector, index_nz_result, result)   n:               [IN] Int  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.ushprod     Method .  nnz_result, index_nz_result, result = ushprod(nlp, goth, x, nnz_vector, index_nz_vector, vector)   nlp:             [IN] CUTEstModel  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.ushprod     Method .  nnz_result, index_nz_result, result = ushprod(n, goth, x, nnz_vector, index_nz_vector, vector)   n:               [IN] Int  goth:            [IN] Bool  x:               [IN] Array{Float64, 1}  nnz_vector:      [IN] Int  index_nz_vector: [IN] Array{Int, 1}  vector:          [IN] Array{Float64, 1}  nnz_result:      [OUT] Int  index_nz_result: [OUT] Array{Int, 1}  result:          [OUT] Array{Float64, 1}   #  CUTEst.uterminate     Method .  uterminate()  #  CUTEst.uvartype!     Method .  uvartype!(n, x_type)   n:       [IN] Int  x_type:  [OUT] Array{Int, 1}   #  CUTEst.uvartype     Method .  x_type = uvartype(n)   n:       [IN] Int  x_type:  [OUT] Array{Int, 1}   #  CUTEst.varnames!     Method .  varnames!(n, vname)   n:       [IN] Int  vname:   [OUT] Array{UInt8, 1}   #  CUTEst.varnames     Method .  vname = varnames(n)   n:       [IN] Int  vname:   [OUT] Array{UInt8, 1}", 
            "title": "Core and specialized API"
        }, 
        {
            "location": "/api/#internal", 
            "text": "#  CUTEst.sifdecoder     Method .  Decode problem and build shared library.  Optional arguments are passed directly to the SIF decoder. Example:      sifdecoder(\"DIXMAANJ\", \"-param\", \"M=30\") .", 
            "title": "Internal"
        }, 
        {
            "location": "/core/", 
            "text": "Working with CUTEst directly\n\n\nWhen working with CUTEst, we created a \ncore\n interface, which is essentially a wrapper for the CUTEst functions. You probably don't want to use that, because the NLPModels interface is much more friendlier, as just as useful. See its \ntutorial\n.\n\n\nCUTEst in Fortran defines functions called with \ncutest_u*\n or \ncutest_c*\n, for the unconstrained and constrained cases, respectively. For each of those, we dropped the \ncutest_\n, so the functions \ncutest_ufn\n and \ncutest_cfn\n are available as \nufn\n and \ncfn\n. To use then you have to convert the types using \nCint\n and \nCdouble\n, and pass arrays because of the underlying pointers in Fortran. In practice, there isn't much improvement in calling these or \nccall\ns.\n\n\nOnly use these functions if you really know what you're doing.\n\n\n\n\nSpecialized Interface\n\n\nThe specialized interface takes the original CUTEst's functions and make them more Julian. To explain, let's look at two simple CUTEst functions: \ncutest_ufn\n and \ncutest_cfn\n.\n\n\nThe original \ncutest_ufn\n function is defined as\n\n\nCALL \nCUTEST_ufn\n(\nstatus\n,\n \nn\n,\n \nX\n,\n \nf\n)\n\n\n\n\n\n\nwhere\n\n\n\n\nstatus\n (output) is an integer signalling whether there was some problem with   the CUTEst call;\n\n\nn\n (input) is number of variables in the problem, i.e., the dimension of \nX\n;\n\n\nX\n (input) is an array with the current estimate of the solution of the problem;\n\n\nf\n (output) is the value of the objective function evaluated at \nX\n.\n\n\n\n\nIn Julia, we have\n\n\nf\n \n=\n \nufn\n(\nn\n,\n \nx\n)\n\n\nf\n \n=\n \nufn\n(\nnlp\n,\n \nx\n)\n\n\n\n\n\n\nIn other words, a simplification of the original function, returning what is simple to return, and reducing the parameters to only what is needed. In addition, there is the option of using \nnlp\n instead of \nn\n, because \nnlp\n includes all this information.\n\n\nIn both cases, the problem would have to be decoded first. Decoding the problem manually is not advised, as you would have to keep track of the variables, bounds, sizes, library, and closing the problem yourself. It can be done through thorough thought, though.\n\n\nUsing \nnlp\n is better, because we can keep everything inside it.\n\n\nFor \ncutest_cfn\n, we would have\n\n\nCALL \nCUTEST_cfn\n(\nstatus\n,\n \nn\n,\n \nm\n,\n \nX\n,\n \nf\n,\n \nC\n)\n\n\n\n\n\n\nwhere\n\n\n\n\nstatus\n (output) is an integer signalling whether there was some problem with   the CUTEst call;\n\n\nn\n (input) is number of variables in the problem, i.e., the dimension of \nX\n;\n\n\nm\n (input) is number of constraints in the problem, i.e., the dimension of \nC\n;\n\n\nX\n (input) is an array with the current estimate of the solution of the problem;\n\n\nf\n (output) is the value of the objective function evaluated at \nX\n;\n\n\nC\n (output) is the value of the constraints function evaluated at \nX\n.\n\n\n\n\nIn Julia, we have\n\n\nf\n,\n \nc\n \n=\n \ncfn\n(\nn\n,\n \nm\n,\n \nx\n)\n\n\nf\n,\n \nc\n \n=\n \ncfn\n(\nnlp\n,\n \nx\n)\n\n\nf\n \n=\n \ncfn!\n(\nn\n,\n \nm\n,\n \nx\n,\n \nc\n)\n\n\nf\n \n=\n \ncfn!\n(\nnlp\n,\n \nx\n,\n \nc\n)\n\n\n\n\n\n\nAs before, we have a simplification of the original call. Also, again, we have the use of \nnlp\n instead of some fixed problem values. Notice how \nnlp\n substitutes more than one thing, making it easier to use because we don't have to remeber what is needed by the function, nor where it goes. When present, \nnlp\n is always the first argument.\n\n\nIn addition, there are two new functions here, obtained by addind a \n!\n in front of the function name. These functions modify the vector \nc\n storing the result in it. This can be done to save memory, since \nc\n will not be recreated. As a convention in Julia, every function that has a \n!\n in the end modifies some input.\n\n\n\n\nReference Guide\n\n\nThere are a lot of functions in CUTEst. To see them all, you can check the \nTechnical Report\n decribing them.\n\n\nBelow is a little guide to search the functions documentation. \nOnly some functions are shown.\n Remember that we are looking into problems in the form \n\\begin{align*} \\min \\quad & f(x) \\\\\n& c_L \\leq c(x) \\leq c_U \\\\\n& \\ell \\leq x \\leq u, \\end{align*}\n with Lagrangian \n\\begin{align*} L(x,y) = f(x) + y^Tc(x). \\end{align*}\n\n\n\n\nNote:\n \nx\n in the beginning of the function name means that both \nu\n and \nc\n versions exist.\n\n\n\n\n\n\n\n\nFunction\n\n\nSpecialized Interface Functions\n\n\n\n\n\n\n\n\n\n\n$f(x)$\n\n\nufn, uofg, cfn, cofg\n\n\n\n\n\n\n$\\nabla f(x)$\n\n\nugr, uofg, cfn, cofg\n\n\n\n\n\n\n$\\nabla^2 f(x)$\n\n\nudh, ugrdh, ush, ugrsh, uhprod\n\n\n\n\n\n\n$c(x)$\n\n\ncfn, ccfg, ccfsg, ccifg\n\n\n\n\n\n\n$J(x)$\n\n\nccfg, ccfsg, ccifg\n\n\n\n\n\n\n$\\nabla^2 L(x,y)$\n\n\ncdh, cgrdh, csh, cgrsh, chprod\n\n\n\n\n\n\n$\\nabla^2 (y^Tc(x))$\n\n\nchcprod\n\n\n\n\n\n\n\n\nExamples\n\n\nusing\n \nCUTEst\n\n\n\nnlp\n \n=\n \nCUTEstModel\n(\nROSENBR\n)\n\n\n\nx\n \n=\n \nnlp\n.\nmeta\n.\nx0\n\n\nfx\n \n=\n \nufn\n(\nnlp\n,\n \nx\n)\n\n\n\n\n\n\n24.199999999999996\n\n\n\n\n\nnnzj\n,\n \nhval\n,\n \nhrow\n,\n \nhcol\n \n=\n \nush\n(\nnlp\n,\n \nx\n)\n\n\n\n\n\n\n(3,[1330.0,480.0,200.0],Int32[1,1,2],Int32[1,2,2])\n\n\n\n\n\ncutest_finalize\n(\nnlp\n)\n\n\nnlp\n \n=\n \nCUTEstModel\n(\nHS51\n)\n\n\nx\n \n=\n \nnlp\n.\nmeta\n.\nx0\n\n\n\n# Checking documentation, in REPL use ?ccfsg\n\n\n@\ndoc\n \nccfsg\n\n\n\n\n\n\n```\nc, nnzj, j_val, j_var, j_fun = ccfsg(nlp, x, grad)\n```\n\n  * nlp:     [IN] CUTEstModel\n  * x:       [IN] Array{Float64, 1}\n  * c:       [OUT] Array{Float64, 1}\n  * nnzj:    [OUT] Int\n  * j_val:   [OUT] Array{Float64, 1}\n  * j_var:   [OUT] Array{Int, 1}\n  * j_fun:   [OUT] Array{Int, 1}\n  * grad:    [IN] Bool\n\n```\nc, nnzj, j_val, j_var, j_fun = ccfsg(n, m, x, lj, grad)\n```\n\n  * n:       [IN] Int\n  * m:       [IN] Int\n  * x:       [IN] Array{Float64, 1}\n  * c:       [OUT] Array{Float64, 1}\n  * nnzj:    [OUT] Int\n  * lj:      [IN] Int\n  * j_val:   [OUT] Array{Float64, 1}\n  * j_var:   [OUT] Array{Int, 1}\n  * j_fun:   [OUT] Array{Int, 1}\n  * grad:    [IN] Bool\n\n# ccfsg\n\nThe ccfsg subroutine evaluates the values of the constraint functions of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly their gradients in the constrained minimization case. The gradients are stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\nFor more information, run the shell command\n\n```\nman cutest_ccfsg\n```\n\nUsage:\n\n```\nccfsg(io_err, n, m, x, c, nnzj, lj, j_val, j_var, j_fun, grad)\n```\n\n  * io_err:  [OUT] Array{Cint, 1}\n  * n:       [IN] Array{Cint, 1}\n  * m:       [IN] Array{Cint, 1}\n  * x:       [IN] Array{Cdouble, 1}\n  * c:       [OUT] Array{Cdouble, 1}\n  * nnzj:    [OUT] Array{Cint, 1}\n  * lj:      [IN] Array{Cint, 1}\n  * j_val:   [OUT] Array{Cdouble, 1}\n  * j_var:   [OUT] Array{Cint, 1}\n  * j_fun:   [OUT] Array{Cint, 1}\n  * grad:    [IN] Array{Cint, 1}\n\n\n\n\n\nc\n,\n \nnnzj\n,\n \njval\n,\n \njvar\n,\n \njfun\n \n=\n \nccfsg\n(\nnlp\n,\n \nx\n,\n \ntrue\n)\n\n\nprintln\n(\nc = \n$c\n)\n\n\nprintln\n(\nJ = \n$(sparse(jvar, jfun, jval))\n)\n\n\n\n\n\n\nc = [0.0,0.0,0.0]\nJ =\n    [1, 1]  =  1.0\n    [2, 1]  =  3.0\n    [3, 2]  =  1.0\n    [4, 2]  =  1.0\n    [5, 2]  =  -2.0\n    [2, 3]  =  1.0\n    [5, 3]  =  -1.0\n\n\n\n\n\nCompare with the NLPModels interface\n\n\nc\n \n=\n \ncons\n(\nnlp\n,\n \nx\n)\n\n\nJ\n \n=\n \njac\n(\nnlp\n,\n \nx\n)\n\n\nprintln\n(\nc = \n$c\n)\n\n\nprintln\n(\nJ = \n$J\n)\n\n\n\n\n\n\nc = [0.0,0.0,0.0]\nJ =\n    [1, 1]  =  1.0\n    [1, 2]  =  3.0\n    [3, 2]  =  1.0\n    [2, 3]  =  1.0\n    [2, 4]  =  1.0\n    [2, 5]  =  -2.0\n    [3, 5]  =  -1.0\n\n\n\n\n\ncutest_finalize\n(\nnlp\n)", 
            "title": "Core"
        }, 
        {
            "location": "/core/#working-with-cutest-directly", 
            "text": "When working with CUTEst, we created a  core  interface, which is essentially a wrapper for the CUTEst functions. You probably don't want to use that, because the NLPModels interface is much more friendlier, as just as useful. See its  tutorial .  CUTEst in Fortran defines functions called with  cutest_u*  or  cutest_c* , for the unconstrained and constrained cases, respectively. For each of those, we dropped the  cutest_ , so the functions  cutest_ufn  and  cutest_cfn  are available as  ufn  and  cfn . To use then you have to convert the types using  Cint  and  Cdouble , and pass arrays because of the underlying pointers in Fortran. In practice, there isn't much improvement in calling these or  ccall s.  Only use these functions if you really know what you're doing.", 
            "title": "Working with CUTEst directly"
        }, 
        {
            "location": "/core/#specialized-interface", 
            "text": "The specialized interface takes the original CUTEst's functions and make them more Julian. To explain, let's look at two simple CUTEst functions:  cutest_ufn  and  cutest_cfn .  The original  cutest_ufn  function is defined as  CALL  CUTEST_ufn ( status ,   n ,   X ,   f )   where   status  (output) is an integer signalling whether there was some problem with   the CUTEst call;  n  (input) is number of variables in the problem, i.e., the dimension of  X ;  X  (input) is an array with the current estimate of the solution of the problem;  f  (output) is the value of the objective function evaluated at  X .   In Julia, we have  f   =   ufn ( n ,   x )  f   =   ufn ( nlp ,   x )   In other words, a simplification of the original function, returning what is simple to return, and reducing the parameters to only what is needed. In addition, there is the option of using  nlp  instead of  n , because  nlp  includes all this information.  In both cases, the problem would have to be decoded first. Decoding the problem manually is not advised, as you would have to keep track of the variables, bounds, sizes, library, and closing the problem yourself. It can be done through thorough thought, though.  Using  nlp  is better, because we can keep everything inside it.  For  cutest_cfn , we would have  CALL  CUTEST_cfn ( status ,   n ,   m ,   X ,   f ,   C )   where   status  (output) is an integer signalling whether there was some problem with   the CUTEst call;  n  (input) is number of variables in the problem, i.e., the dimension of  X ;  m  (input) is number of constraints in the problem, i.e., the dimension of  C ;  X  (input) is an array with the current estimate of the solution of the problem;  f  (output) is the value of the objective function evaluated at  X ;  C  (output) is the value of the constraints function evaluated at  X .   In Julia, we have  f ,   c   =   cfn ( n ,   m ,   x )  f ,   c   =   cfn ( nlp ,   x )  f   =   cfn! ( n ,   m ,   x ,   c )  f   =   cfn! ( nlp ,   x ,   c )   As before, we have a simplification of the original call. Also, again, we have the use of  nlp  instead of some fixed problem values. Notice how  nlp  substitutes more than one thing, making it easier to use because we don't have to remeber what is needed by the function, nor where it goes. When present,  nlp  is always the first argument.  In addition, there are two new functions here, obtained by addind a  !  in front of the function name. These functions modify the vector  c  storing the result in it. This can be done to save memory, since  c  will not be recreated. As a convention in Julia, every function that has a  !  in the end modifies some input.", 
            "title": "Specialized Interface"
        }, 
        {
            "location": "/core/#reference-guide", 
            "text": "There are a lot of functions in CUTEst. To see them all, you can check the  Technical Report  decribing them.  Below is a little guide to search the functions documentation.  Only some functions are shown.  Remember that we are looking into problems in the form  \\begin{align*} \\min \\quad & f(x) \\\\\n& c_L \\leq c(x) \\leq c_U \\\\\n& \\ell \\leq x \\leq u, \\end{align*}  with Lagrangian  \\begin{align*} L(x,y) = f(x) + y^Tc(x). \\end{align*}   Note:   x  in the beginning of the function name means that both  u  and  c  versions exist.     Function  Specialized Interface Functions      $f(x)$  ufn, uofg, cfn, cofg    $\\nabla f(x)$  ugr, uofg, cfn, cofg    $\\nabla^2 f(x)$  udh, ugrdh, ush, ugrsh, uhprod    $c(x)$  cfn, ccfg, ccfsg, ccifg    $J(x)$  ccfg, ccfsg, ccifg    $\\nabla^2 L(x,y)$  cdh, cgrdh, csh, cgrsh, chprod    $\\nabla^2 (y^Tc(x))$  chcprod     Examples  using   CUTEst  nlp   =   CUTEstModel ( ROSENBR )  x   =   nlp . meta . x0  fx   =   ufn ( nlp ,   x )   24.199999999999996  nnzj ,   hval ,   hrow ,   hcol   =   ush ( nlp ,   x )   (3,[1330.0,480.0,200.0],Int32[1,1,2],Int32[1,2,2])  cutest_finalize ( nlp )  nlp   =   CUTEstModel ( HS51 )  x   =   nlp . meta . x0  # Checking documentation, in REPL use ?ccfsg  @ doc   ccfsg   ```\nc, nnzj, j_val, j_var, j_fun = ccfsg(nlp, x, grad)\n```\n\n  * nlp:     [IN] CUTEstModel\n  * x:       [IN] Array{Float64, 1}\n  * c:       [OUT] Array{Float64, 1}\n  * nnzj:    [OUT] Int\n  * j_val:   [OUT] Array{Float64, 1}\n  * j_var:   [OUT] Array{Int, 1}\n  * j_fun:   [OUT] Array{Int, 1}\n  * grad:    [IN] Bool\n\n```\nc, nnzj, j_val, j_var, j_fun = ccfsg(n, m, x, lj, grad)\n```\n\n  * n:       [IN] Int\n  * m:       [IN] Int\n  * x:       [IN] Array{Float64, 1}\n  * c:       [OUT] Array{Float64, 1}\n  * nnzj:    [OUT] Int\n  * lj:      [IN] Int\n  * j_val:   [OUT] Array{Float64, 1}\n  * j_var:   [OUT] Array{Int, 1}\n  * j_fun:   [OUT] Array{Int, 1}\n  * grad:    [IN] Bool\n\n# ccfsg\n\nThe ccfsg subroutine evaluates the values of the constraint functions of the problem decoded from a SIF file by the script sifdecoder at the point X, and possibly their gradients in the constrained minimization case. The gradients are stored in sparse format. The problem under consideration is to minimize or maximize an objective function f(x) over all x \u2208 Rn subject to general equations ci(x)=0, (i \u2208 1,...,mE), general inequalities ci(x)\u2264ci(x)\u2264ci(x), (i \u2208 mE+1,...,m), and simple bounds xl\u2264x\u2264xu. The objective function is group-partially separable and all constraint functions are partially separable.\n\nFor more information, run the shell command\n\n```\nman cutest_ccfsg\n```\n\nUsage:\n\n```\nccfsg(io_err, n, m, x, c, nnzj, lj, j_val, j_var, j_fun, grad)\n```\n\n  * io_err:  [OUT] Array{Cint, 1}\n  * n:       [IN] Array{Cint, 1}\n  * m:       [IN] Array{Cint, 1}\n  * x:       [IN] Array{Cdouble, 1}\n  * c:       [OUT] Array{Cdouble, 1}\n  * nnzj:    [OUT] Array{Cint, 1}\n  * lj:      [IN] Array{Cint, 1}\n  * j_val:   [OUT] Array{Cdouble, 1}\n  * j_var:   [OUT] Array{Cint, 1}\n  * j_fun:   [OUT] Array{Cint, 1}\n  * grad:    [IN] Array{Cint, 1}  c ,   nnzj ,   jval ,   jvar ,   jfun   =   ccfsg ( nlp ,   x ,   true )  println ( c =  $c )  println ( J =  $(sparse(jvar, jfun, jval)) )   c = [0.0,0.0,0.0]\nJ =\n    [1, 1]  =  1.0\n    [2, 1]  =  3.0\n    [3, 2]  =  1.0\n    [4, 2]  =  1.0\n    [5, 2]  =  -2.0\n    [2, 3]  =  1.0\n    [5, 3]  =  -1.0  Compare with the NLPModels interface  c   =   cons ( nlp ,   x )  J   =   jac ( nlp ,   x )  println ( c =  $c )  println ( J =  $J )   c = [0.0,0.0,0.0]\nJ =\n    [1, 1]  =  1.0\n    [1, 2]  =  3.0\n    [3, 2]  =  1.0\n    [2, 3]  =  1.0\n    [2, 4]  =  1.0\n    [2, 5]  =  -2.0\n    [3, 5]  =  -1.0  cutest_finalize ( nlp )", 
            "title": "Reference Guide"
        }, 
        {
            "location": "/reference/", 
            "text": "Reference\n\n\n\n\nCUTEst.ccfg\n\n\nCUTEst.ccfg\n\n\nCUTEst.ccfg\n\n\nCUTEst.ccfg!\n\n\nCUTEst.ccfg!\n\n\nCUTEst.ccfsg\n\n\nCUTEst.ccfsg\n\n\nCUTEst.ccfsg\n\n\nCUTEst.ccfsg!\n\n\nCUTEst.ccfsg!\n\n\nCUTEst.cchprods\n\n\nCUTEst.cchprods\n\n\nCUTEst.cchprods\n\n\nCUTEst.cchprods!\n\n\nCUTEst.cchprods!\n\n\nCUTEst.ccifg\n\n\nCUTEst.ccifg\n\n\nCUTEst.ccifg\n\n\nCUTEst.ccifg!\n\n\nCUTEst.ccifg!\n\n\nCUTEst.ccifsg\n\n\nCUTEst.ccifsg\n\n\nCUTEst.ccifsg\n\n\nCUTEst.ccifsg!\n\n\nCUTEst.ccifsg!\n\n\nCUTEst.cdh\n\n\nCUTEst.cdh\n\n\nCUTEst.cdh\n\n\nCUTEst.cdh!\n\n\nCUTEst.cdh!\n\n\nCUTEst.cdhc\n\n\nCUTEst.cdhc\n\n\nCUTEst.cdhc\n\n\nCUTEst.cdhc!\n\n\nCUTEst.cdhc!\n\n\nCUTEst.cdimchp\n\n\nCUTEst.cdimchp\n\n\nCUTEst.cdimchp\n\n\nCUTEst.cdimen\n\n\nCUTEst.cdimen\n\n\nCUTEst.cdimse\n\n\nCUTEst.cdimse\n\n\nCUTEst.cdimsh\n\n\nCUTEst.cdimsh\n\n\nCUTEst.cdimsj\n\n\nCUTEst.cdimsj\n\n\nCUTEst.ceh\n\n\nCUTEst.ceh\n\n\nCUTEst.ceh\n\n\nCUTEst.ceh!\n\n\nCUTEst.ceh!\n\n\nCUTEst.cfn\n\n\nCUTEst.cfn\n\n\nCUTEst.cfn\n\n\nCUTEst.cfn!\n\n\nCUTEst.cfn!\n\n\nCUTEst.cgr\n\n\nCUTEst.cgr\n\n\nCUTEst.cgr\n\n\nCUTEst.cgr!\n\n\nCUTEst.cgr!\n\n\nCUTEst.cgrdh\n\n\nCUTEst.cgrdh\n\n\nCUTEst.cgrdh\n\n\nCUTEst.cgrdh!\n\n\nCUTEst.cgrdh!\n\n\nCUTEst.chcprod\n\n\nCUTEst.chcprod\n\n\nCUTEst.chcprod\n\n\nCUTEst.chcprod!\n\n\nCUTEst.chcprod!\n\n\nCUTEst.chprod\n\n\nCUTEst.chprod\n\n\nCUTEst.chprod\n\n\nCUTEst.chprod!\n\n\nCUTEst.chprod!\n\n\nCUTEst.cidh\n\n\nCUTEst.cidh\n\n\nCUTEst.cidh\n\n\nCUTEst.cidh!\n\n\nCUTEst.cidh!\n\n\nCUTEst.cish\n\n\nCUTEst.cish\n\n\nCUTEst.cish\n\n\nCUTEst.cish!\n\n\nCUTEst.cish!\n\n\nCUTEst.cjprod\n\n\nCUTEst.cjprod\n\n\nCUTEst.cjprod\n\n\nCUTEst.cjprod!\n\n\nCUTEst.cjprod!\n\n\nCUTEst.clfg\n\n\nCUTEst.clfg\n\n\nCUTEst.clfg\n\n\nCUTEst.clfg!\n\n\nCUTEst.clfg!\n\n\nCUTEst.cnames\n\n\nCUTEst.cnames\n\n\nCUTEst.cnames\n\n\nCUTEst.cnames!\n\n\nCUTEst.cnames!\n\n\nCUTEst.cofg\n\n\nCUTEst.cofg\n\n\nCUTEst.cofg\n\n\nCUTEst.cofg!\n\n\nCUTEst.cofg!\n\n\nCUTEst.cofsg\n\n\nCUTEst.cofsg\n\n\nCUTEst.cofsg\n\n\nCUTEst.cofsg!\n\n\nCUTEst.cofsg!\n\n\nCUTEst.connames\n\n\nCUTEst.connames\n\n\nCUTEst.connames\n\n\nCUTEst.connames!\n\n\nCUTEst.connames!\n\n\nCUTEst.cons_coord\n\n\nCUTEst.creport\n\n\nCUTEst.creport\n\n\nCUTEst.creport\n\n\nCUTEst.creport!\n\n\nCUTEst.creport!\n\n\nCUTEst.csetup\n\n\nCUTEst.csetup\n\n\nCUTEst.csetup!\n\n\nCUTEst.csgr\n\n\nCUTEst.csgr\n\n\nCUTEst.csgr\n\n\nCUTEst.csgr!\n\n\nCUTEst.csgr!\n\n\nCUTEst.csgreh\n\n\nCUTEst.csgreh\n\n\nCUTEst.csgreh\n\n\nCUTEst.csgreh!\n\n\nCUTEst.csgreh!\n\n\nCUTEst.csgrsh\n\n\nCUTEst.csgrsh\n\n\nCUTEst.csgrsh\n\n\nCUTEst.csgrsh!\n\n\nCUTEst.csgrsh!\n\n\nCUTEst.csh\n\n\nCUTEst.csh\n\n\nCUTEst.csh\n\n\nCUTEst.csh!\n\n\nCUTEst.csh!\n\n\nCUTEst.cshc\n\n\nCUTEst.cshc\n\n\nCUTEst.cshc\n\n\nCUTEst.cshc!\n\n\nCUTEst.cshc!\n\n\nCUTEst.cshcprod\n\n\nCUTEst.cshcprod\n\n\nCUTEst.cshcprod\n\n\nCUTEst.cshcprod!\n\n\nCUTEst.cshcprod!\n\n\nCUTEst.cshp\n\n\nCUTEst.cshp\n\n\nCUTEst.cshp\n\n\nCUTEst.cshp!\n\n\nCUTEst.cshp!\n\n\nCUTEst.cshprod\n\n\nCUTEst.cshprod\n\n\nCUTEst.cshprod\n\n\nCUTEst.cshprod!\n\n\nCUTEst.cshprod!\n\n\nCUTEst.csjprod\n\n\nCUTEst.csjprod\n\n\nCUTEst.csjprod\n\n\nCUTEst.csjprod!\n\n\nCUTEst.csjprod!\n\n\nCUTEst.cstats\n\n\nCUTEst.cstats\n\n\nCUTEst.cstats\n\n\nCUTEst.cterminate\n\n\nCUTEst.cterminate\n\n\nCUTEst.cvartype\n\n\nCUTEst.cvartype\n\n\nCUTEst.cvartype!\n\n\nCUTEst.objcons\n\n\nCUTEst.objgrad\n\n\nCUTEst.pname\n\n\nCUTEst.pname\n\n\nCUTEst.pname\n\n\nCUTEst.probname\n\n\nCUTEst.probname\n\n\nCUTEst.probname\n\n\nCUTEst.sifdecoder\n\n\nCUTEst.ubandh\n\n\nCUTEst.ubandh\n\n\nCUTEst.ubandh\n\n\nCUTEst.ubandh!\n\n\nCUTEst.ubandh!\n\n\nCUTEst.udh\n\n\nCUTEst.udh\n\n\nCUTEst.udh\n\n\nCUTEst.udh!\n\n\nCUTEst.udh!\n\n\nCUTEst.udimen\n\n\nCUTEst.udimen\n\n\nCUTEst.udimse\n\n\nCUTEst.udimse\n\n\nCUTEst.udimsh\n\n\nCUTEst.udimsh\n\n\nCUTEst.ueh\n\n\nCUTEst.ueh\n\n\nCUTEst.ueh\n\n\nCUTEst.ueh!\n\n\nCUTEst.ueh!\n\n\nCUTEst.ufn\n\n\nCUTEst.ufn\n\n\nCUTEst.ufn\n\n\nCUTEst.ugr\n\n\nCUTEst.ugr\n\n\nCUTEst.ugr\n\n\nCUTEst.ugr!\n\n\nCUTEst.ugr!\n\n\nCUTEst.ugrdh\n\n\nCUTEst.ugrdh\n\n\nCUTEst.ugrdh\n\n\nCUTEst.ugrdh!\n\n\nCUTEst.ugrdh!\n\n\nCUTEst.ugreh\n\n\nCUTEst.ugreh\n\n\nCUTEst.ugreh\n\n\nCUTEst.ugreh!\n\n\nCUTEst.ugreh!\n\n\nCUTEst.ugrsh\n\n\nCUTEst.ugrsh\n\n\nCUTEst.ugrsh\n\n\nCUTEst.ugrsh!\n\n\nCUTEst.ugrsh!\n\n\nCUTEst.uhprod\n\n\nCUTEst.uhprod\n\n\nCUTEst.uhprod\n\n\nCUTEst.uhprod!\n\n\nCUTEst.uhprod!\n\n\nCUTEst.unames\n\n\nCUTEst.unames\n\n\nCUTEst.unames!\n\n\nCUTEst.uofg\n\n\nCUTEst.uofg\n\n\nCUTEst.uofg\n\n\nCUTEst.uofg!\n\n\nCUTEst.uofg!\n\n\nCUTEst.ureport\n\n\nCUTEst.ureport\n\n\nCUTEst.ureport\n\n\nCUTEst.ureport!\n\n\nCUTEst.ureport!\n\n\nCUTEst.usetup\n\n\nCUTEst.usetup\n\n\nCUTEst.usetup!\n\n\nCUTEst.ush\n\n\nCUTEst.ush\n\n\nCUTEst.ush\n\n\nCUTEst.ush!\n\n\nCUTEst.ush!\n\n\nCUTEst.ushp\n\n\nCUTEst.ushp\n\n\nCUTEst.ushp\n\n\nCUTEst.ushp!\n\n\nCUTEst.ushp!\n\n\nCUTEst.ushprod\n\n\nCUTEst.ushprod\n\n\nCUTEst.ushprod\n\n\nCUTEst.ushprod!\n\n\nCUTEst.ushprod!\n\n\nCUTEst.uterminate\n\n\nCUTEst.uterminate\n\n\nCUTEst.uvartype\n\n\nCUTEst.uvartype\n\n\nCUTEst.uvartype!\n\n\nCUTEst.varnames\n\n\nCUTEst.varnames\n\n\nCUTEst.varnames!\n\n\nLinearOperators.reset!\n\n\nNLPModels.NLPtoMPB\n\n\nNLPModels.cons\n\n\nNLPModels.cons!\n\n\nNLPModels.grad\n\n\nNLPModels.grad!\n\n\nNLPModels.hess\n\n\nNLPModels.hess_coord\n\n\nNLPModels.hprod\n\n\nNLPModels.hprod!\n\n\nNLPModels.jac\n\n\nNLPModels.jac_coord\n\n\nNLPModels.jprod\n\n\nNLPModels.jprod!\n\n\nNLPModels.jtprod\n\n\nNLPModels.jtprod!\n\n\nNLPModels.obj", 
            "title": "Reference"
        }, 
        {
            "location": "/reference/#reference", 
            "text": "CUTEst.ccfg  CUTEst.ccfg  CUTEst.ccfg  CUTEst.ccfg!  CUTEst.ccfg!  CUTEst.ccfsg  CUTEst.ccfsg  CUTEst.ccfsg  CUTEst.ccfsg!  CUTEst.ccfsg!  CUTEst.cchprods  CUTEst.cchprods  CUTEst.cchprods  CUTEst.cchprods!  CUTEst.cchprods!  CUTEst.ccifg  CUTEst.ccifg  CUTEst.ccifg  CUTEst.ccifg!  CUTEst.ccifg!  CUTEst.ccifsg  CUTEst.ccifsg  CUTEst.ccifsg  CUTEst.ccifsg!  CUTEst.ccifsg!  CUTEst.cdh  CUTEst.cdh  CUTEst.cdh  CUTEst.cdh!  CUTEst.cdh!  CUTEst.cdhc  CUTEst.cdhc  CUTEst.cdhc  CUTEst.cdhc!  CUTEst.cdhc!  CUTEst.cdimchp  CUTEst.cdimchp  CUTEst.cdimchp  CUTEst.cdimen  CUTEst.cdimen  CUTEst.cdimse  CUTEst.cdimse  CUTEst.cdimsh  CUTEst.cdimsh  CUTEst.cdimsj  CUTEst.cdimsj  CUTEst.ceh  CUTEst.ceh  CUTEst.ceh  CUTEst.ceh!  CUTEst.ceh!  CUTEst.cfn  CUTEst.cfn  CUTEst.cfn  CUTEst.cfn!  CUTEst.cfn!  CUTEst.cgr  CUTEst.cgr  CUTEst.cgr  CUTEst.cgr!  CUTEst.cgr!  CUTEst.cgrdh  CUTEst.cgrdh  CUTEst.cgrdh  CUTEst.cgrdh!  CUTEst.cgrdh!  CUTEst.chcprod  CUTEst.chcprod  CUTEst.chcprod  CUTEst.chcprod!  CUTEst.chcprod!  CUTEst.chprod  CUTEst.chprod  CUTEst.chprod  CUTEst.chprod!  CUTEst.chprod!  CUTEst.cidh  CUTEst.cidh  CUTEst.cidh  CUTEst.cidh!  CUTEst.cidh!  CUTEst.cish  CUTEst.cish  CUTEst.cish  CUTEst.cish!  CUTEst.cish!  CUTEst.cjprod  CUTEst.cjprod  CUTEst.cjprod  CUTEst.cjprod!  CUTEst.cjprod!  CUTEst.clfg  CUTEst.clfg  CUTEst.clfg  CUTEst.clfg!  CUTEst.clfg!  CUTEst.cnames  CUTEst.cnames  CUTEst.cnames  CUTEst.cnames!  CUTEst.cnames!  CUTEst.cofg  CUTEst.cofg  CUTEst.cofg  CUTEst.cofg!  CUTEst.cofg!  CUTEst.cofsg  CUTEst.cofsg  CUTEst.cofsg  CUTEst.cofsg!  CUTEst.cofsg!  CUTEst.connames  CUTEst.connames  CUTEst.connames  CUTEst.connames!  CUTEst.connames!  CUTEst.cons_coord  CUTEst.creport  CUTEst.creport  CUTEst.creport  CUTEst.creport!  CUTEst.creport!  CUTEst.csetup  CUTEst.csetup  CUTEst.csetup!  CUTEst.csgr  CUTEst.csgr  CUTEst.csgr  CUTEst.csgr!  CUTEst.csgr!  CUTEst.csgreh  CUTEst.csgreh  CUTEst.csgreh  CUTEst.csgreh!  CUTEst.csgreh!  CUTEst.csgrsh  CUTEst.csgrsh  CUTEst.csgrsh  CUTEst.csgrsh!  CUTEst.csgrsh!  CUTEst.csh  CUTEst.csh  CUTEst.csh  CUTEst.csh!  CUTEst.csh!  CUTEst.cshc  CUTEst.cshc  CUTEst.cshc  CUTEst.cshc!  CUTEst.cshc!  CUTEst.cshcprod  CUTEst.cshcprod  CUTEst.cshcprod  CUTEst.cshcprod!  CUTEst.cshcprod!  CUTEst.cshp  CUTEst.cshp  CUTEst.cshp  CUTEst.cshp!  CUTEst.cshp!  CUTEst.cshprod  CUTEst.cshprod  CUTEst.cshprod  CUTEst.cshprod!  CUTEst.cshprod!  CUTEst.csjprod  CUTEst.csjprod  CUTEst.csjprod  CUTEst.csjprod!  CUTEst.csjprod!  CUTEst.cstats  CUTEst.cstats  CUTEst.cstats  CUTEst.cterminate  CUTEst.cterminate  CUTEst.cvartype  CUTEst.cvartype  CUTEst.cvartype!  CUTEst.objcons  CUTEst.objgrad  CUTEst.pname  CUTEst.pname  CUTEst.pname  CUTEst.probname  CUTEst.probname  CUTEst.probname  CUTEst.sifdecoder  CUTEst.ubandh  CUTEst.ubandh  CUTEst.ubandh  CUTEst.ubandh!  CUTEst.ubandh!  CUTEst.udh  CUTEst.udh  CUTEst.udh  CUTEst.udh!  CUTEst.udh!  CUTEst.udimen  CUTEst.udimen  CUTEst.udimse  CUTEst.udimse  CUTEst.udimsh  CUTEst.udimsh  CUTEst.ueh  CUTEst.ueh  CUTEst.ueh  CUTEst.ueh!  CUTEst.ueh!  CUTEst.ufn  CUTEst.ufn  CUTEst.ufn  CUTEst.ugr  CUTEst.ugr  CUTEst.ugr  CUTEst.ugr!  CUTEst.ugr!  CUTEst.ugrdh  CUTEst.ugrdh  CUTEst.ugrdh  CUTEst.ugrdh!  CUTEst.ugrdh!  CUTEst.ugreh  CUTEst.ugreh  CUTEst.ugreh  CUTEst.ugreh!  CUTEst.ugreh!  CUTEst.ugrsh  CUTEst.ugrsh  CUTEst.ugrsh  CUTEst.ugrsh!  CUTEst.ugrsh!  CUTEst.uhprod  CUTEst.uhprod  CUTEst.uhprod  CUTEst.uhprod!  CUTEst.uhprod!  CUTEst.unames  CUTEst.unames  CUTEst.unames!  CUTEst.uofg  CUTEst.uofg  CUTEst.uofg  CUTEst.uofg!  CUTEst.uofg!  CUTEst.ureport  CUTEst.ureport  CUTEst.ureport  CUTEst.ureport!  CUTEst.ureport!  CUTEst.usetup  CUTEst.usetup  CUTEst.usetup!  CUTEst.ush  CUTEst.ush  CUTEst.ush  CUTEst.ush!  CUTEst.ush!  CUTEst.ushp  CUTEst.ushp  CUTEst.ushp  CUTEst.ushp!  CUTEst.ushp!  CUTEst.ushprod  CUTEst.ushprod  CUTEst.ushprod  CUTEst.ushprod!  CUTEst.ushprod!  CUTEst.uterminate  CUTEst.uterminate  CUTEst.uvartype  CUTEst.uvartype  CUTEst.uvartype!  CUTEst.varnames  CUTEst.varnames  CUTEst.varnames!  LinearOperators.reset!  NLPModels.NLPtoMPB  NLPModels.cons  NLPModels.cons!  NLPModels.grad  NLPModels.grad!  NLPModels.hess  NLPModels.hess_coord  NLPModels.hprod  NLPModels.hprod!  NLPModels.jac  NLPModels.jac_coord  NLPModels.jprod  NLPModels.jprod!  NLPModels.jtprod  NLPModels.jtprod!  NLPModels.obj", 
            "title": "Reference"
        }
    ]
}